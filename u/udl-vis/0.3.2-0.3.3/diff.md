# Comparing `tmp/udl_vis-0.3.2-py3-none-any.whl.zip` & `tmp/udl_vis-0.3.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,22 +1,22 @@
-Zip file size: 421555 bytes, number of entries: 224
+Zip file size: 422485 bytes, number of entries: 224
 -rw-rw-rw-  2.0 fat      250 b- defN 23-Jun-09 10:56 udl_vis/__init__.py
 -rw-rw-rw-  2.0 fat       15 b- defN 23-Jun-09 09:55 udl_vis/AutoDL/__init__.py
--rw-rw-rw-  2.0 fat    13800 b- defN 23-Jun-17 16:50 udl_vis/AutoDL/trainer.py
+-rw-rw-rw-  2.0 fat    13858 b- defN 23-Jun-21 03:23 udl_vis/AutoDL/trainer.py
 -rw-rw-rw-  2.0 fat       15 b- defN 23-Jun-09 09:55 udl_vis/Basis/__init__.py
 -rw-rw-rw-  2.0 fat     2851 b- defN 22-Oct-04 08:46 udl_vis/Basis/cal_ssim.py
 -rw-rw-rw-  2.0 fat    29004 b- defN 23-Jun-07 03:16 udl_vis/Basis/config.py
 -rw-rw-rw-  2.0 fat     4087 b- defN 23-Jun-07 03:16 udl_vis/Basis/criterion_metrics.py
 -rw-rw-rw-  2.0 fat     6622 b- defN 22-Oct-04 08:46 udl_vis/Basis/dist_utils.py
 -rw-rw-rw-  2.0 fat    14882 b- defN 22-Oct-04 08:46 udl_vis/Basis/launch.py
 -rw-rw-rw-  2.0 fat     8754 b- defN 23-Jun-07 03:16 udl_vis/Basis/logger.py
 -rw-rw-rw-  2.0 fat     3145 b- defN 23-Jun-07 03:16 udl_vis/Basis/metrics.py
--rw-rw-rw-  2.0 fat    16848 b- defN 22-Sep-16 14:28 udl_vis/Basis/module.py
+-rw-rw-rw-  2.0 fat    16806 b- defN 23-Jun-19 15:32 udl_vis/Basis/module.py
 -rw-rw-rw-  2.0 fat     9926 b- defN 22-Oct-04 08:46 udl_vis/Basis/optim.py
--rw-rw-rw-  2.0 fat     6233 b- defN 23-Jun-17 16:04 udl_vis/Basis/option.py
+-rw-rw-rw-  2.0 fat     6270 b- defN 23-Jun-21 03:23 udl_vis/Basis/option.py
 -rw-rw-rw-  2.0 fat    17306 b- defN 23-Jun-07 03:16 udl_vis/Basis/postprocess.py
 -rw-rw-rw-  2.0 fat     5187 b- defN 23-Jun-09 18:39 udl_vis/Basis/python_sub_class.py
 -rw-rw-rw-  2.0 fat     3145 b- defN 23-Jun-07 03:16 udl_vis/Basis/variance_sacling_initializer.py
 -rw-rw-rw-  2.0 fat      134 b- defN 22-Oct-04 08:46 udl_vis/Basis/auxiliary/__init__.py
 -rw-rw-rw-  2.0 fat     1084 b- defN 22-Oct-04 08:46 udl_vis/Basis/auxiliary/base.py
 -rw-rw-rw-  2.0 fat     7303 b- defN 22-Oct-04 08:46 udl_vis/Basis/auxiliary/fp16_utils.py
 -rw-rw-rw-  2.0 fat    11956 b- defN 23-Jun-07 03:14 udl_vis/Basis/auxiliary/utils.py
@@ -146,64 +146,64 @@
 -rw-rw-rw-  2.0 fat     4945 b- defN 23-Jun-07 03:14 udl_vis/mmcv/parallel/distributed.py
 -rw-rw-rw-  2.0 fat     2887 b- defN 22-Oct-04 08:46 udl_vis/mmcv/parallel/distributed_deprecated.py
 -rw-rw-rw-  2.0 fat      328 b- defN 23-Jun-07 03:14 udl_vis/mmcv/parallel/registry.py
 -rw-rw-rw-  2.0 fat     2366 b- defN 22-Oct-04 08:46 udl_vis/mmcv/parallel/scatter_gather.py
 -rw-rw-rw-  2.0 fat      728 b- defN 22-Oct-04 08:46 udl_vis/mmcv/parallel/utils.py
 -rw-rw-rw-  2.0 fat     4385 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/__init__.py
 -rw-rw-rw-  2.0 fat    14570 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/base_module.py
--rw-rw-rw-  2.0 fat    22884 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/base_runner.py
+-rw-rw-rw-  2.0 fat    24419 b- defN 23-Jun-21 03:25 udl_vis/mmcv/runner/base_runner.py
 -rw-rw-rw-  2.0 fat      690 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/builder.py
--rw-rw-rw-  2.0 fat    33627 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/checkpoint.py
+-rw-rw-rw-  2.0 fat    33917 b- defN 23-Jun-21 03:32 udl_vis/mmcv/runner/checkpoint.py
 -rw-rw-rw-  2.0 fat     1952 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/default_constructor.py
 -rw-rw-rw-  2.0 fat     5559 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/dist_utils.py
--rw-rw-rw-  2.0 fat    13951 b- defN 23-Jun-17 16:58 udl_vis/mmcv/runner/epoch_based_runner.py
+-rw-rw-rw-  2.0 fat    14168 b- defN 23-Jun-19 15:28 udl_vis/mmcv/runner/epoch_based_runner.py
 -rw-rw-rw-  2.0 fat    16873 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/fp16_utils.py
 -rw-rw-rw-  2.0 fat    11438 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/iter_based_runner.py
 -rw-rw-rw-  2.0 fat     1880 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/log_buffer.py
 -rw-rw-rw-  2.0 fat     1241 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/misc.py
 -rw-rw-rw-  2.0 fat     1658 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/priority.py
 -rw-rw-rw-  2.0 fat    11169 b- defN 23-Jun-17 15:49 udl_vis/mmcv/runner/record.py
 -rw-rw-rw-  2.0 fat     3014 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/utils.py
 -rw-rw-rw-  2.0 fat     2402 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/__init__.py
--rw-rw-rw-  2.0 fat    18955 b- defN 23-Jun-17 15:52 udl_vis/mmcv/runner/hooks/checkpoint.py
+-rw-rw-rw-  2.0 fat    19368 b- defN 23-Jun-21 03:42 udl_vis/mmcv/runner/hooks/checkpoint.py
 -rw-rw-rw-  2.0 fat      280 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/closure.py
 -rw-rw-rw-  2.0 fat     3674 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/ema.py
 -rw-rw-rw-  2.0 fat    22917 b- defN 23-Jun-09 14:10 udl_vis/mmcv/runner/hooks/evaluation.py
--rw-rw-rw-  2.0 fat     2849 b- defN 23-Jun-17 16:24 udl_vis/mmcv/runner/hooks/hook.py
+-rw-rw-rw-  2.0 fat     2927 b- defN 23-Jun-18 03:48 udl_vis/mmcv/runner/hooks/hook.py
 -rw-rw-rw-  2.0 fat      521 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/iter_timer.py
 -rw-rw-rw-  2.0 fat    27815 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/lr_updater.py
 -rw-rw-rw-  2.0 fat      682 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/memory.py
 -rw-rw-rw-  2.0 fat    23465 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/momentum_updater.py
 -rw-rw-rw-  2.0 fat     1602 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/nni_hook.py
 -rw-rw-rw-  2.0 fat    25296 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/optimizer.py
 -rw-rw-rw-  2.0 fat     8221 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/profiler.py
 -rw-rw-rw-  2.0 fat      867 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/sampler_seed.py
 -rw-rw-rw-  2.0 fat      729 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/sync_buffer.py
 -rw-rw-rw-  2.0 fat      537 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/logger/__init__.py
--rw-rw-rw-  2.0 fat     6222 b- defN 23-Jun-17 16:34 udl_vis/mmcv/runner/hooks/logger/base.py
+-rw-rw-rw-  2.0 fat     6410 b- defN 23-Jun-18 17:14 udl_vis/mmcv/runner/hooks/logger/base.py
 -rw-rw-rw-  2.0 fat     2294 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/logger/dvclive.py
 -rw-rw-rw-  2.0 fat     2995 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/logger/mlflow.py
 -rw-rw-rw-  2.0 fat     3338 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/logger/neptune.py
 -rw-rw-rw-  2.0 fat     5269 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/logger/pavi.py
 -rw-rw-rw-  2.0 fat     2739 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/logger/tensorboard.py
--rw-rw-rw-  2.0 fat    11234 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/logger/text.py
+-rw-rw-rw-  2.0 fat    12526 b- defN 23-Jun-21 03:27 udl_vis/mmcv/runner/hooks/logger/text.py
 -rw-rw-rw-  2.0 fat     4009 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/logger/wandb.py
 -rw-rw-rw-  2.0 fat      379 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/optimizer/__init__.py
 -rw-rw-rw-  2.0 fat     1390 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/optimizer/builder.py
 -rw-rw-rw-  2.0 fat    11971 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/optimizer/default_constructor.py
 -rw-rw-rw-  2.0 fat      788 b- defN 22-Oct-04 08:46 udl_vis/mmcv/tensorrt/__init__.py
 -rw-rw-rw-  2.0 fat      916 b- defN 22-Oct-04 08:46 udl_vis/mmcv/tensorrt/init_plugins.py
 -rw-rw-rw-  2.0 fat     4459 b- defN 22-Oct-04 08:46 udl_vis/mmcv/tensorrt/preprocess.py
 -rw-rw-rw-  2.0 fat     8417 b- defN 22-Oct-04 08:46 udl_vis/mmcv/tensorrt/tensorrt_utils.py
 -rw-rw-rw-  2.0 fat     4027 b- defN 22-Oct-04 08:46 udl_vis/mmcv/utils/__init__.py
 -rw-rw-rw-  2.0 fat    27039 b- defN 22-Oct-04 08:46 udl_vis/mmcv/utils/config.py
 -rw-rw-rw-  2.0 fat     3407 b- defN 23-Jun-07 03:14 udl_vis/mmcv/utils/env.py
 -rw-rw-rw-  2.0 fat     2092 b- defN 22-Oct-04 08:46 udl_vis/mmcv/utils/ext_loader.py
 -rw-rw-rw-  2.0 fat     6167 b- defN 22-Oct-04 08:46 udl_vis/mmcv/utils/hub.py
--rw-rw-rw-  2.0 fat    13466 b- defN 23-Jun-09 14:09 udl_vis/mmcv/utils/logging.py
+-rw-rw-rw-  2.0 fat    13489 b- defN 23-Jun-18 06:36 udl_vis/mmcv/utils/logging.py
 -rw-rw-rw-  2.0 fat    11864 b- defN 22-Oct-04 08:46 udl_vis/mmcv/utils/misc.py
 -rw-rw-rw-  2.0 fat      940 b- defN 22-Oct-04 08:46 udl_vis/mmcv/utils/parrots_jit.py
 -rw-rw-rw-  2.0 fat     3643 b- defN 22-Oct-04 08:46 udl_vis/mmcv/utils/parrots_wrapper.py
 -rw-rw-rw-  2.0 fat     3516 b- defN 22-Oct-04 08:46 udl_vis/mmcv/utils/path.py
 -rw-rw-rw-  2.0 fat     7313 b- defN 22-Oct-04 08:46 udl_vis/mmcv/utils/progressbar.py
 -rw-rw-rw-  2.0 fat    11722 b- defN 22-Oct-04 08:46 udl_vis/mmcv/utils/registry.py
 -rw-rw-rw-  2.0 fat     4429 b- defN 22-Oct-04 08:46 udl_vis/mmcv/utils/testing.py
@@ -214,13 +214,13 @@
 -rw-rw-rw-  2.0 fat    10517 b- defN 23-Jun-07 03:14 udl_vis/mmcv/video/io.py
 -rw-rw-rw-  2.0 fat     9942 b- defN 23-Jun-07 03:14 udl_vis/mmcv/video/optflow.py
 -rw-rw-rw-  2.0 fat     5439 b- defN 23-Jun-07 03:14 udl_vis/mmcv/video/processing.py
 -rw-rw-rw-  2.0 fat      347 b- defN 22-Oct-04 08:46 udl_vis/mmcv/visualization/__init__.py
 -rw-rw-rw-  2.0 fat     1420 b- defN 23-Jun-07 03:14 udl_vis/mmcv/visualization/color.py
 -rw-rw-rw-  2.0 fat     5285 b- defN 23-Jun-07 03:14 udl_vis/mmcv/visualization/image.py
 -rw-rw-rw-  2.0 fat     3477 b- defN 23-Jun-07 03:14 udl_vis/mmcv/visualization/optflow.py
--rw-rw-rw-  2.0 fat    35823 b- defN 23-Jun-17 17:07 udl_vis-0.3.2.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     5930 b- defN 23-Jun-17 17:07 udl_vis-0.3.2.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Jun-17 17:07 udl_vis-0.3.2.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 23-Jun-17 17:07 udl_vis-0.3.2.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat    20326 b- defN 23-Jun-17 17:07 udl_vis-0.3.2.dist-info/RECORD
-224 files, 1440459 bytes uncompressed, 389291 bytes compressed:  73.0%
+-rw-rw-rw-  2.0 fat    35823 b- defN 23-Jun-21 03:43 udl_vis-0.3.3.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     5930 b- defN 23-Jun-21 03:43 udl_vis-0.3.3.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Jun-21 03:43 udl_vis-0.3.3.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        8 b- defN 23-Jun-21 03:43 udl_vis-0.3.3.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat    20326 b- defN 23-Jun-21 03:43 udl_vis-0.3.3.dist-info/RECORD
+224 files, 1444548 bytes uncompressed, 390221 bytes compressed:  73.0%
```

## zipnote {}

```diff
@@ -651,23 +651,23 @@
 
 Filename: udl_vis/mmcv/visualization/image.py
 Comment: 
 
 Filename: udl_vis/mmcv/visualization/optflow.py
 Comment: 
 
-Filename: udl_vis-0.3.2.dist-info/LICENSE
+Filename: udl_vis-0.3.3.dist-info/LICENSE
 Comment: 
 
-Filename: udl_vis-0.3.2.dist-info/METADATA
+Filename: udl_vis-0.3.3.dist-info/METADATA
 Comment: 
 
-Filename: udl_vis-0.3.2.dist-info/WHEEL
+Filename: udl_vis-0.3.3.dist-info/WHEEL
 Comment: 
 
-Filename: udl_vis-0.3.2.dist-info/top_level.txt
+Filename: udl_vis-0.3.3.dist-info/top_level.txt
 Comment: 
 
-Filename: udl_vis-0.3.2.dist-info/RECORD
+Filename: udl_vis-0.3.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## udl_vis/AutoDL/trainer.py

```diff
@@ -124,14 +124,15 @@
             # assert cfg.epochs == cfg.runner['max_epochs'], print(cfg.epochs, cfg.runner['max_epochs'])
 
     runner = build_runner(
         cfg.runner,
         default_args=dict(
             model=model,
             optimizer=optimizer,
+            seed=cfg.seed,
             work_dir=cfg.work_dir,
             logger=logger,
             meta=meta,
             opt_cfg={'log_interval': cfg.log_interval,
                      'save_interval': cfg.save_interval,
                      'accumulated_step': cfg.accumulated_step,
                      'grad_clip': cfg.grad_clip,
@@ -277,15 +278,15 @@
     resume_from = None
     if cfg.get('resume_from', None) is None and cfg.get('auto_resume'):
         resume_from = find_latest_checkpoint(cfg.work_dir)
     if resume_from is not None:
         cfg.resume_from = resume_from
 
     # if cfg.get('resume_from', None):
-    runner.resume(cfg.resume_from, cfg.resume_mode, cfg.reset_lr, cfg.lr)
+    runner.resume(cfg.resume_from, cfg.resume_mode, cfg.reset_lr, cfg.lr, cfg.prefix_model)
     if cfg.get('load_from', None) and cfg.get('resume_from', None) is not None:
         runner.load_checkpoint(cfg.load_from, cfg.resume_mode)
 
     ############################################################
     # 载入数据，运行模型
     ############################################################
     runner.run(data_loaders, cfg.workflow)
@@ -300,18 +301,18 @@
         init_dist(cfg.launcher, **cfg.dist_params)
         # re-set gpu_ids with distributed training mode
         _, world_size = get_dist_info()
         cfg.gpu_ids = range(world_size)
 
     logger, out_dir, model_save_dir, tfb_dir = create_logger(cfg, cfg.experimental_desc, 0)
     cfg.out_dir = cfg.work_dir = model_save_dir
-    seed = init_random_seed(cfg.seed)
-    print_log(f'Set random seed to {seed}', logger=logger)
+    cfg.seed = init_random_seed(cfg.seed)
+    print_log(f'Set random seed to {cfg.seed}', logger=logger)
 
-    set_random_seed(seed)
+    set_random_seed(cfg.seed)
 
     # if cfg.checkpoint_config is not None:
     #     # save mmdet version, config file content and class names in
     #     # checkpoints as meta data
     #     cfg.checkpoint_config.meta = dict(
     #         mmdet_version=__version__ + get_git_hash()[:7],
     #         CLASSES=datasets[0].CLASSES)
```

## udl_vis/Basis/module.py

```diff
@@ -1,15 +1,13 @@
 # GPL License
-# Copyright (C) 2021 , UESTC
-# All Rights Reserved 
-#
-# @Time    : 2022/9/16 22:28
+# Copyright (C) UESTC
+# All Rights Reserved
 # @Author  : Xiao Wu
 # @reference: 
-#
+
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 
 class PatchMergeModule(nn.Module):
```

## udl_vis/Basis/option.py

```diff
@@ -11,15 +11,15 @@
 from udl_vis.Basis.config import Config
 import warnings
 
 def common_cfg():
     parser = argparse.ArgumentParser(description='PyTorch Training')
 
     # * Logger
-    parser.add_argument('--use-log', default=True
+    parser.add_argument('--use_log_and_save', default=True
                         , type=bool)
     parser.add_argument('--log-dir', metavar='DIR', default='logs',
                         help='path to save log')
     parser.add_argument('--tfb-dir', metavar='DIR', default=None,
                         help='useless in this script.')
     parser.add_argument('--use-tfb', default=False, type=bool)
 
@@ -79,14 +79,15 @@
     args.save_top_k = 5
     args.start_epoch = 1
     assert args.accumulated_step > 0
     args.load_model_strict = True
     args.resume_mode = 'best'
     args.validate = False
     args.gpu_ids = [0]
+    args.prefix_model = ''
     # args.workflow = []
 
     return Config(args)
 
 def nni_cfg(args):
     if args.mode == 'nni':
         import nni
```

## udl_vis/mmcv/runner/base_runner.py

```diff
@@ -1,28 +1,29 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import copy
 import logging
+import os.path
 import os.path as osp
 import warnings
 from abc import ABCMeta, abstractmethod
 
 import torch
+import numpy as np
 from torch.optim import Optimizer
 
 from udl_vis import mmcv
 from ..parallel import is_module_wrapper
-from .checkpoint import load_checkpoint
+from .checkpoint import load_checkpoint, print_log
 from .dist_utils import get_dist_info
 from .hooks import HOOKS, Hook
 from .log_buffer import LogBuffer
 from .priority import Priority, get_priority
 from .utils import get_time_str
 from .record import MetricLogger
 
-
 class BaseRunner(metaclass=ABCMeta):
     """The base class of Runner, a training helper for PyTorch.
 
     All subclasses should implement the following APIs:
 
     - ``run()``
     - ``train()``
@@ -49,14 +50,15 @@
         max_iters (int, optional): Total training iterations.
     """
 
     def __init__(self,
                  model,
                  batch_processor=None,
                  optimizer=None,
+                 seed=None,
                  work_dir=None,
                  logger=None,
                  meta=None,
                  max_iters=None,
                  max_epochs=None,
                  opt_cfg=None):
         if batch_processor is not None:
@@ -90,36 +92,38 @@
         elif not isinstance(optimizer, Optimizer) and optimizer is not None:
             raise TypeError(
                 f'optimizer must be a torch.optim.Optimizer object '
                 f'or dict or None, but got {type(optimizer)}')
 
         # check the type of `logger`
         if not isinstance(logger, logging.Logger):
-            raise TypeError(f'logger must be a logging.Logger object, '
+            warnings.warn(f'logger must be a logging.Logger object, '
                             f'but got {type(logger)}')
 
         # check the type of `meta`
         if meta is not None and not isinstance(meta, dict):
             raise TypeError(
                 f'meta must be a dict or None, but got {type(meta)}')
 
         self.model = model
         self.batch_processor = batch_processor
         self.optimizer = optimizer
         self.logger = logger
         self.meta = meta
         self.opt_cfg = opt_cfg
         self.earlyStop = False
+        self.seed = seed
         # create work_dir
         save_dir = opt_cfg['save_dir']
         if mmcv.is_str(work_dir):
             self.work_dir = osp.abspath(work_dir)
             self.save_dir = osp.abspath(save_dir)
-            mmcv.mkdir_or_exist(self.save_dir)
-            mmcv.mkdir_or_exist(self.work_dir)
+            if os.path.isdir(work_dir):
+                mmcv.mkdir_or_exist(self.save_dir)
+                # mmcv.mkdir_or_exist(self.work_dir)
         elif work_dir is None:
             self.work_dir = None
             self.save_dir = None
         else:
             raise TypeError(f'"work_dir: {work_dir}" must be a str or None')
 
 
@@ -343,48 +347,50 @@
                 stage_hook_infos.append(info)
         return '\n'.join(stage_hook_infos)
 
     def load_checkpoint(self,
                         filename,
                         resume_mode,
                         map_location='cpu',
+                        prefix='',
                         strict=False,
                         revise_keys=[(r'^module.', '')]):
 
         return load_checkpoint(
             resume_mode,
-            self.work_dir,
+            os.path.dirname(filename) if os.path.isdir(os.path.dirname(filename)) else self.work_dir,
             self.model,
             filename,
             map_location,
+            prefix,
             strict,
             self.logger,
             revise_keys=revise_keys)
 
     def resume(self,
                resume, resume_mode,
-               reset_lr, lr,
+               reset_lr, lr, prefix,
                resume_optimizer=True,
                map_location='default'):
 
         if map_location == 'default':
             if torch.cuda.is_available():
                 device_id = torch.cuda.current_device()
                 checkpoint = self.load_checkpoint(
                     resume, resume_mode,
-                    map_location=lambda storage, loc: storage.cuda(device_id))
+                    map_location=lambda storage, loc: storage.cuda(device_id), prefix=prefix)
             else:
-                checkpoint = self.load_checkpoint(resume, resume_mode)
+                checkpoint = self.load_checkpoint(resume, resume_mode, prefix=prefix)
         else:
             checkpoint = self.load_checkpoint(
-                resume, resume_mode, map_location=map_location)
+                resume, resume_mode, map_location=map_location, prefix=prefix)
 
         self._epoch = checkpoint['meta']['epoch']
         if self.opt_cfg['eval']:
-            self._max_epochs = self._epoch
+            self._max_epochs = self._epoch + 1
         self._iter = checkpoint['meta']['iter']
         if self.meta is None:
             self.meta = {}
         self.meta.setdefault('hook_msgs', {})
         # load `last_ckpt`, `best_score`, `best_ckpt`, etc. for hook messages
         self.meta['hook_msgs'].update(checkpoint['meta'].get('hook_msgs', {}))
 
@@ -394,48 +400,62 @@
             config = mmcv.Config.fromstring(
                 checkpoint['meta']['config'], file_format='.py')
             previous_gpu_ids = config.get('gpu_ids', None)
             if previous_gpu_ids and len(previous_gpu_ids) > 0 and len(
                     previous_gpu_ids) != self.world_size:
                 self._iter = int(self._iter * len(previous_gpu_ids) /
                                  self.world_size)
-                self.logger.info('the iteration number is changed due to '
-                                 'change of GPU number')
+                print_log('the iteration number is changed due to '
+                                 'change of GPU number', logger=self.logger)
 
         # resume meta information meta
         self.meta = checkpoint['meta']
         # if optimizer is not None:
         #     if checkpoint.get('optimizer') is not None:
         #         optimizer.load_state_dict(checkpoint['optimizer'])
         #
         #     if lr > 0 and reset_lr:
         #         for param_group in optimizer.param_groups:
         #             param_group['lr'] = lr
         #     print_log("loaded checkpoint.optimizer")
         if 'optimizer' in checkpoint and resume_optimizer:
             if isinstance(self.optimizer, Optimizer):
+                # self.optimizer.param_groups[0]['params'][0].mean()
+                # Out[14]: tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)
+                # Out[15]: tensor(-0.0046, device='cuda:0', grad_fn=<MeanBackward0>)
+                # checkpoint['optimizer']['param_groups'][0]['params'][0]
+                # 0
+                # param_sum = np.sum([param.sum().cpu().numpy() for _, v in
+                #                     checkpoint['optimizer']['state'].items() for param in list(v.values())])
                 self.optimizer.load_state_dict(checkpoint['optimizer'])
+                new_opt_param_groups = np.sum([param.cpu().detach().numpy().sum() for param in
+                                    self.optimizer.param_groups[0]['params']])
+                new_opt_state = np.sum([param.cpu().detach().numpy().sum() for _, v in
+                                    self.optimizer.state.items()  for param in list(v.values())])
+
+                # self.optimizer.param_groups.checkpoint['optimizer']['param_groups']
                 if lr > 0 and reset_lr:
                     for param_group in self.optimizer.param_groups:
                             param_group['lr'] = lr
-                    self.logger.info("loaded checkpoint.optimizer")
+                # values = [np.mean(v['exp_avg'].cpu().numpy()) for v in self.optimizer.state_dict()['param_groups']] #.items()
+                print_log(f"loaded checkpoint.optimizer, opt={new_opt_param_groups}, {new_opt_state}", logger=self.logger) #
             elif isinstance(self.optimizer, dict):
                 for k in self.optimizer.keys():
                     self.optimizer[k].load_state_dict(
                         checkpoint['optimizer'][k])
                 if lr > 0 and reset_lr:
                     for param_group in self.optimizer[k].param_groups:
                             param_group['lr'] = lr
-                    self.logger.info("loaded checkpoint.optimizer")
+                print_log("loaded checkpoint.optimizer.", logger=self.logger)
             else:
                 raise TypeError(
                     'Optimizer should be dict or torch.optim.Optimizer '
                     f'but got {type(self.optimizer)}')
 
-        self.logger.info('resumed epoch %d, iter %d', self.epoch, self.iter)
+        print_log(f'resumed epoch {self.epoch}, iter {self.iter}', logger=self.logger)
 
     def register_lr_hook(self, lr_config):
         if lr_config is None:
             return
         elif isinstance(lr_config, dict):
             assert 'policy' in lr_config
             policy_type = lr_config.pop('policy')
```

## udl_vis/mmcv/runner/checkpoint.py

```diff
@@ -33,15 +33,15 @@
             os.path.join(
                 os.getenv(ENV_XDG_CACHE_HOME, DEFAULT_CACHE_DIR), 'mmcv')))
 
     mkdir_or_exist(mmcv_home)
     return mmcv_home
 
 
-def load_state_dict(module, state_dict, strict=False, logger=None):
+def load_state_dict(module, state_dict, prefix='', strict=False, logger=None):
     """Load state_dict to a module.
 
     This method is modified from :meth:`torch.nn.Module.load_state_dict`.
     Default value for ``strict`` is set to ``False`` and the message for
     param mismatch will be shown even if strict is False.
 
     Args:
@@ -94,15 +94,15 @@
             module._load_from_state_dict(state_dict, prefix, local_metadata, True,
                                          all_missing_keys, unexpected_keys,
                                          err_msg)
             for name, child in module._modules.items():
                 if child is not None:
                     load(child, prefix + name + '.')
 
-    load(module)
+    load(module, prefix)
     load = None  # break load->load reference cycle
 
     # ignore "num_batches_tracked" of BN layers
     missing_keys = [
         key for key in all_missing_keys if 'num_batches_tracked' not in key
     ]
 
@@ -577,25 +577,26 @@
             # 第二个用于加载best模型, 因为best_k_models是个[[]],索引不方便
             best_k_models.append([epoch, metric, line[0]])
             best_fname.append(line[0])
             # best_k_models['epoch'].append(epoch)
             # best_k_models[indicator].append(float(v))
 
     if len(best_k_models) == 0:
-        msg = f"checkpoint in directory {OUT_DIR} don't exist or is empty"
+        msg = f"checkpoint in directory {OUT_DIR} is not right or empty"
         warnings.warn(msg)
 
     return best_k_models, best_fname
 
 
 def load_checkpoint(resume_mode,
                     work_dir,
                     model,
                     filename,
                     map_location=None,
+                    prefix='',
                     strict=False,
                     logger=None,
                     revise_keys=[(r'^module\.', '')]):
     """Load checkpoint from a file or URI.
 
     Args:
         model (Module): Module to load checkpoint.
@@ -612,35 +613,36 @@
             the prefix 'module.' by [(r'^module\\.', '')].
 
     Returns:
         dict or OrderedDict: The loaded checkpoint.
     """
     ################
     # 只从work_dir里读ckpt，用于模型的继续训练
-    resume_mode = resume_mode.lower()
-    if resume_mode == 'best':
-        _, best_k_fname = get_best_k_model(os.path.join(work_dir, "checkpoint"), None)
-        if len(best_k_fname) > 0:
-            best_k_model = sorted(best_k_fname)[-1]
-            filename = os.path.join(work_dir, best_k_model)
-        else:
-            print_log("loading best model failed, maybe it's from scratch currently.", logger=logger)
-
-    elif resume_mode == 'auto':
-        ckpt = get_last_checkpoint(work_dir)
-        if ckpt is not None:
-            filename = ckpt
-    ################
     if not os.path.isfile(filename):
-        print_log(f"no checkpoint found at {filename}", logger=logger)
-        return {'meta': {'epoch': 1,
-                         'iter': 1,
-                         'best_epoch': 1,
-                         'best_metric': None}}
-    ################
+        resume_mode = resume_mode.lower()
+        if resume_mode == 'best':
+            _, best_k_fname = get_best_k_model(os.path.join(work_dir, "checkpoint"), None)
+            if len(best_k_fname) > 0:
+                best_k_model = sorted(best_k_fname)[-1]
+                filename = os.path.join(work_dir, best_k_model, '.pth.tar')
+            else:
+                print_log("loading best model failed, maybe it's from scratch currently.", logger=logger)
+
+        elif resume_mode == 'auto':
+            ckpt = get_last_checkpoint(work_dir)
+            if ckpt is not None:
+                filename = ckpt
+        ################
+        if not os.path.isfile(filename):
+            print_log(f"no checkpoint found at {filename}", logger=logger)
+            return {'meta': {'epoch': 0,
+                             'iter': 0,
+                             'best_epoch': 0,
+                             'best_metric': None}}
+        ################
 
     checkpoint = _load_checkpoint(filename, map_location, logger)
     # OrderedDict is a subclass of dict
     if not isinstance(checkpoint, dict):
         raise RuntimeError(
             f'No state_dict found in checkpoint file {filename}')
 
@@ -662,15 +664,15 @@
             metadata = getattr(state_dict, '_metadata', OrderedDict())
             for p, r in revise_keys:
                 state_dict = OrderedDict(
                     {re.sub(p, r, k): v
                      for k, v in state_dict.items()})
             # Keep metadata in state_dict
             state_dict._metadata = metadata
-            load_state_dict(m, state_dict, strict, logger)
+            load_state_dict(m, state_dict, prefix, strict, logger)
     else:
         if 'model' in checkpoint:
             state_dict = checkpoint['model']
         elif 'state_dict' in checkpoint:
             state_dict = checkpoint['state_dict']
         else:
             state_dict = checkpoint
@@ -679,29 +681,29 @@
         metadata = getattr(state_dict, '_metadata', OrderedDict())
         for p, r in revise_keys:
             state_dict = OrderedDict(
                 {re.sub(p, r, k): v
                  for k, v in state_dict.items()})
         # Keep metadata in state_dict
         state_dict._metadata = metadata
-        load_state_dict(mod, state_dict, strict, logger)
+        load_state_dict(mod, state_dict, prefix, strict, logger)
         # if optimizer is not None:
         #     if checkpoint.get('optimizer') is not None:
         #         optimizer.load_state_dict(checkpoint['optimizer'])
         #
         #     if lr > 0 and reset_lr:
         #         for param_group in optimizer.param_groups:
         #             param_group['lr'] = lr
         #     print_log("loaded checkpoint.optimizer")
 
         # load state_dict
 
-        checkpoint['meta'].setdefault('epoch', 0) + 1
-        checkpoint['meta'].setdefault('iter', 0) + 1
-        checkpoint['meta'].setdefault('best_epoch', 0)
+        checkpoint['meta'].setdefault('epoch', 0) # checkpoint['meta']['epoch']  =
+        checkpoint['meta'].setdefault('iter', 0)  # checkpoint['meta']['iter']  =
+        checkpoint['meta'].setdefault('best_epoch', 0) #checkpoint['meta']['best_epoch']  =
         checkpoint['meta'].setdefault('best_metric', None)
 
     return checkpoint
 
 
 def weights_to_cpu(state_dict):
     """Copy a model state_dict to cpu.
```

## udl_vis/mmcv/runner/epoch_based_runner.py

```diff
@@ -64,23 +64,25 @@
         #     for name in self.model.keys():
         #         self.model[name].train()
 
         self.mode = 'train'
         self.data_loader = data_loader
         self._max_iters = self._max_epochs * len(self.data_loader)
         self.call_hook('before_train_epoch')
+        tic = time.time()
         time.sleep(2)  # Prevent possible deadlock during epoch transition
         for i, data_batch in enumerate(self.data_loader):
             self._inner_iter = i
             self.call_hook('before_train_iter')
             self.run_iter(data_batch, train_mode=True, **kwargs)
             self.call_hook('after_train_iter')
             self._iter += 1
-
+            # break
         self.metrics = {k: meter.avg for k, meter in self.log_buffer.meters.items()}
+        self.metrics.update(epoch_time=time.time() - tic)
         self.call_hook('after_train_epoch')
         self._epoch += 1
 
     def simple_train(self, data_loader, **kwargs):
         optimizer = self.optimizer
         accumulated_step = self.opt_cfg.get('accumulated_step', 1)
         grad_clip = self.opt_cfg.get('grad_clip', 0)
@@ -141,45 +143,48 @@
             # self.run_iter()
             metric_logger.update_dict(metrics)
         stats = {k: meter.avg for k, meter in metric_logger.meters.items()}
         if opt_cfg['mode'] == 'nni':
             self.nni.report_final_result({name: value for name, value in stats.items() if opt_cfg['metrics'] in name})
         # 仅进行验证时触发，结束while
         metric_logger.clear()
-        if not self.flag:
+        if not self.eval_flag:
             self._epoch += 1
+            self.eval_flag = True
 
     @torch.no_grad()
     def val(self, data_loader, **kwargs):
         kwargs['test_mode'] = False if not kwargs.get('test_mode', None) else True
         if hasattr(self.model, 'eval'):
             self.model.eval()
         elif isinstance(self.model.model, dict):
             for name in self.model.model.keys():
                 self.model.model[name].eval()
         else:
             self.model.model.eval()
-        self.mode = 'val'
+        self.mode = 'val' if not kwargs.get('test_mode', None) else 'test'
         self.data_loader = data_loader
         self.call_hook('before_val_epoch')
         time.sleep(2)  # Prevent possible deadlock during epoch transition
         tic = time.time()
         for i, data_batch in enumerate(self.data_loader):
             self._inner_iter = i
             self.call_hook('before_val_iter')
             self.run_iter(data_batch, train_mode=False, idx=i,
                           img_range=self.opt_cfg['img_range'], eval=self.opt_cfg['eval'],
                           save_fmt=self.opt_cfg['save_fmt'], filename=data_batch.get('filename', [None])[0], save_dir=self.save_dir,
                           **kwargs)
                           # val_mode=self.opt_cfg['val_mode'])
             self.call_hook('after_val_iter')
+            # break
         print("test time:", time.time() - tic)
         self.call_hook('after_val_epoch')
         if self.opt_cfg['eval']:
             self._epoch += 1
+            self.eval_flag = True
 
     @torch.no_grad()
     def test(self, data_loader, **kwargs):
         return self.val(data_loader, test_mode=True, **kwargs)
 
     def run(self, data_loaders, workflow, max_epochs=None, **kwargs):
         """Start running.
@@ -199,39 +204,39 @@
             warnings.warn(
                 'setting max_epochs in run is deprecated, '
                 'please set max_epochs in runner_config', DeprecationWarning)
             self._max_epochs = max_epochs
 
         assert self._max_epochs is not None, (
             'max_epochs must be specified during instantiation')
-        self.flag = any('train' in mode for mode, _ in workflow)
+        self.eval_flag = any('train' in mode for mode, _ in workflow)
         self.workflow = workflow
-        self.data_length = 1
+        self.data_length = {}
         for i, flow in enumerate(workflow):
             mode, epochs = flow
-            if mode == 'train':
-                self._max_iters = self._max_epochs * len(data_loaders[mode])
-                self.data_length = len(data_loaders[mode])
-                break
+            self.data_length[mode] = len(data_loaders[mode])
+        if 'train' in data_loaders.keys():
+            self._max_iters = self._max_epochs * len(data_loaders['train'])
+
 
 
         work_dir = self.work_dir if self.work_dir is not None else 'NONE'
         print_log(f'Start running, host: {get_host_info()}, work_dir: {work_dir}',
                   logger=self.logger)
         print_log(f'Hooks will be executed in the following order:\n{self.get_hook_info()}',
                   logger=self.logger)
         print_log(f'workflow: {workflow}, max: {self._max_epochs} epochs',
                   logger=self.logger)
         self.call_hook('before_run')
         tic = time.time()
-        print_freq = self.opt_cfg.get('print_freq', 1)
         # from 1 to self._max_epochs, not from 0
-        while self.epoch < self._max_epochs:
+        while self.epoch < self._max_epochs or not self.eval_flag:
             for i, flow in enumerate(workflow):
                 mode, epochs = flow
+
                 if isinstance(mode, str):  # self.train()
                     if not hasattr(self, mode):
                         raise ValueError(
                             f'runner has no method named "{mode}" to run an '
                             'epoch')
                     epoch_runner = getattr(self, mode)
                 else:
@@ -248,14 +253,15 @@
                 break
         time.sleep(1)  # wait for some hooks like loggers to finish
         self.call_hook('after_run')
         total_time = time.time() - tic
         total_time_str = str(datetime.timedelta(seconds=int(total_time)))
         print_log('Training time {}'.format(total_time_str), logger=self.logger)
 
+
     def save_checkpoint(self,
                         out_dir,
                         filename_tmpl='epoch_{}.pth',
                         save_optimizer=True,
                         meta=None,
                         create_symlink=True):
         """Save the checkpoint.
```

## udl_vis/mmcv/runner/hooks/checkpoint.py

```diff
@@ -8,14 +8,15 @@
 from math import inf
 import os
 import re
 from ..checkpoint import save_checkpoint, get_best_k_model
 import platform
 from udl_vis import mmcv
 import shutil
+import numpy as np
 
 @HOOKS.register_module()
 class CheckpointHook(Hook):
     """Save checkpoints periodically.
 
     Args:
         interval (int): The saving period. If ``by_epoch=True``, interval
@@ -169,28 +170,27 @@
             print_log(
                 f'Saving checkpoint at {runner.iter + 1} iterations', logger=runner.logger)
             if self.sync_buffer:
                 allreduce_params(runner.model.buffers())
             self._save_checkpoint(runner)
 
 
-
 @HOOKS.register_module()
 class ModelCheckpoint(Hook):
-
     rule_map = {'greater': lambda x, y: x >= y, 'less': lambda x, y: x <= y}
     indicator_rule_map = {'greater': lambda x, y: max(x, y), 'less': lambda x, y: min(x, y)}
     _default_greater_keys = [
         'acc', 'top', 'AR@', 'auc', 'precision', 'mAP', 'mDice', 'mIoU',
         'mAcc', 'aAcc', 'psnr', 'ssim', 'q'
     ]
     _default_best_prec1 = {'greater': -inf, 'less': inf}
     _default_less_keys = ['loss', 'sam', 'ergas']
 
-    def __init__(self, indicator: str, formatter_filename="model_best_{epoch},{best_metric}", save_interval=1, save_top_k: int=1,
+    def __init__(self, indicator: str, formatter_filename="model_best_{epoch},{best_metric}", save_interval=1,
+                 save_top_k: int = 1,
                  greater_keys=None, less_keys=None, best_prec1=None, best_epoch=0, sync_buffer=False):
         '''
         Args:
             save_interval:
             save_top_k: ``save_top_k == k``,
                         if ``save_top_k == 0``, no models are saved.
                         if ``save_top_k == -1``, all models are saved.
@@ -241,25 +241,23 @@
 
     def before_run(self, runner):
         self.save_model_path = runner.work_dir
         self.ckpt = os.path.join(self.save_model_path, 'checkpoint')
         os.makedirs(self.save_model_path, exist_ok=True)
         print_log(f'Checkpoints will be saved to {self.save_model_path}', logger=runner.logger)
 
-
     def earlyStopping(self, avg_grad_norm):
 
         if avg_grad_norm > 100:
             return True
 
-
     def after_train_epoch(self, runner):
         if self.sync_buffer:
             allreduce_params(runner.model.buffers())
-        metrics = runner.metrics# metrics = {k: meter.avg for k, meter in runner.log_buffer.meters.items()}
+        metrics = runner.metrics  # metrics = {k: meter.avg for k, meter in runner.log_buffer.meters.items()}
         runner.earlyStop = self.earlyStopping(metrics.get('grad_norm', 0))
         self.save_checkpoint(runner, metrics)
 
         # print_log(' * Best training metrics so far@ {best_metric} in epoch {best_epoch}'.format(
         #     best_metric=metrics['best_metric'], best_epoch=metrics['best_epoch']), logger=runner.logger)
 
     def _save_checkpoint(self, meta, out_dir, filename, is_best, create_symlink=True):
@@ -268,54 +266,62 @@
         elif not isinstance(meta, dict):
             raise TypeError(
                 f'meta should be a dict or None, but got {type(meta)}')
         # meta.update(epoch=meta.pop('epoch') + 1, iter=meta.pop('iter'))
         filepath = os.path.join(out_dir, filename)
         # save_checkpoint(meta.pop('model'), filepath, optimizer=meta.pop('optimizer'), meta=meta)
         save_checkpoint(filepath, meta=meta)
-        if create_symlink or is_best:
-            dst_file = os.path.join(out_dir, 'model_best_.pth')
+        if create_symlink and is_best:
+            dst_file = os.path.join(out_dir, f'model_best_{filename}')
             if platform.system() != 'Windows':
                 mmcv.symlink(filename, dst_file)
             else:
                 shutil.copy(filepath, dst_file)
 
     @master_only
     def save_checkpoint(self, runner, metrics):
         flag = False
+        epoch =  runner.epoch + 1
+        iter = runner.iter + 1
         if not hasattr(runner.model, 'train') and isinstance(runner.model.model, dict):
             flag = True
             stats = {}
             for k, m in runner.model.model.items():
                 stats[k] = {
-                    'epoch': runner.epoch,
-                    'iter': runner.iter,
+                    'epoch': epoch,
+                    'iter': iter,
                     'model': m,
                     'best_metric': {name: value for name, value in metrics.items() if
                                     name not in ['grad_norm', 'lr', 'time', 'data_time']},
                     # 保存多个metric的数值,  实际比较的时候还是只有一个
                     'loss': metrics['loss'],
-                    'best_epoch': runner._epoch,
-                    'optimizer': runner.optimizer[k]
+                    'best_epoch': epoch,
+                    'optimizer': runner.optimizer[k],
+                    'seed': runner.seed
                 }
                 runner.metrics.update(
                     {'best_metric': {k: stats[k]['best_metric']}, 'best_epoch': {k: stats[k]['best_epoch']}})
         else:
             stats = {
-                'epoch': runner.epoch,
-                'iter': runner.iter,
+                'epoch': epoch,
+                'iter': iter,
                 'model': runner.model,
                 'best_metric': {name: value for name, value in metrics.items() if
                                 name not in ['grad_norm', 'lr', 'time', 'data_time']},
                 # 保存多个metric的数值,  实际比较的时候还是只有一个
                 'loss': metrics['loss'],
-                'best_epoch': runner._epoch,
-                'optimizer': runner.optimizer
+                'best_epoch': epoch,
+                'optimizer': runner.optimizer,
+                'seed': runner.seed
             }
             runner.metrics.update(best_metric=stats['best_metric'], best_epoch=stats['best_epoch'])
+        # runner.optimizer.param_groups[0]['params'][0].mean()
+        # Out[2]: tensor(0.0015, device='cuda:0', grad_fn= < MeanBackward0 >)
+        # runner.optimizer.param_groups[0]['params'][1].mean()
+        # Out[3]: tensor(-0.0080, device='cuda:0', grad_fn= < MeanBackward0 >)
 
         new_best_k_model_flag = []
         indicator = self.indicator
         save_top_k = self.save_top_k
         # stats 应当是{epoch: X, score: Y} -> [epoch, score]
         assert isinstance(stats, dict), print(f"stats in model_checkpoint should be dict but be {type(stats)}")
         # stats = list(stats.values())
@@ -323,15 +329,15 @@
 
         # print(best_k_model)
         if save_top_k < 0:
             raise ValueError(f"Invalid value for save_top_k={save_top_k}. Must be >= 0")
         if save_top_k == 0:
             stats['best_metric'] = self._default_best_prec1[self.rule]
             stats['best_epoch'] = 0
-            self._save_checkpoint(stats, self.save_model_path, is_best=False, filename=f"{stats['epoch']}.pth.tar")
+            self._save_checkpoint(stats, self.save_model_path, is_best=False, filename=f"{epoch}.pth.tar")
 
         if save_top_k >= 1:
             # self.best_prec1 = self.indicator_func(self.best_prec1, stats[self.indicator])
             if len(best_k_model) >= save_top_k:
                 # reverse=True, 降序, default： False
                 # 使用索引去对best_k_model进行排序,best_k_model应是列表，才能返回索引
                 best_k_model.append([stats['epoch'], stats['best_metric'], None])
@@ -353,15 +359,15 @@
                     if new_best_k_model_flag[index]:
                         # top_k_count += 1
                         # best_k_model[indicator][index] = stats[indicator]
                         # best_k_model['epoch'][index] = stats['epoch']
                         # best_k_model.pop(str(index))
                         # best_k_model.update(ckpt_stats)
                         # best_k_model[index] = list(ckpt_stats.popitem())
-                        fname = self.save_model_path + "/" + best_k_model[index][2]
+                        fname = self.save_model_path + "/" + best_k_model[index][2] + '.pth.tar'
                         ckpt_stats.append(None)
                         best_k_model[index] = ckpt_stats
 
                         if os.path.isfile(fname):
                             os.remove(fname)
                         break
                 stats['best_epoch'], stats['best_metric'] = best_k_model[sortedIndex_best_k_model[-1]][:2]
@@ -380,15 +386,15 @@
                 # if save_top_k == 1:
                 # if len(best_k_model) < save_top_k:
                 #     new_best_k_model_flag = [True]
 
             is_best = any(new_best_k_model_flag)
             if runner.epoch % self.save_interval == 0 or is_best:
                 self._save_checkpoint(
-                        stats, out_dir=self.save_model_path, is_best=is_best, filename=f"{runner.epoch}.pth.tar")
+                    stats, out_dir=self.save_model_path, is_best=is_best, filename=f"{epoch}.pth.tar")
 
                 if not flag:
                     print_log(' * Best training metrics so far@ {best_metric} in epoch {best_epoch}'.format(
                         best_metric=stats['best_metric'], best_epoch=stats['best_epoch']), logger=runner.logger
                     )
 
             return stats
@@ -397,13 +403,7 @@
         if hasattr(runner.model, 'train'):
             if type(runner.model.module.model).__name__ == 'INN':
                 runner.model.module.model.free()
         else:
             if isinstance(runner.model.model, dict):
                 runner.model.model['PAN2MS'].module.free()
     # raise NotImplementedError("after_train_iter is not implemented by ModelCheckpoint (customed)")
-
-
-
-
-
-
```

## udl_vis/mmcv/runner/hooks/hook.py

```diff
@@ -58,15 +58,16 @@
     def every_n_inner_iters(self, runner, n):
         return (runner.inner_iter + 1) % n == 0 if n > 0 else False
 
     def every_n_iters(self, runner, n):
         return (runner.iter + 1) % n == 0 if n > 0 else False
 
     def end_of_n_inner_iters(self, runner):
-        return runner.inner_iter + 1 == len(runner.data_loader)
+        self.status_end_of_n_inner_iters  = runner.inner_iter + 1 == len(runner.data_loader)
+        return self.status_end_of_n_inner_iters
 
     def is_last_epoch(self, runner):
         return runner.epoch + 1 == runner._max_epochs
 
     def is_last_iter(self, runner):
         return runner.iter + 1 == runner._max_iters
```

## udl_vis/mmcv/runner/hooks/logger/base.py

```diff
@@ -55,32 +55,37 @@
         elif include_torch and isinstance(val, torch.Tensor) and len(val) == 1:
             return True
         else:
             return False
 
     def get_mode(self, runner):
         if runner.mode == 'train':
-            if 'time' in runner.log_buffer.meters: #output
-                mode = 'train'
-            else:
-                mode = 'val'
+            mode = 'train'
+            # if 'time' in runner.log_buffer.meters: #output
+            #     mode = 'train'
+            # else:
+            #     mode = 'val'
         elif runner.mode == 'val':
             mode = 'val'
+        elif runner.mode == 'test':
+            mode = 'test'
         else:
-            raise ValueError(f"runner mode should be 'train' or 'val', "
+            raise ValueError(f"runner mode should be 'train' or 'val' or 'test', "
                              f'but got {runner.mode}')
         return mode
 
     def get_epoch(self, runner):
         if runner.mode == 'train':
-            epoch = runner.epoch# + 1
+            epoch = runner.epoch + 1
         elif runner.mode == 'val':
             # normal val mode
             # runner.epoch += 1 has been done before val workflow
-            epoch = runner.epoch
+            epoch = runner.epoch + 1
+        elif runner.mode == 'test':
+            epoch = runner.epoch + 1
         else:
             raise ValueError(f"runner mode should be 'train' or 'val', "
                              f'but got {runner.mode}')
         return epoch
 
     def get_iter(self, runner, inner_iter=False):
         """Get the current training iteration step."""
```

## udl_vis/mmcv/runner/hooks/logger/text.py

```diff
@@ -1,21 +1,22 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import datetime
 import os
 import os.path as osp
 from collections import OrderedDict
 
+import numpy as np
 import torch
 import torch.distributed as dist
 
 from udl_vis import mmcv
 from udl_vis.mmcv.fileio.file_client import FileClient
 from udl_vis.mmcv.utils import is_tuple_of, scandir
-from ..hook import HOOKS
-from .base import LoggerHook
+from udl_vis.mmcv.runner.hooks.hook import HOOKS
+from udl_vis.mmcv.runner.hooks.logger.base import LoggerHook
 from udl_vis.mmcv.utils.logging import print_log
 
 
 @HOOKS.register_module()
 class TextLoggerHook(LoggerHook):
     """Logger hook in text.
 
@@ -52,26 +53,29 @@
             Default: None.
             `New in version 1.3.16.`
     """
 
     def __init__(self,
                  by_epoch=True,
                  interval=10,
+                 use_json=False,
                  ignore_last=True,
                  reset_flag=False,
                  interval_exp_name=1000,
                  out_dir=None,
                  out_suffix=('.log.json', '.log', '.py'),
                  keep_local=True,
                  file_client_args=None):
         super(TextLoggerHook, self).__init__(interval, ignore_last, reset_flag,
                                              by_epoch)
         self.by_epoch = by_epoch
         self.time_sec_tot = 0
         self.interval_exp_name = interval_exp_name
+        self.use_json = use_json
+        self.status_end_of_n_inner_iters = False
 
         if out_dir is None and file_client_args is not None:
             raise ValueError(
                 'file_client_args should be "None" when `out_dir` is not'
                 'specified.')
         self.out_dir = out_dir
 
@@ -102,15 +106,15 @@
                  f'{self.file_client.name} after the training process.'), logger=runner.logger)
 
         self.start_iter = runner.iter
         self.data_length = runner.data_length
         self.max_epochs = runner.max_epochs
         self.json_log_path = osp.join(runner.work_dir,
                                       f'{runner.timestamp}.log.json')
-        if runner.meta is not None:
+        if runner.meta is not None and runner.logger is not None and self.use_json:
             self._dump_log(runner.meta, runner)
 
     def _get_max_memory(self, runner):
         device = getattr(runner.model, 'output_device', None)
         mem = torch.cuda.max_memory_allocated(device=device)
         mem_mb = torch.tensor([mem / (1024 * 1024)],
                               dtype=torch.int,
@@ -136,16 +140,16 @@
                 lr_str = ' '.join(lr_str)
             else:
                 lr_str = f'lr: {log_dict["lr"]:.3e}'
 
             # by epoch: Epoch [4][100/1000]
             # by iter:  Iter [100/100000]
             if self.by_epoch:
-                log_str = f'Epoch [{log_dict["epoch"]}]/[{self.max_epochs}]' \
-                          f'[{log_dict["iter"]}/{self.data_length}]\t'
+                log_str = f'Iter [{log_dict["iter"]}] Epoch [{log_dict["epoch"]}/{self.max_epochs}]' \
+                          f'[{log_dict["inner_iter"]}/{self.data_length["train"]}]\t'
             else:
                 log_str = f'Iter [{log_dict["iter"]}/{runner.max_iters}]\t'
             log_str += f'{lr_str}, '
 
             if 'time' in log_dict.keys():
                 self.time_sec_tot += (log_dict['time'] * self.interval)
                 time_sec_avg = self.time_sec_tot / (
@@ -154,32 +158,39 @@
                 eta_str = str(datetime.timedelta(seconds=int(eta_sec)))
                 log_str += f'eta: {eta_str}, '
                 log_str += f'time: {log_dict["time"]:.3f}, ' \
                            f'data_time: {log_dict["data_time"]:.3f}, '
                 # statistic memory
                 if torch.cuda.is_available():
                     log_str += f'memory: {log_dict["memory"]}MB, '
+                if self.status_end_of_n_inner_iters:
+                    new_opt_param_groups = np.sum([param.cpu().detach().numpy().sum() for param in
+                                        runner.optimizer.param_groups[0]['params']])
+                    new_opt_state = np.sum([param.cpu().detach().numpy().sum() for _, v in
+                                        runner.optimizer.state.items()  for param in list(v.values())])
+                    log_str += f"opt_param_groups: {new_opt_param_groups}, opt_state: {new_opt_state} "
         else:
             # val/test time
             # here 1000 is the length of the val dataloader
             # by epoch: Epoch[val] [4][1000]
             # by iter: Iter[val] [1000]
             if self.by_epoch:
-                log_str = f'Epoch({log_dict["mode"]}) ' \
-                    f'[{log_dict["epoch"]}][{log_dict["iter"]}]\t'
+                log_str = f'Iter [{log_dict["iter"]}] Epoch({log_dict["mode"]}) ' \
+                          f'[{log_dict["epoch"]}]/[{self.max_epochs}]\t' \
+                          f'[{log_dict["inner_iter"]}/{self.data_length[log_dict["mode"]]}]\t'
             else:
                 log_str = f'Iter({log_dict["mode"]}) [{log_dict["iter"]}]\t'
 
         log_items = []
         for name, val in log_dict.items():
             # TODO: resolve this hack
             # these items have been in log_str
             if name in [
                     'mode', 'Epoch', 'iter', 'lr', 'time', 'data_time',
-                    'memory', 'epoch'
+                    'memory', 'epoch', 'inner_iter'
             ]:
                 continue
             if isinstance(val, float):
                 val = f'{val:.5f}'
             log_items.append(f'{name}: {val}')
         log_str += ', '.join(log_items)
         print_log(log_str, logger=runner.logger)
@@ -209,15 +220,16 @@
             cur_iter = runner.log_buffer.meters.pop('eval_iter_num') #output
         else:
             cur_iter = self.get_iter(runner, inner_iter=True)
 
         log_dict = OrderedDict(
             mode=self.get_mode(runner),
             epoch=self.get_epoch(runner),
-            iter=cur_iter)
+            inner_iter=cur_iter,
+            iter=self.get_iter(runner))
 
         # only record lr of the first param group
         cur_lr = runner.current_lr()
         if isinstance(cur_lr, list):
             log_dict['lr'] = cur_lr[0]
         else:
             assert isinstance(cur_lr, dict)
@@ -229,17 +241,22 @@
         if 'time' in runner.log_buffer.meters:#output
             # statistic memory
             if torch.cuda.is_available():
                 log_dict['memory'] = self._get_max_memory(runner)
 
         runner.metrics = {k: meter.avg for k, meter in runner.log_buffer.meters.items()}
         log_dict = dict(log_dict, **runner.metrics) #output
+        if self.status_end_of_n_inner_iters:
+            values = [np.mean(v['exp_avg'].cpu().numpy()) for k, v in runner.optimizer.state_dict()['state'].items()]
+            log_dict.update(opt=np.mean(values))
+
 
         self._log_info(log_dict, runner)
-        self._dump_log(log_dict, runner)
+        if self.use_json and runner.logger is not None:
+            self._dump_log(log_dict, runner)
         return log_dict
 
     def after_run(self, runner):
         # copy or upload logs to self.out_dir
         if self.out_dir is not None:
             for filename in scandir(runner.work_dir, self.out_suffix, True):
                 local_filepath = osp.join(runner.work_dir, filename)
```

## udl_vis/mmcv/utils/logging.py

```diff
@@ -273,20 +273,21 @@
     if cfg.eval:
         model_save_tmp = os.path.dirname(cfg.resume_from).split('/')[-1]
     else:
         model_save_tmp = "model_{}".format(time_str)
 
     model_save_dir = final_output_dir / model_save_tmp
     # if not dist_print:
-    print_log('=> creating {}'.format(final_output_dir))
-    final_output_dir.mkdir(parents=True, exist_ok=True)
-    model_save_dir.mkdir(parents=True, exist_ok=True)
 
 
-    if cfg.use_log:
+    if cfg.use_log_and_save:
+        print_log('=> creating {}'.format(final_output_dir))
+        final_output_dir.mkdir(parents=True, exist_ok=True)
+        model_save_dir.mkdir(parents=True, exist_ok=True)
+
         cfg_name = '{}_{}'.format(cfg_name, time_str)
         # a logger to save results
         log_file = '{}_{}.log'.format(cfg_name, phase)
         if cfg.eval:
             final_log_file = model_save_dir / log_file
         else:
             final_log_file = final_output_dir / log_file
```

## Comparing `udl_vis-0.3.2.dist-info/LICENSE` & `udl_vis-0.3.3.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `udl_vis-0.3.2.dist-info/METADATA` & `udl_vis-0.3.3.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: udl-vis
-Version: 0.3.2
+Version: 0.3.3
 Summary: unified pytorch framework for vision task
 Home-page: https://github.com/XiaoXiao-Woo/PanCollection
 Author: XiaoXiao-Woo
 Author-email: wxwsx1997@gmail.com
 License: GPLv3
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
```

## Comparing `udl_vis-0.3.2.dist-info/RECORD` & `udl_vis-0.3.3.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 udl_vis/__init__.py,sha256=jPqedAPKI8MRMSK8o-F-9WuCAgsfZ5AFg4cUBj6x1zU,250
 udl_vis/AutoDL/__init__.py,sha256=ovguP4wzQEDNguczwiZnhMm4dRRVcvnzmHrfQtlRCNQ,15
-udl_vis/AutoDL/trainer.py,sha256=EtMxuj9occEWrrq5tIK2oFyJdeMA4mm7Vh4PudZVUrk,13800
+udl_vis/AutoDL/trainer.py,sha256=UQRZ8oiPuGAMT3TV9VUm7heNBxTx8BGkBlSAZhPvstk,13858
 udl_vis/Basis/__init__.py,sha256=ovguP4wzQEDNguczwiZnhMm4dRRVcvnzmHrfQtlRCNQ,15
 udl_vis/Basis/cal_ssim.py,sha256=BuPhoTypDOPaxaZiz0tJvKZoGk5UTIgA35EuIk98EYY,2851
 udl_vis/Basis/config.py,sha256=R1R663Oe9eWtUgaEI2X7WBw3vJDXWyMWmBTdnsC7RK8,29004
 udl_vis/Basis/criterion_metrics.py,sha256=hNLNcvsmO1AUwyB9kI5G_pxEMpjz-1K38RUHARL0EP0,4087
 udl_vis/Basis/dist_utils.py,sha256=hFoog343eLiQI9sLm7LUVdDWxoklcQxUjIVC_XjS4gg,6622
 udl_vis/Basis/launch.py,sha256=zd8AuWJzRbXS3BF9p2K8sHv-i69M2o6-4Edi0m-KNFg,14882
 udl_vis/Basis/logger.py,sha256=R3NWWdxPm_QnRn9SuTsILyG63C_fcpkjHDUhwUf8j5s,8754
 udl_vis/Basis/metrics.py,sha256=Fg8wV8p0rrLN7HQ24BrkxaE7xUXMOORPIbdUaQDcE8Q,3145
-udl_vis/Basis/module.py,sha256=ezXBWuXK9UlwtWP0MNKINXg2Mj58823olRbbqFpUN2E,16848
+udl_vis/Basis/module.py,sha256=gip797wlrR7rEpCHznAlAIkokNmqA82QHD2MeuTj76Y,16806
 udl_vis/Basis/optim.py,sha256=2dypTCovd1xV7eIaHpFz2fepERPploatT0ZLvu5TOvE,9926
-udl_vis/Basis/option.py,sha256=t7RTGMpcK9WmVSlTBUJti_thFYo10lJ-rxACbnQX_VU,6233
+udl_vis/Basis/option.py,sha256=OpfHUp5Hqmqy2UpiUCcluO0EsxoL7FsDNDJ14IgvWCQ,6270
 udl_vis/Basis/postprocess.py,sha256=-A7YPKsTHI4xlL-6fzfl1Ws6xgrvv3zD9mo1loIQ43o,17306
 udl_vis/Basis/python_sub_class.py,sha256=rRV5ZSKy7BILVBclYasFs9d6_1PvGrPF4E3XcfQMtis,5187
 udl_vis/Basis/variance_sacling_initializer.py,sha256=Ub0HTUQsjkjMI1rse2uUSrp0l0UmvJX1JMxaco7DfkE,3145
 udl_vis/Basis/auxiliary/__init__.py,sha256=N7S6PyM1oUxq90HraUHPVaywibZ08YTzucpz-OHTh8U,134
 udl_vis/Basis/auxiliary/base.py,sha256=wCkUqLKhi8tiDEeAikt4EJrZuthnCPwvgEZW2HCr-G4,1084
 udl_vis/Basis/auxiliary/fp16_utils.py,sha256=IJ6iVgq_N5expZz7mO609bfPJQ9I5koEZfSc39xhEEk,7303
 udl_vis/Basis/auxiliary/utils.py,sha256=of_TyTV-yi0vH7T9mkG0mXwYM8yb6XWLaeP_oNb4HE8,11956
@@ -145,64 +145,64 @@
 udl_vis/mmcv/parallel/distributed.py,sha256=ByVq79hUJj8ic1f56IQM1PzncsbJI12b6GdpzmHdJCE,4945
 udl_vis/mmcv/parallel/distributed_deprecated.py,sha256=KWgCZMwzoroaoV5YecUpOCf6_ubPMvt9Ve5giT3wdbk,2887
 udl_vis/mmcv/parallel/registry.py,sha256=AxyS-c-pCPJ7-bRiKxz_8oJ1k7z5mQpw6XuvHgmOVV4,328
 udl_vis/mmcv/parallel/scatter_gather.py,sha256=AxxkS6uq-2c0_8k4lRtRxv0Bix9eKO-Bpsb0V3aXCPk,2366
 udl_vis/mmcv/parallel/utils.py,sha256=wg6-rhJqFl3-NaU5vMw9CG5UBxcuOr4aJMlBBG1D0Dk,728
 udl_vis/mmcv/runner/__init__.py,sha256=sxC4fyVcxZjiHLL3_5EcvDywM1cXjNoU3ZlG6G_ti9I,4385
 udl_vis/mmcv/runner/base_module.py,sha256=pajuXr-sZz5J046chHyn8khrSS1vg4PuV2TQ82GK69Q,14570
-udl_vis/mmcv/runner/base_runner.py,sha256=4Uq56-6mLXLv3NRp8YJjHNog_2OJftnMy1jM0SU5spA,22884
+udl_vis/mmcv/runner/base_runner.py,sha256=dYr5XLbxQ-XDhZymOdDE6jhMcMYltXdL38jM3mM7Poc,24419
 udl_vis/mmcv/runner/builder.py,sha256=yEp9ctE7Kw4gbGbY2Yf88Yc48RrZQLM-cR0WGkYgKyk,690
-udl_vis/mmcv/runner/checkpoint.py,sha256=KKrcyqQHT1x01GzvyOdSgXvylpB4i9Uz9v9Kq-HAPE0,33627
+udl_vis/mmcv/runner/checkpoint.py,sha256=62Tf8jESUYTY7JVAC3PtmgUKjRDLXETntXOfluce4kY,33917
 udl_vis/mmcv/runner/default_constructor.py,sha256=b6edxh4NotRdYNdqZ9a0NE5KKInXSvvbzqLyi6PPazw,1952
 udl_vis/mmcv/runner/dist_utils.py,sha256=56RURtqjEHSH7Nh933b53cg0T4mAzXv6yF8vFq4NRgY,5559
-udl_vis/mmcv/runner/epoch_based_runner.py,sha256=wF1OMOE6v6fX0-Zx1Pzcf4lCKjXEATS7y57lVMljr00,13951
+udl_vis/mmcv/runner/epoch_based_runner.py,sha256=Ej-fjoFO3QHRIuPn4_m6RiUQ7tD3uxkPYUOw2l8gZHM,14168
 udl_vis/mmcv/runner/fp16_utils.py,sha256=nO36ezgpKzcewM4hSTxXbPihhO8w2xrGMne4bV-vrX0,16873
 udl_vis/mmcv/runner/iter_based_runner.py,sha256=x7ZtmX04mhrENaO9Hz7I_xlkweYYswTAQejDZFMf49Y,11438
 udl_vis/mmcv/runner/log_buffer.py,sha256=zdjg0Aphh9zJgNScEiauGpgR-u5bGRubuXYwoQ2Vk1E,1880
 udl_vis/mmcv/runner/misc.py,sha256=U7MPrB1srnbVPupNxVw34yOn93_k5TeYJmCnSd7mll4,1241
 udl_vis/mmcv/runner/priority.py,sha256=G8CBRfmUWlIp2zAP9twjEjlMlos98_6OAXG5KHOXB30,1658
 udl_vis/mmcv/runner/record.py,sha256=Bdr0_9NMZm_suWVvY2xgCGRq0PZ1oBiGJPNu4Q1xLLk,11169
 udl_vis/mmcv/runner/utils.py,sha256=FaOBbQlCBbH8ms24YXTmg5PX02KgOaUfKOSSokRkCGc,3014
 udl_vis/mmcv/runner/hooks/__init__.py,sha256=wGiPEb1jNBOH4QJCX-mNszEbEM6n9HVjef2EVQnwS_A,2402
-udl_vis/mmcv/runner/hooks/checkpoint.py,sha256=7fLwNNKtRussvbV1dOxJEYM-WIscYDeHp-eZuUN4dso,18955
+udl_vis/mmcv/runner/hooks/checkpoint.py,sha256=KyBk3ONbx3ITlcEV0DafXdykP-3ERTkk1-GjLmf9PGw,19368
 udl_vis/mmcv/runner/hooks/closure.py,sha256=-cC2C-FdrLroTtckeUsmRN5ylZIhyD8JrKo3cqtOhac,280
 udl_vis/mmcv/runner/hooks/ema.py,sha256=V-RiL_Qg2yTRKapcSN1ymHid1vsQMq-GWh3l-jPoOBg,3674
 udl_vis/mmcv/runner/hooks/evaluation.py,sha256=G-5wezy_DZ0hfZptCn-HtI_99N5uKsCM7dw_9bSUlKc,22917
-udl_vis/mmcv/runner/hooks/hook.py,sha256=ebhRTZAQd9Z-7O2f12gklDrLYHprypoh-o6UgtpB9DU,2849
+udl_vis/mmcv/runner/hooks/hook.py,sha256=cI-XTMtGvRCyOLb5FcFsPVWBI07Gxq9xjKxTKoKRsdo,2927
 udl_vis/mmcv/runner/hooks/iter_timer.py,sha256=BGIOgNW-v8-a5KCdSX_HIeZgH5Kcq_-mReIcGEDFCQ8,521
 udl_vis/mmcv/runner/hooks/lr_updater.py,sha256=gi05MgmVkuzLi-EcteByzbsf7p70aoLeSYbRPkOq9Hw,27815
 udl_vis/mmcv/runner/hooks/memory.py,sha256=ynvJeHEHlELy_mQRgo0JEInQhULP7t5JCHNjNwfwMzY,682
 udl_vis/mmcv/runner/hooks/momentum_updater.py,sha256=BO1gfg6BLPTg34CN1Ck-ZUCn_UOqxLQknnijI-mYDRA,23465
 udl_vis/mmcv/runner/hooks/nni_hook.py,sha256=tby26kxtSPTHrmdDlSZVZBHFZGVwRcl3GMKm8_HGmIU,1602
 udl_vis/mmcv/runner/hooks/optimizer.py,sha256=arP82gGwku17ihDsnwnfIsifuMPAPS8B5jUVwAl7KcY,25296
 udl_vis/mmcv/runner/hooks/profiler.py,sha256=sLZk1hUYzB5t0m4U5UvZcnu8AEpMxTeWOwP9ICswj0s,8221
 udl_vis/mmcv/runner/hooks/sampler_seed.py,sha256=MU4haFBYJUBNxGLe5GTzVO4BZqhX-nDDzHPbvqrqXZM,867
 udl_vis/mmcv/runner/hooks/sync_buffer.py,sha256=eHxJGlwXWm_h-hoVe-6UvVmkXlyobwc1TsMjl9tAGSM,729
 udl_vis/mmcv/runner/hooks/logger/__init__.py,sha256=UaUE-IAETUKskXuwqhUg1B8Q26lpEw8siktBtqsn-l0,537
-udl_vis/mmcv/runner/hooks/logger/base.py,sha256=V2_De12ZaTYtP7-HchvaMl9yk8WYNdsNSUkYxKwhVxM,6222
+udl_vis/mmcv/runner/hooks/logger/base.py,sha256=ygbLXlvqW2siQA4nptd79eYKpWZ5A0Z6_VAY8EhBTc0,6410
 udl_vis/mmcv/runner/hooks/logger/dvclive.py,sha256=vuaeGoKtBwF_1rLe7a1iOcNQRwyOkDCyol25ceC5xu4,2294
 udl_vis/mmcv/runner/hooks/logger/mlflow.py,sha256=TlCsfS2P1OXjqdKq4m9ukjwEpYLlHkVB9c-I2e4CTFE,2995
 udl_vis/mmcv/runner/hooks/logger/neptune.py,sha256=1iaIiZ_M2GcJ-u9EOQvZUnOR0qKzZ-C4aTEgKnqiBXs,3338
 udl_vis/mmcv/runner/hooks/logger/pavi.py,sha256=pyF8bLp2GxhwoFqEaVEUJNCJ5x59bQEU4mYr5nQeb9Q,5269
 udl_vis/mmcv/runner/hooks/logger/tensorboard.py,sha256=UGJxaQPs85CIoZu6E0cWNoLLc2LLv6xoCuapYlXfLV4,2739
-udl_vis/mmcv/runner/hooks/logger/text.py,sha256=hxUZXGJsU3s0rdw29TZDN_4XtFNrTCixQCsT-eWyYWM,11234
+udl_vis/mmcv/runner/hooks/logger/text.py,sha256=C5Q9cjs2bjDE8F5aKtKzMZsS2lq276o1PpkaYZMu8pI,12526
 udl_vis/mmcv/runner/hooks/logger/wandb.py,sha256=Iq4605_B0qF7jnDOpbTjxA6qQdMOv-oScqt4G2nc_1Y,4009
 udl_vis/mmcv/runner/optimizer/__init__.py,sha256=KQgKnlQvYl2GyC-SvJBG4921AYnR9KQGN0DdbCdF1CE,379
 udl_vis/mmcv/runner/optimizer/builder.py,sha256=AzEYtI2qddTJsDPf6tSibjujq6rr7ab10LnQYiPlPH8,1390
 udl_vis/mmcv/runner/optimizer/default_constructor.py,sha256=FuqUgtUi8v4WkFndf3MXlihycrKIUP0t1qq2J2X7pqE,11971
 udl_vis/mmcv/tensorrt/__init__.py,sha256=-Z0RXE8vJJV2soQ5RqnWno1OEs61oZJqWEYl8ys61UM,788
 udl_vis/mmcv/tensorrt/init_plugins.py,sha256=miTA83z2oemLK6TPnh8pPpiwmDQhsF6ET5GCRaWaWHw,916
 udl_vis/mmcv/tensorrt/preprocess.py,sha256=U_ozP91sK7VUqdzxnwx3eWtr8hduuh-FGoSHOMzsWiM,4459
 udl_vis/mmcv/tensorrt/tensorrt_utils.py,sha256=k1H7ciwICpgTOviVxAkbm7hlaZhmRrlmkc3iCtEHG4U,8417
 udl_vis/mmcv/utils/__init__.py,sha256=2-PyhGZrqWphp3p65zcyxY4WKmv3OaXdqqAEvRIPZMM,4027
 udl_vis/mmcv/utils/config.py,sha256=vgOZXX1qWZZsFTRj0JHEuYU5MoEtngDEpZKL8DFT9pg,27039
 udl_vis/mmcv/utils/env.py,sha256=dQfrJudYLZK7HEv6dnTatvggQC8o73iZE8C8DvdsFWY,3407
 udl_vis/mmcv/utils/ext_loader.py,sha256=bVwtzF6oAvmKCBM7TAWvMUPb5-iVME1YNQVgcH89TBU,2092
 udl_vis/mmcv/utils/hub.py,sha256=0jfv4LD6f8J0tIruxBum2Oa-mUVU5zuv5Y9VJC-zOjE,6167
-udl_vis/mmcv/utils/logging.py,sha256=nCgmD6qzXaD2CjCnvsaHMw_uPvs-TUhjYQ-x1NJzAmU,13466
+udl_vis/mmcv/utils/logging.py,sha256=1AttOvbhT4vZ47bQRNQ9o0NGrmYork5eGEjcu_TE7K8,13489
 udl_vis/mmcv/utils/misc.py,sha256=690_cNNkMZsQQVxlouO3rwdlLeeRGtCHk0obOEnujJE,11864
 udl_vis/mmcv/utils/parrots_jit.py,sha256=qs-pmzBm2mIpezgiBMjs4Qs-Venlh7wF0rGogX8yDoo,940
 udl_vis/mmcv/utils/parrots_wrapper.py,sha256=UoGceWp1WeBUSR5oC0T-JwRWQpyqMEqP5RIDkeGn9D8,3643
 udl_vis/mmcv/utils/path.py,sha256=vRWXZfkm8PnS9jXXxOlvvHVoqzCzgieXZhUjMC8dlJA,3516
 udl_vis/mmcv/utils/progressbar.py,sha256=StJ17Rm4Gzn_zl3DZWdQ2twoEIB1Xl-EEd3dA5t-7Pk,7313
 udl_vis/mmcv/utils/registry.py,sha256=--0W9bJTtqIDxlAOI6ivSQfkAGRtbwNAAV69W7n0pFU,11722
 udl_vis/mmcv/utils/testing.py,sha256=uS--CYMC31g0f8SR45eu1tIuiMZW1h9-0RI5F_OgTrM,4429
@@ -213,12 +213,12 @@
 udl_vis/mmcv/video/io.py,sha256=rnbh6rnTVF8Gaq7p2t5fItMi4o-FYvF5vCYfzSpyJUo,10517
 udl_vis/mmcv/video/optflow.py,sha256=hDobz1nWcVSuHQUB6C8vDTCwUYvgzf1EZlCY253KB0Y,9942
 udl_vis/mmcv/video/processing.py,sha256=ReMLLg8M-TpkmMP2lhVkEhIeYbKuBAw6UdBnxEGYrj0,5439
 udl_vis/mmcv/visualization/__init__.py,sha256=7bjyjDI2DNV8SfsDa7MaB3Yr7tjMCS3_zflkNMfdSjY,347
 udl_vis/mmcv/visualization/color.py,sha256=ldTEA13GOlmCUzuuZkrlHSh6rHCKcxuRUC2cBXwjNwY,1420
 udl_vis/mmcv/visualization/image.py,sha256=9W78dT6U84cY5i1Cm5LheB1sNPxoWYVWc7FgRTRTv_o,5285
 udl_vis/mmcv/visualization/optflow.py,sha256=PWdjNrqjl77czn4787rE_ir6nilHIAvV6Wq8aKr2dfA,3477
-udl_vis-0.3.2.dist-info/LICENSE,sha256=IwGE9guuL-ryRPEKi6wFPI_zOhg7zDZbTYuHbSt_SAk,35823
-udl_vis-0.3.2.dist-info/METADATA,sha256=ILZmNnaLeGxjmyYi3ZIzyFmnhWJu5QpHKWjfM_k-igk,5930
-udl_vis-0.3.2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-udl_vis-0.3.2.dist-info/top_level.txt,sha256=lwXVNhXgYH7yLAdg0S8Gb4hYbomoBdaja9PeHE6iDoU,8
-udl_vis-0.3.2.dist-info/RECORD,,
+udl_vis-0.3.3.dist-info/LICENSE,sha256=IwGE9guuL-ryRPEKi6wFPI_zOhg7zDZbTYuHbSt_SAk,35823
+udl_vis-0.3.3.dist-info/METADATA,sha256=YG370_nIx-W_1NBQDR63tjDHFvgk7BO5ZkIJzE-ZoSk,5930
+udl_vis-0.3.3.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+udl_vis-0.3.3.dist-info/top_level.txt,sha256=lwXVNhXgYH7yLAdg0S8Gb4hYbomoBdaja9PeHE6iDoU,8
+udl_vis-0.3.3.dist-info/RECORD,,
```

