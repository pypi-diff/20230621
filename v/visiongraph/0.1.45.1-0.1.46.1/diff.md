# Comparing `tmp/visiongraph-0.1.45.1-py3-none-any.whl.zip` & `tmp/visiongraph-0.1.46.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,266 +1,267 @@
-Zip file size: 244136 bytes, number of entries: 264
--rw-r--r--  2.0 unx     1758 b- defN 23-May-22 08:36 visiongraph/AsyncGraphNode.py
--rw-r--r--  2.0 unx     2806 b- defN 23-May-22 08:36 visiongraph/BaseGraph.py
--rw-r--r--  2.0 unx      678 b- defN 23-May-22 08:36 visiongraph/GraphNode.py
--rw-r--r--  2.0 unx      276 b- defN 23-May-22 08:36 visiongraph/Processable.py
--rw-r--r--  2.0 unx     2094 b- defN 23-May-22 08:36 visiongraph/VisionGraph.py
--rw-r--r--  2.0 unx     1898 b- defN 23-May-22 08:36 visiongraph/VisionGraphBuilder.py
--rw-r--r--  2.0 unx    24206 b- defN 23-May-22 08:37 visiongraph/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/cache/__init__.py
--rw-r--r--  2.0 unx      368 b- defN 23-May-22 08:36 visiongraph/data/Asset.py
--rw-r--r--  2.0 unx      376 b- defN 23-May-22 08:36 visiongraph/data/LocalAsset.py
--rw-r--r--  2.0 unx     1099 b- defN 23-May-22 08:36 visiongraph/data/RepositoryAsset.py
--rw-r--r--  2.0 unx      324 b- defN 23-May-22 08:36 visiongraph/data/__init__.py
--rw-r--r--  2.0 unx     2568 b- defN 23-May-22 08:36 visiongraph/data/labels/COCO.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/data/labels/__init__.py
--rw-r--r--  2.0 unx      172 b- defN 23-May-22 08:36 visiongraph/dsp/BaseFilterNumpy.py
--rw-r--r--  2.0 unx     2421 b- defN 23-May-22 08:36 visiongraph/dsp/LandmarkSmoothFilter.py
--rw-r--r--  2.0 unx     1487 b- defN 23-May-22 08:36 visiongraph/dsp/OneEuroFilter.py
--rw-r--r--  2.0 unx     1651 b- defN 23-May-22 08:36 visiongraph/dsp/OneEuroFilterNumba.py
--rw-r--r--  2.0 unx     2642 b- defN 23-May-22 08:36 visiongraph/dsp/OneEuroFilterNumpy.py
--rw-r--r--  2.0 unx     1037 b- defN 23-May-22 08:36 visiongraph/dsp/VectorNumpySmoothFilter.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/dsp/__init__.py
--rw-r--r--  2.0 unx      619 b- defN 23-May-22 08:36 visiongraph/estimator/BaseClassifier.py
--rw-r--r--  2.0 unx      397 b- defN 23-May-22 08:36 visiongraph/estimator/BaseEstimator.py
--rw-r--r--  2.0 unx     4345 b- defN 23-May-22 08:36 visiongraph/estimator/BaseVisionEngine.py
--rw-r--r--  2.0 unx     1100 b- defN 23-May-22 08:36 visiongraph/estimator/ChainEstimator.py
--rw-r--r--  2.0 unx      403 b- defN 23-May-22 08:36 visiongraph/estimator/ScoreThresholdEstimator.py
--rw-r--r--  2.0 unx      868 b- defN 23-May-22 08:36 visiongraph/estimator/VisionClassifier.py
--rw-r--r--  2.0 unx      410 b- defN 23-May-22 08:36 visiongraph/estimator/VisionEstimator.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/__init__.py
--rw-r--r--  2.0 unx     2448 b- defN 23-May-22 08:36 visiongraph/estimator/calculator/UndistortionCalculator.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/calculator/__init__.py
--rw-r--r--  2.0 unx     1335 b- defN 23-May-22 08:36 visiongraph/estimator/engine/InferenceEngineFactory.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/engine/__init__.py
--rw-r--r--  2.0 unx      529 b- defN 23-May-22 08:36 visiongraph/estimator/inpaint/BaseInpainter.py
--rw-r--r--  2.0 unx     2161 b- defN 23-May-22 08:36 visiongraph/estimator/inpaint/GMCNNInpainter.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/inpaint/__init__.py
--rw-r--r--  2.0 unx     2532 b- defN 23-May-22 08:36 visiongraph/estimator/onnx/ONNXVisionEngine.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/onnx/__init__.py
--rw-r--r--  2.0 unx     2337 b- defN 23-May-22 08:36 visiongraph/estimator/openvino/OpenVinoEngine.py
--rw-r--r--  2.0 unx     2516 b- defN 23-May-22 08:36 visiongraph/estimator/openvino/OpenVinoObjectDetector.py
--rw-r--r--  2.0 unx     2967 b- defN 23-May-22 08:36 visiongraph/estimator/openvino/OpenVinoPoseEstimator.py
--rw-r--r--  2.0 unx      726 b- defN 23-May-22 08:36 visiongraph/estimator/openvino/SyncInferencePipeline.py
--rw-r--r--  2.0 unx     1813 b- defN 23-May-22 08:36 visiongraph/estimator/openvino/VisionInferenceEngine.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/openvino/__init__.py
--rw-r--r--  2.0 unx     1750 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/CenterNetDetector.py
--rw-r--r--  2.0 unx     3270 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/CrowdHumanDetector.py
--rw-r--r--  2.0 unx     1781 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/DETRDetector.py
--rw-r--r--  2.0 unx      544 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/InstanceSegmentationEstimator.py
--rw-r--r--  2.0 unx      523 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/LandmarkEstimator.py
--rw-r--r--  2.0 unx      524 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/ObjectDetector.py
--rw-r--r--  2.0 unx     1279 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/RoiEstimator.py
--rw-r--r--  2.0 unx     3147 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/SSDDetector.py
--rw-r--r--  2.0 unx     2082 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/SlidingWindowEstimator.py
--rw-r--r--  2.0 unx     1436 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/SpatialCascadeEstimator.py
--rw-r--r--  2.0 unx     3173 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/YOLODetector.py
--rw-r--r--  2.0 unx     2868 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/YOLOXE2EDetector.py
--rw-r--r--  2.0 unx     3594 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/YOLOv5Detector.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/__init__.py
--rw-r--r--  2.0 unx     3441 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/camera/ArUcoCameraPoseEstimator.py
--rw-r--r--  2.0 unx      850 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/camera/BoardCameraCalibrator.py
--rw-r--r--  2.0 unx     4276 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/camera/ChArUcoCalibrator.py
--rw-r--r--  2.0 unx     3145 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/camera/ChessboardCalibrator.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/camera/__init__.py
--rw-r--r--  2.0 unx     1127 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/AdasFaceDetector.py
--rw-r--r--  2.0 unx      512 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/FaceDetector.py
--rw-r--r--  2.0 unx     3805 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/OpenVinoFaceDetector.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/__init__.py
--rw-r--r--  2.0 unx     1781 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/emotion/AffectNetEmotionClassifier.py
--rw-r--r--  2.0 unx     2038 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/emotion/FERPlusEmotionClassifier.py
--rw-r--r--  2.0 unx      450 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/emotion/FaceEmotionEstimator.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/emotion/__init__.py
--rw-r--r--  2.0 unx      609 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/landmark/FaceLandmarkEstimator.py
--rw-r--r--  2.0 unx     2646 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/landmark/IrisDistanceCalculator.py
--rw-r--r--  2.0 unx     2204 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/landmark/MediaPipeFaceDetector.py
--rw-r--r--  2.0 unx     2324 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/landmark/MediaPipeFaceMeshEstimator.py
--rw-r--r--  2.0 unx     1832 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/landmark/RegressionLandmarkEstimator.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/landmark/__init__.py
--rw-r--r--  2.0 unx     1301 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/pose/AdasHeadPoseEstimator.py
--rw-r--r--  2.0 unx      315 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/pose/HeadPoseEstimator.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/pose/__init__.py
--rw-r--r--  2.0 unx     4265 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/recognition/FaceRecognitionEstimator.py
--rw-r--r--  2.0 unx     2842 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/recognition/FaceReidentificationEstimator.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/face/recognition/__init__.py
--rw-r--r--  2.0 unx      517 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/hand/HandDetector.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/hand/__init__.py
--rw-r--r--  2.0 unx      608 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/hand/landmark/HandLandmarkEstimator.py
--rw-r--r--  2.0 unx     2778 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/hand/landmark/MediaPipeHandEstimator.py
--rw-r--r--  2.0 unx     2330 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/hand/landmark/OpenPoseHandEstimator.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/hand/landmark/__init__.py
--rw-r--r--  2.0 unx     2086 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/AEPoseEstimator.py
--rw-r--r--  2.0 unx     5139 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/EfficientPoseEstimator.py
--rw-r--r--  2.0 unx     7134 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/KAPAOPoseEstimator.py
--rw-r--r--  2.0 unx     3890 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/LiteHRNetEstimator.py
--rw-r--r--  2.0 unx     2855 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/LitePoseEstimator.py
--rw-r--r--  2.0 unx     3100 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/MediaPipePoseEstimator.py
--rw-r--r--  2.0 unx     6641 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/MobileHumanPoseEstimator.py
--rw-r--r--  2.0 unx     9658 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/MobileNetV2PoseEstimator.py
--rw-r--r--  2.0 unx     4325 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/MoveNetPoseEstimator.py
--rw-r--r--  2.0 unx     1660 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/OpenPoseEstimator.py
--rw-r--r--  2.0 unx      518 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/PoseEstimator.py
--rw-r--r--  2.0 unx     2347 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/TopDownPoseEstimator.py
--rw-r--r--  2.0 unx     5416 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/pose/__init__.py
--rw-r--r--  2.0 unx     7516 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/segmentation/MaskRCNNEstimator.py
--rw-r--r--  2.0 unx     1989 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/segmentation/MediaPipeSelfieSegmentation.py
--rw-r--r--  2.0 unx     3287 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/segmentation/YolactEstimator.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/spatial/segmentation/__init__.py
--rw-r--r--  2.0 unx     1714 b- defN 23-May-22 08:36 visiongraph/estimator/translation/DeblurGANv2.py
--rw-r--r--  2.0 unx      314 b- defN 23-May-22 08:36 visiongraph/estimator/translation/DepthEstimator.py
--rw-r--r--  2.0 unx     2898 b- defN 23-May-22 08:36 visiongraph/estimator/translation/MidasDepthEstimator.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/estimator/translation/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/external/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/external/intel/__init__.py
--rw-r--r--  2.0 unx     4337 b- defN 23-May-22 08:36 visiongraph/external/intel/performance_metrics.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/external/intel/adapters/__init__.py
--rw-r--r--  2.0 unx     5682 b- defN 23-May-22 08:36 visiongraph/external/intel/adapters/inference_adapter.py
--rw-r--r--  2.0 unx    15557 b- defN 23-May-22 08:36 visiongraph/external/intel/adapters/openvino_adapter.py
--rw-r--r--  2.0 unx     7413 b- defN 23-May-22 08:36 visiongraph/external/intel/adapters/ovms_adapter.py
--rw-r--r--  2.0 unx    10920 b- defN 23-May-22 08:36 visiongraph/external/intel/adapters/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/external/intel/models/__init__.py
--rw-r--r--  2.0 unx     7582 b- defN 23-May-22 08:36 visiongraph/external/intel/models/centernet.py
--rw-r--r--  2.0 unx     6784 b- defN 23-May-22 08:36 visiongraph/external/intel/models/detection_model.py
--rw-r--r--  2.0 unx     3215 b- defN 23-May-22 08:36 visiongraph/external/intel/models/detr.py
--rw-r--r--  2.0 unx    16363 b- defN 23-May-22 08:36 visiongraph/external/intel/models/hpe_associative_embedding.py
--rw-r--r--  2.0 unx     8434 b- defN 23-May-22 08:36 visiongraph/external/intel/models/image_model.py
--rw-r--r--  2.0 unx    19269 b- defN 23-May-22 08:36 visiongraph/external/intel/models/model.py
--rw-r--r--  2.0 unx    19768 b- defN 23-May-22 08:36 visiongraph/external/intel/models/open_pose.py
--rw-r--r--  2.0 unx     5995 b- defN 23-May-22 08:36 visiongraph/external/intel/models/ssd.py
--rw-r--r--  2.0 unx     7510 b- defN 23-May-22 08:36 visiongraph/external/intel/models/types.py
--rw-r--r--  2.0 unx     7600 b- defN 23-May-22 08:36 visiongraph/external/intel/models/utils.py
--rw-r--r--  2.0 unx    24161 b- defN 23-May-22 08:36 visiongraph/external/intel/models/yolo.py
--rw-r--r--  2.0 unx      154 b- defN 23-May-22 08:36 visiongraph/external/intel/pipelines/__init__.py
--rw-r--r--  2.0 unx     5407 b- defN 23-May-22 08:36 visiongraph/external/intel/pipelines/async_pipeline.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/external/midas/__init__.py
--rw-r--r--  2.0 unx     7868 b- defN 23-May-22 08:36 visiongraph/external/midas/transforms.py
--rw-r--r--  2.0 unx      193 b- defN 23-May-22 08:36 visiongraph/external/motpy/__init__.py
--rw-r--r--  2.0 unx     1816 b- defN 23-May-22 08:36 visiongraph/external/motpy/core.py
--rw-r--r--  2.0 unx      333 b- defN 23-May-22 08:36 visiongraph/external/motpy/detector.py
--rw-r--r--  2.0 unx     1147 b- defN 23-May-22 08:36 visiongraph/external/motpy/metrics.py
--rw-r--r--  2.0 unx     5402 b- defN 23-May-22 08:36 visiongraph/external/motpy/model.py
--rw-r--r--  2.0 unx     3576 b- defN 23-May-22 08:36 visiongraph/external/motpy/testing.py
--rw-r--r--  2.0 unx     2647 b- defN 23-May-22 08:36 visiongraph/external/motpy/testing_viz.py
--rw-r--r--  2.0 unx    16512 b- defN 23-May-22 08:36 visiongraph/external/motpy/tracker.py
--rw-r--r--  2.0 unx      652 b- defN 23-May-22 08:36 visiongraph/external/motpy/utils.py
--rw-r--r--  2.0 unx     5312 b- defN 23-May-22 08:36 visiongraph/external/motrackers/Track.py
--rw-r--r--  2.0 unx     7486 b- defN 23-May-22 08:36 visiongraph/external/motrackers/Tracker.py
--rw-r--r--  2.0 unx      184 b- defN 23-May-22 08:36 visiongraph/external/motrackers/__init__.py
--rw-r--r--  2.0 unx       83 b- defN 23-May-22 08:36 visiongraph/external/motrackers/utils/__init__.py
--rw-r--r--  2.0 unx     8978 b- defN 23-May-22 08:36 visiongraph/external/motrackers/utils/misc.py
--rw-r--r--  2.0 unx    16025 b- defN 23-May-22 08:36 visiongraph/input/AzureKinectInput.py
--rw-r--r--  2.0 unx     4108 b- defN 23-May-22 08:36 visiongraph/input/BaseDepthCamera.py
--rw-r--r--  2.0 unx     1309 b- defN 23-May-22 08:36 visiongraph/input/BaseDepthInput.py
--rw-r--r--  2.0 unx     3760 b- defN 23-May-22 08:36 visiongraph/input/BaseInput.py
--rw-r--r--  2.0 unx     1721 b- defN 23-May-22 08:36 visiongraph/input/CamGearInput.py
--rw-r--r--  2.0 unx     1493 b- defN 23-May-22 08:36 visiongraph/input/ImageInput.py
--rw-r--r--  2.0 unx    19563 b- defN 23-May-22 08:36 visiongraph/input/RealSenseInput.py
--rw-r--r--  2.0 unx     5032 b- defN 23-May-22 08:36 visiongraph/input/VideoCaptureInput.py
--rw-r--r--  2.0 unx     1305 b- defN 23-May-22 08:36 visiongraph/input/__init__.py
--rw-r--r--  2.0 unx     1887 b- defN 23-May-22 08:36 visiongraph/model/CameraIntrinsics.py
--rw-r--r--  2.0 unx      101 b- defN 23-May-22 08:36 visiongraph/model/CameraStreamType.py
--rw-r--r--  2.0 unx      549 b- defN 23-May-22 08:36 visiongraph/model/DepthBuffer.py
--rw-r--r--  2.0 unx      753 b- defN 23-May-22 08:36 visiongraph/model/VisionEngineOutput.py
--rw-r--r--  2.0 unx      135 b- defN 23-May-22 08:36 visiongraph/model/_ImportStub.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/model/__init__.py
--rw-r--r--  2.0 unx     4229 b- defN 23-May-22 08:36 visiongraph/model/geometry/BoundingBox2D.py
--rw-r--r--  2.0 unx      815 b- defN 23-May-22 08:36 visiongraph/model/geometry/Size2D.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/model/geometry/__init__.py
--rw-r--r--  2.0 unx      585 b- defN 23-May-22 08:36 visiongraph/model/parameter/ArgumentConfigurable.py
--rw-r--r--  2.0 unx      186 b- defN 23-May-22 08:36 visiongraph/model/parameter/NamedParameter.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/model/parameter/__init__.py
--rw-r--r--  2.0 unx      399 b- defN 23-May-22 08:36 visiongraph/model/tracker/Trackable.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/model/tracker/__init__.py
--rw-r--r--  2.0 unx      440 b- defN 23-May-22 08:36 visiongraph/model/types/ModelPrecision.py
--rw-r--r--  2.0 unx      199 b- defN 23-May-22 08:36 visiongraph/model/types/RealSenseColorScheme.py
--rw-r--r--  2.0 unx      204 b- defN 23-May-22 08:36 visiongraph/model/types/RealSenseFilter.py
--rw-r--r--  2.0 unx     1180 b- defN 23-May-22 08:36 visiongraph/model/types/VideoCaptureBackend.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/model/types/__init__.py
--rw-r--r--  2.0 unx      905 b- defN 23-May-22 08:36 visiongraph/node/ApplyNode.py
--rw-r--r--  2.0 unx      753 b- defN 23-May-22 08:36 visiongraph/node/BreakpointNode.py
--rw-r--r--  2.0 unx      815 b- defN 23-May-22 08:36 visiongraph/node/CustomNode.py
--rw-r--r--  2.0 unx      903 b- defN 23-May-22 08:36 visiongraph/node/ExtractNode.py
--rw-r--r--  2.0 unx      525 b- defN 23-May-22 08:36 visiongraph/node/PassThroughNode.py
--rw-r--r--  2.0 unx      825 b- defN 23-May-22 08:36 visiongraph/node/SequenceNode.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/node/__init__.py
--rw-r--r--  2.0 unx     1471 b- defN 23-May-22 08:36 visiongraph/output/ImagePreview.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/output/__init__.py
--rw-r--r--  2.0 unx      935 b- defN 23-May-22 08:36 visiongraph/output/fbs/FrameBufferSharingServer.py
--rw-r--r--  2.0 unx     1390 b- defN 23-May-22 08:36 visiongraph/output/fbs/SpoutServer.py
--rw-r--r--  2.0 unx     3287 b- defN 23-May-22 08:36 visiongraph/output/fbs/SyphonServer.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/output/fbs/__init__.py
--rw-r--r--  2.0 unx      980 b- defN 23-May-22 08:36 visiongraph/recorder/AsyncFrameSetRecorder.py
--rw-r--r--  2.0 unx     1108 b- defN 23-May-22 08:36 visiongraph/recorder/BaseFrameRecorder.py
--rw-r--r--  2.0 unx     1143 b- defN 23-May-22 08:36 visiongraph/recorder/CV2VideoRecorder.py
--rw-r--r--  2.0 unx     1016 b- defN 23-May-22 08:36 visiongraph/recorder/FrameSetRecorder.py
--rw-r--r--  2.0 unx      905 b- defN 23-May-22 08:36 visiongraph/recorder/MoviePyVideoRecorder.py
--rw-r--r--  2.0 unx     1377 b- defN 23-May-22 08:36 visiongraph/recorder/VidGearVideoRecorder.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/recorder/__init__.py
--rw-r--r--  2.0 unx      564 b- defN 23-May-22 08:36 visiongraph/result/ArUcoCameraPose.py
--rw-r--r--  2.0 unx     1521 b- defN 23-May-22 08:36 visiongraph/result/ArUcoMarkerDetection.py
--rw-r--r--  2.0 unx      167 b- defN 23-May-22 08:36 visiongraph/result/BaseResult.py
--rw-r--r--  2.0 unx      525 b- defN 23-May-22 08:36 visiongraph/result/CameraPoseResult.py
--rw-r--r--  2.0 unx      378 b- defN 23-May-22 08:36 visiongraph/result/ClassificationResult.py
--rw-r--r--  2.0 unx     1709 b- defN 23-May-22 08:36 visiongraph/result/DepthMap.py
--rw-r--r--  2.0 unx      487 b- defN 23-May-22 08:36 visiongraph/result/EmbeddingResult.py
--rw-r--r--  2.0 unx      474 b- defN 23-May-22 08:36 visiongraph/result/HeadPoseResult.py
--rw-r--r--  2.0 unx      333 b- defN 23-May-22 08:36 visiongraph/result/ImageResult.py
--rw-r--r--  2.0 unx     1165 b- defN 23-May-22 08:36 visiongraph/result/ResultAnnotator.py
--rw-r--r--  2.0 unx      483 b- defN 23-May-22 08:36 visiongraph/result/ResultDict.py
--rw-r--r--  2.0 unx      466 b- defN 23-May-22 08:36 visiongraph/result/ResultList.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/result/__init__.py
--rw-r--r--  2.0 unx      779 b- defN 23-May-22 08:36 visiongraph/result/spatial/CrowdHumanResult.py
--rw-r--r--  2.0 unx     1354 b- defN 23-May-22 08:36 visiongraph/result/spatial/InstanceSegmentationResult.py
--rw-r--r--  2.0 unx     4199 b- defN 23-May-22 08:36 visiongraph/result/spatial/LandmarkDetectionResult.py
--rw-r--r--  2.0 unx     3475 b- defN 23-May-22 08:36 visiongraph/result/spatial/ObjectDetectionResult.py
--rw-r--r--  2.0 unx      878 b- defN 23-May-22 08:36 visiongraph/result/spatial/SpatialCascadeResult.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/result/spatial/__init__.py
--rw-r--r--  2.0 unx      924 b- defN 23-May-22 08:36 visiongraph/result/spatial/face/BlazeFace.py
--rw-r--r--  2.0 unx     2064 b- defN 23-May-22 08:36 visiongraph/result/spatial/face/BlazeFaceMesh.py
--rw-r--r--  2.0 unx      702 b- defN 23-May-22 08:36 visiongraph/result/spatial/face/EmotionClassificationResult.py
--rw-r--r--  2.0 unx      409 b- defN 23-May-22 08:36 visiongraph/result/spatial/face/FaceDetectionResult.py
--rw-r--r--  2.0 unx      881 b- defN 23-May-22 08:36 visiongraph/result/spatial/face/FaceLandmarkResult.py
--rw-r--r--  2.0 unx     1390 b- defN 23-May-22 08:36 visiongraph/result/spatial/face/IrisDistanceResult.py
--rw-r--r--  2.0 unx      868 b- defN 23-May-22 08:36 visiongraph/result/spatial/face/RegressionFace.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/result/spatial/face/__init__.py
--rw-r--r--  2.0 unx     2648 b- defN 23-May-22 08:36 visiongraph/result/spatial/hand/BlazeHand.py
--rw-r--r--  2.0 unx      409 b- defN 23-May-22 08:36 visiongraph/result/spatial/hand/HandDetectionResult.py
--rw-r--r--  2.0 unx     2590 b- defN 23-May-22 08:36 visiongraph/result/spatial/hand/HandLandmarkResult.py
--rw-r--r--  2.0 unx       88 b- defN 23-May-22 08:36 visiongraph/result/spatial/hand/Handedness.py
--rw-r--r--  2.0 unx      106 b- defN 23-May-22 08:36 visiongraph/result/spatial/hand/OpenPoseHand.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/result/spatial/hand/__init__.py
--rw-r--r--  2.0 unx     3435 b- defN 23-May-22 08:36 visiongraph/result/spatial/pose/BlazePose.py
--rw-r--r--  2.0 unx     1266 b- defN 23-May-22 08:36 visiongraph/result/spatial/pose/BlazePoseSegmentation.py
--rw-r--r--  2.0 unx     2826 b- defN 23-May-22 08:36 visiongraph/result/spatial/pose/COCOOpenPose.py
--rw-r--r--  2.0 unx     2680 b- defN 23-May-22 08:36 visiongraph/result/spatial/pose/COCOPose.py
--rw-r--r--  2.0 unx     2337 b- defN 23-May-22 08:36 visiongraph/result/spatial/pose/EfficientPose.py
--rw-r--r--  2.0 unx     2738 b- defN 23-May-22 08:36 visiongraph/result/spatial/pose/MobileHumanPose.py
--rw-r--r--  2.0 unx     2823 b- defN 23-May-22 08:36 visiongraph/result/spatial/pose/PoseLandmarkResult.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/result/spatial/pose/__init__.py
--rw-r--r--  2.0 unx      492 b- defN 23-May-22 08:36 visiongraph/tracker/BaseObjectDetectionTracker.py
--rw-r--r--  2.0 unx     1908 b- defN 23-May-22 08:36 visiongraph/tracker/CentroidTracker.py
--rw-r--r--  2.0 unx     4906 b- defN 23-May-22 08:36 visiongraph/tracker/FlateTracker.py
--rw-r--r--  2.0 unx     2705 b- defN 23-May-22 08:36 visiongraph/tracker/MotpyTracker.py
--rw-r--r--  2.0 unx     3299 b- defN 23-May-22 08:36 visiongraph/tracker/ObjectAssignmentSolver.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/tracker/__init__.py
--rw-r--r--  2.0 unx     3105 b- defN 23-May-22 08:36 visiongraph/util/ArgUtils.py
--rw-r--r--  2.0 unx     1009 b- defN 23-May-22 08:36 visiongraph/util/CodeUtils.py
--rw-r--r--  2.0 unx      222 b- defN 23-May-22 08:36 visiongraph/util/CollectionUtils.py
--rw-r--r--  2.0 unx      314 b- defN 23-May-22 08:36 visiongraph/util/CommonArgs.py
--rw-r--r--  2.0 unx     3653 b- defN 23-May-22 08:36 visiongraph/util/DrawingUtils.py
--rw-r--r--  2.0 unx     3588 b- defN 23-May-22 08:36 visiongraph/util/ImageUtils.py
--rw-r--r--  2.0 unx     2608 b- defN 23-May-22 08:36 visiongraph/util/LinalgUtils.py
--rw-r--r--  2.0 unx      539 b- defN 23-May-22 08:36 visiongraph/util/LoggingUtils.py
--rw-r--r--  2.0 unx     1752 b- defN 23-May-22 08:36 visiongraph/util/MathUtils.py
--rw-r--r--  2.0 unx     2084 b- defN 23-May-22 08:36 visiongraph/util/NetworkUtils.py
--rw-r--r--  2.0 unx      195 b- defN 23-May-22 08:36 visiongraph/util/OSUtils.py
--rw-r--r--  2.0 unx      704 b- defN 23-May-22 08:36 visiongraph/util/OpenVinoUtils.py
--rw-r--r--  2.0 unx     1240 b- defN 23-May-22 08:36 visiongraph/util/ResultUtils.py
--rw-r--r--  2.0 unx     2102 b- defN 23-May-22 08:36 visiongraph/util/TimeUtils.py
--rw-r--r--  2.0 unx     3225 b- defN 23-May-22 08:36 visiongraph/util/VectorUtils.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-22 08:36 visiongraph/util/__init__.py
--rw-r--r--  2.0 unx    11847 b- defN 23-May-22 08:37 visiongraph-0.1.45.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-22 08:37 visiongraph-0.1.45.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       20 b- defN 23-May-22 08:37 visiongraph-0.1.45.1.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       12 b- defN 23-May-22 08:37 visiongraph-0.1.45.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    26444 b- defN 23-May-22 08:37 visiongraph-0.1.45.1.dist-info/RECORD
-264 files, 670683 bytes uncompressed, 200758 bytes compressed:  70.1%
+Zip file size: 244597 bytes, number of entries: 265
+-rw-r--r--  2.0 unx     1758 b- defN 23-Jun-21 10:01 visiongraph/AsyncGraphNode.py
+-rw-r--r--  2.0 unx     2806 b- defN 23-Jun-21 10:01 visiongraph/BaseGraph.py
+-rw-r--r--  2.0 unx      678 b- defN 23-Jun-21 10:01 visiongraph/GraphNode.py
+-rw-r--r--  2.0 unx      276 b- defN 23-Jun-21 10:01 visiongraph/Processable.py
+-rw-r--r--  2.0 unx     2094 b- defN 23-Jun-21 10:01 visiongraph/VisionGraph.py
+-rw-r--r--  2.0 unx     1898 b- defN 23-Jun-21 10:01 visiongraph/VisionGraphBuilder.py
+-rw-r--r--  2.0 unx    23273 b- defN 23-Jun-21 10:01 visiongraph/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/cache/__init__.py
+-rw-r--r--  2.0 unx      368 b- defN 23-Jun-21 10:01 visiongraph/data/Asset.py
+-rw-r--r--  2.0 unx      376 b- defN 23-Jun-21 10:01 visiongraph/data/LocalAsset.py
+-rw-r--r--  2.0 unx     1099 b- defN 23-Jun-21 10:01 visiongraph/data/RepositoryAsset.py
+-rw-r--r--  2.0 unx      324 b- defN 23-Jun-21 10:01 visiongraph/data/__init__.py
+-rw-r--r--  2.0 unx     2568 b- defN 23-Jun-21 10:01 visiongraph/data/labels/COCO.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/data/labels/__init__.py
+-rw-r--r--  2.0 unx      172 b- defN 23-Jun-21 10:01 visiongraph/dsp/BaseFilterNumpy.py
+-rw-r--r--  2.0 unx     2421 b- defN 23-Jun-21 10:01 visiongraph/dsp/LandmarkSmoothFilter.py
+-rw-r--r--  2.0 unx     1487 b- defN 23-Jun-21 10:01 visiongraph/dsp/OneEuroFilter.py
+-rw-r--r--  2.0 unx     1651 b- defN 23-Jun-21 10:01 visiongraph/dsp/OneEuroFilterNumba.py
+-rw-r--r--  2.0 unx     2642 b- defN 23-Jun-21 10:01 visiongraph/dsp/OneEuroFilterNumpy.py
+-rw-r--r--  2.0 unx     1037 b- defN 23-Jun-21 10:01 visiongraph/dsp/VectorNumpySmoothFilter.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/dsp/__init__.py
+-rw-r--r--  2.0 unx      619 b- defN 23-Jun-21 10:01 visiongraph/estimator/BaseClassifier.py
+-rw-r--r--  2.0 unx      397 b- defN 23-Jun-21 10:01 visiongraph/estimator/BaseEstimator.py
+-rw-r--r--  2.0 unx     4863 b- defN 23-Jun-21 10:01 visiongraph/estimator/BaseVisionEngine.py
+-rw-r--r--  2.0 unx     1100 b- defN 23-Jun-21 10:01 visiongraph/estimator/ChainEstimator.py
+-rw-r--r--  2.0 unx      403 b- defN 23-Jun-21 10:01 visiongraph/estimator/ScoreThresholdEstimator.py
+-rw-r--r--  2.0 unx      868 b- defN 23-Jun-21 10:01 visiongraph/estimator/VisionClassifier.py
+-rw-r--r--  2.0 unx      410 b- defN 23-Jun-21 10:01 visiongraph/estimator/VisionEstimator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/__init__.py
+-rw-r--r--  2.0 unx     2448 b- defN 23-Jun-21 10:01 visiongraph/estimator/calculator/UndistortionCalculator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/calculator/__init__.py
+-rw-r--r--  2.0 unx     1859 b- defN 23-Jun-21 10:01 visiongraph/estimator/engine/InferenceEngineFactory.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/engine/__init__.py
+-rw-r--r--  2.0 unx      529 b- defN 23-Jun-21 10:01 visiongraph/estimator/inpaint/BaseInpainter.py
+-rw-r--r--  2.0 unx     2161 b- defN 23-Jun-21 10:01 visiongraph/estimator/inpaint/GMCNNInpainter.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/inpaint/__init__.py
+-rw-r--r--  2.0 unx     2532 b- defN 23-Jun-21 10:01 visiongraph/estimator/onnx/ONNXVisionEngine.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/onnx/__init__.py
+-rw-r--r--  2.0 unx     2337 b- defN 23-Jun-21 10:01 visiongraph/estimator/openvino/OpenVinoEngine.py
+-rw-r--r--  2.0 unx     2516 b- defN 23-Jun-21 10:01 visiongraph/estimator/openvino/OpenVinoObjectDetector.py
+-rw-r--r--  2.0 unx     2967 b- defN 23-Jun-21 10:01 visiongraph/estimator/openvino/OpenVinoPoseEstimator.py
+-rw-r--r--  2.0 unx      726 b- defN 23-Jun-21 10:01 visiongraph/estimator/openvino/SyncInferencePipeline.py
+-rw-r--r--  2.0 unx     1813 b- defN 23-Jun-21 10:01 visiongraph/estimator/openvino/VisionInferenceEngine.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/openvino/__init__.py
+-rw-r--r--  2.0 unx     1750 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/CenterNetDetector.py
+-rw-r--r--  2.0 unx     3270 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/CrowdHumanDetector.py
+-rw-r--r--  2.0 unx     1781 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/DETRDetector.py
+-rw-r--r--  2.0 unx      544 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/InstanceSegmentationEstimator.py
+-rw-r--r--  2.0 unx      523 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/LandmarkEstimator.py
+-rw-r--r--  2.0 unx      524 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/ObjectDetector.py
+-rw-r--r--  2.0 unx     1279 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/RoiEstimator.py
+-rw-r--r--  2.0 unx     3147 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/SSDDetector.py
+-rw-r--r--  2.0 unx     2082 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/SlidingWindowEstimator.py
+-rw-r--r--  2.0 unx     1436 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/SpatialCascadeEstimator.py
+-rw-r--r--  2.0 unx     3173 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/YOLODetector.py
+-rw-r--r--  2.0 unx     2868 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/YOLOXE2EDetector.py
+-rw-r--r--  2.0 unx     3594 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/YOLOv5Detector.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/__init__.py
+-rw-r--r--  2.0 unx     3441 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/camera/ArUcoCameraPoseEstimator.py
+-rw-r--r--  2.0 unx      850 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/camera/BoardCameraCalibrator.py
+-rw-r--r--  2.0 unx     4276 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/camera/ChArUcoCalibrator.py
+-rw-r--r--  2.0 unx     3145 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/camera/ChessboardCalibrator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/camera/__init__.py
+-rw-r--r--  2.0 unx     1127 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/AdasFaceDetector.py
+-rw-r--r--  2.0 unx      512 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/FaceDetector.py
+-rw-r--r--  2.0 unx     3805 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/OpenVinoFaceDetector.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/__init__.py
+-rw-r--r--  2.0 unx     1781 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/emotion/AffectNetEmotionClassifier.py
+-rw-r--r--  2.0 unx     2038 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/emotion/FERPlusEmotionClassifier.py
+-rw-r--r--  2.0 unx      450 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/emotion/FaceEmotionEstimator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/emotion/__init__.py
+-rw-r--r--  2.0 unx      609 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/landmark/FaceLandmarkEstimator.py
+-rw-r--r--  2.0 unx     2646 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/landmark/IrisDistanceCalculator.py
+-rw-r--r--  2.0 unx     2204 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/landmark/MediaPipeFaceDetector.py
+-rw-r--r--  2.0 unx     2324 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/landmark/MediaPipeFaceMeshEstimator.py
+-rw-r--r--  2.0 unx     1832 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/landmark/RegressionLandmarkEstimator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/landmark/__init__.py
+-rw-r--r--  2.0 unx     1301 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/pose/AdasHeadPoseEstimator.py
+-rw-r--r--  2.0 unx      315 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/pose/HeadPoseEstimator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/pose/__init__.py
+-rw-r--r--  2.0 unx     4265 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/recognition/FaceRecognitionEstimator.py
+-rw-r--r--  2.0 unx     2842 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/recognition/FaceReidentificationEstimator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/face/recognition/__init__.py
+-rw-r--r--  2.0 unx      517 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/hand/HandDetector.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/hand/__init__.py
+-rw-r--r--  2.0 unx      608 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/hand/landmark/HandLandmarkEstimator.py
+-rw-r--r--  2.0 unx     2778 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/hand/landmark/MediaPipeHandEstimator.py
+-rw-r--r--  2.0 unx     2330 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/hand/landmark/OpenPoseHandEstimator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/hand/landmark/__init__.py
+-rw-r--r--  2.0 unx     2086 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/AEPoseEstimator.py
+-rw-r--r--  2.0 unx     5139 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/EfficientPoseEstimator.py
+-rw-r--r--  2.0 unx     7134 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/KAPAOPoseEstimator.py
+-rw-r--r--  2.0 unx     3890 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/LiteHRNetEstimator.py
+-rw-r--r--  2.0 unx     2855 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/LitePoseEstimator.py
+-rw-r--r--  2.0 unx     3100 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/MediaPipePoseEstimator.py
+-rw-r--r--  2.0 unx     6641 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/MobileHumanPoseEstimator.py
+-rw-r--r--  2.0 unx     9658 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/MobileNetV2PoseEstimator.py
+-rw-r--r--  2.0 unx     4325 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/MoveNetPoseEstimator.py
+-rw-r--r--  2.0 unx     1660 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/OpenPoseEstimator.py
+-rw-r--r--  2.0 unx      518 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/PoseEstimator.py
+-rw-r--r--  2.0 unx     2347 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/TopDownPoseEstimator.py
+-rw-r--r--  2.0 unx     5416 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/pose/__init__.py
+-rw-r--r--  2.0 unx     7516 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/segmentation/MaskRCNNEstimator.py
+-rw-r--r--  2.0 unx     1989 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/segmentation/MediaPipeSelfieSegmentation.py
+-rw-r--r--  2.0 unx     3287 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/segmentation/YolactEstimator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/spatial/segmentation/__init__.py
+-rw-r--r--  2.0 unx     1714 b- defN 23-Jun-21 10:01 visiongraph/estimator/translation/DeblurGANv2.py
+-rw-r--r--  2.0 unx      314 b- defN 23-Jun-21 10:01 visiongraph/estimator/translation/DepthEstimator.py
+-rw-r--r--  2.0 unx     2898 b- defN 23-Jun-21 10:01 visiongraph/estimator/translation/MidasDepthEstimator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/estimator/translation/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/external/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/external/intel/__init__.py
+-rw-r--r--  2.0 unx     4337 b- defN 23-Jun-21 10:01 visiongraph/external/intel/performance_metrics.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/external/intel/adapters/__init__.py
+-rw-r--r--  2.0 unx     5682 b- defN 23-Jun-21 10:01 visiongraph/external/intel/adapters/inference_adapter.py
+-rw-r--r--  2.0 unx    15557 b- defN 23-Jun-21 10:01 visiongraph/external/intel/adapters/openvino_adapter.py
+-rw-r--r--  2.0 unx     7413 b- defN 23-Jun-21 10:01 visiongraph/external/intel/adapters/ovms_adapter.py
+-rw-r--r--  2.0 unx    10920 b- defN 23-Jun-21 10:01 visiongraph/external/intel/adapters/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/__init__.py
+-rw-r--r--  2.0 unx     7582 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/centernet.py
+-rw-r--r--  2.0 unx     6784 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/detection_model.py
+-rw-r--r--  2.0 unx     3215 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/detr.py
+-rw-r--r--  2.0 unx    16363 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/hpe_associative_embedding.py
+-rw-r--r--  2.0 unx     8434 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/image_model.py
+-rw-r--r--  2.0 unx    19269 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/model.py
+-rw-r--r--  2.0 unx    19768 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/open_pose.py
+-rw-r--r--  2.0 unx     5995 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/ssd.py
+-rw-r--r--  2.0 unx     7510 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/types.py
+-rw-r--r--  2.0 unx     7600 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/utils.py
+-rw-r--r--  2.0 unx    24161 b- defN 23-Jun-21 10:01 visiongraph/external/intel/models/yolo.py
+-rw-r--r--  2.0 unx      154 b- defN 23-Jun-21 10:01 visiongraph/external/intel/pipelines/__init__.py
+-rw-r--r--  2.0 unx     5407 b- defN 23-Jun-21 10:01 visiongraph/external/intel/pipelines/async_pipeline.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/external/midas/__init__.py
+-rw-r--r--  2.0 unx     7868 b- defN 23-Jun-21 10:01 visiongraph/external/midas/transforms.py
+-rw-r--r--  2.0 unx      193 b- defN 23-Jun-21 10:01 visiongraph/external/motpy/__init__.py
+-rw-r--r--  2.0 unx     1816 b- defN 23-Jun-21 10:01 visiongraph/external/motpy/core.py
+-rw-r--r--  2.0 unx      333 b- defN 23-Jun-21 10:01 visiongraph/external/motpy/detector.py
+-rw-r--r--  2.0 unx     1147 b- defN 23-Jun-21 10:01 visiongraph/external/motpy/metrics.py
+-rw-r--r--  2.0 unx     5402 b- defN 23-Jun-21 10:01 visiongraph/external/motpy/model.py
+-rw-r--r--  2.0 unx     3576 b- defN 23-Jun-21 10:01 visiongraph/external/motpy/testing.py
+-rw-r--r--  2.0 unx     2647 b- defN 23-Jun-21 10:01 visiongraph/external/motpy/testing_viz.py
+-rw-r--r--  2.0 unx    16512 b- defN 23-Jun-21 10:01 visiongraph/external/motpy/tracker.py
+-rw-r--r--  2.0 unx      652 b- defN 23-Jun-21 10:01 visiongraph/external/motpy/utils.py
+-rw-r--r--  2.0 unx     5312 b- defN 23-Jun-21 10:01 visiongraph/external/motrackers/Track.py
+-rw-r--r--  2.0 unx     7486 b- defN 23-Jun-21 10:01 visiongraph/external/motrackers/Tracker.py
+-rw-r--r--  2.0 unx      184 b- defN 23-Jun-21 10:01 visiongraph/external/motrackers/__init__.py
+-rw-r--r--  2.0 unx       83 b- defN 23-Jun-21 10:01 visiongraph/external/motrackers/utils/__init__.py
+-rw-r--r--  2.0 unx     8978 b- defN 23-Jun-21 10:01 visiongraph/external/motrackers/utils/misc.py
+-rw-r--r--  2.0 unx    16016 b- defN 23-Jun-21 10:01 visiongraph/input/AzureKinectInput.py
+-rw-r--r--  2.0 unx     4108 b- defN 23-Jun-21 10:01 visiongraph/input/BaseDepthCamera.py
+-rw-r--r--  2.0 unx     1309 b- defN 23-Jun-21 10:01 visiongraph/input/BaseDepthInput.py
+-rw-r--r--  2.0 unx     3760 b- defN 23-Jun-21 10:01 visiongraph/input/BaseInput.py
+-rw-r--r--  2.0 unx     1721 b- defN 23-Jun-21 10:01 visiongraph/input/CamGearInput.py
+-rw-r--r--  2.0 unx     1493 b- defN 23-Jun-21 10:01 visiongraph/input/ImageInput.py
+-rw-r--r--  2.0 unx    19563 b- defN 23-Jun-21 10:01 visiongraph/input/RealSenseInput.py
+-rw-r--r--  2.0 unx     5032 b- defN 23-Jun-21 10:01 visiongraph/input/VideoCaptureInput.py
+-rw-r--r--  2.0 unx     1305 b- defN 23-Jun-21 10:01 visiongraph/input/__init__.py
+-rw-r--r--  2.0 unx     1887 b- defN 23-Jun-21 10:01 visiongraph/model/CameraIntrinsics.py
+-rw-r--r--  2.0 unx      101 b- defN 23-Jun-21 10:01 visiongraph/model/CameraStreamType.py
+-rw-r--r--  2.0 unx      549 b- defN 23-Jun-21 10:01 visiongraph/model/DepthBuffer.py
+-rw-r--r--  2.0 unx      753 b- defN 23-Jun-21 10:01 visiongraph/model/VisionEngineOutput.py
+-rw-r--r--  2.0 unx      135 b- defN 23-Jun-21 10:01 visiongraph/model/_ImportStub.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/model/__init__.py
+-rw-r--r--  2.0 unx     4229 b- defN 23-Jun-21 10:01 visiongraph/model/geometry/BoundingBox2D.py
+-rw-r--r--  2.0 unx      815 b- defN 23-Jun-21 10:01 visiongraph/model/geometry/Size2D.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/model/geometry/__init__.py
+-rw-r--r--  2.0 unx      585 b- defN 23-Jun-21 10:01 visiongraph/model/parameter/ArgumentConfigurable.py
+-rw-r--r--  2.0 unx      186 b- defN 23-Jun-21 10:01 visiongraph/model/parameter/NamedParameter.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/model/parameter/__init__.py
+-rw-r--r--  2.0 unx      399 b- defN 23-Jun-21 10:01 visiongraph/model/tracker/Trackable.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/model/tracker/__init__.py
+-rw-r--r--  2.0 unx       78 b- defN 23-Jun-21 10:01 visiongraph/model/types/InputShapeOrder.py
+-rw-r--r--  2.0 unx      440 b- defN 23-Jun-21 10:01 visiongraph/model/types/ModelPrecision.py
+-rw-r--r--  2.0 unx      199 b- defN 23-Jun-21 10:01 visiongraph/model/types/RealSenseColorScheme.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-21 10:01 visiongraph/model/types/RealSenseFilter.py
+-rw-r--r--  2.0 unx     1180 b- defN 23-Jun-21 10:01 visiongraph/model/types/VideoCaptureBackend.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/model/types/__init__.py
+-rw-r--r--  2.0 unx      905 b- defN 23-Jun-21 10:01 visiongraph/node/ApplyNode.py
+-rw-r--r--  2.0 unx      753 b- defN 23-Jun-21 10:01 visiongraph/node/BreakpointNode.py
+-rw-r--r--  2.0 unx      815 b- defN 23-Jun-21 10:01 visiongraph/node/CustomNode.py
+-rw-r--r--  2.0 unx      903 b- defN 23-Jun-21 10:01 visiongraph/node/ExtractNode.py
+-rw-r--r--  2.0 unx      525 b- defN 23-Jun-21 10:01 visiongraph/node/PassThroughNode.py
+-rw-r--r--  2.0 unx      825 b- defN 23-Jun-21 10:01 visiongraph/node/SequenceNode.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/node/__init__.py
+-rw-r--r--  2.0 unx     1471 b- defN 23-Jun-21 10:01 visiongraph/output/ImagePreview.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/output/__init__.py
+-rw-r--r--  2.0 unx      935 b- defN 23-Jun-21 10:01 visiongraph/output/fbs/FrameBufferSharingServer.py
+-rw-r--r--  2.0 unx     1390 b- defN 23-Jun-21 10:01 visiongraph/output/fbs/SpoutServer.py
+-rw-r--r--  2.0 unx     3287 b- defN 23-Jun-21 10:01 visiongraph/output/fbs/SyphonServer.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/output/fbs/__init__.py
+-rw-r--r--  2.0 unx      980 b- defN 23-Jun-21 10:01 visiongraph/recorder/AsyncFrameSetRecorder.py
+-rw-r--r--  2.0 unx     1108 b- defN 23-Jun-21 10:01 visiongraph/recorder/BaseFrameRecorder.py
+-rw-r--r--  2.0 unx     1143 b- defN 23-Jun-21 10:01 visiongraph/recorder/CV2VideoRecorder.py
+-rw-r--r--  2.0 unx     1016 b- defN 23-Jun-21 10:01 visiongraph/recorder/FrameSetRecorder.py
+-rw-r--r--  2.0 unx      905 b- defN 23-Jun-21 10:01 visiongraph/recorder/MoviePyVideoRecorder.py
+-rw-r--r--  2.0 unx     1377 b- defN 23-Jun-21 10:01 visiongraph/recorder/VidGearVideoRecorder.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/recorder/__init__.py
+-rw-r--r--  2.0 unx      564 b- defN 23-Jun-21 10:01 visiongraph/result/ArUcoCameraPose.py
+-rw-r--r--  2.0 unx     1521 b- defN 23-Jun-21 10:01 visiongraph/result/ArUcoMarkerDetection.py
+-rw-r--r--  2.0 unx      167 b- defN 23-Jun-21 10:01 visiongraph/result/BaseResult.py
+-rw-r--r--  2.0 unx      525 b- defN 23-Jun-21 10:01 visiongraph/result/CameraPoseResult.py
+-rw-r--r--  2.0 unx      378 b- defN 23-Jun-21 10:01 visiongraph/result/ClassificationResult.py
+-rw-r--r--  2.0 unx     1709 b- defN 23-Jun-21 10:01 visiongraph/result/DepthMap.py
+-rw-r--r--  2.0 unx      487 b- defN 23-Jun-21 10:01 visiongraph/result/EmbeddingResult.py
+-rw-r--r--  2.0 unx      474 b- defN 23-Jun-21 10:01 visiongraph/result/HeadPoseResult.py
+-rw-r--r--  2.0 unx      333 b- defN 23-Jun-21 10:01 visiongraph/result/ImageResult.py
+-rw-r--r--  2.0 unx     1165 b- defN 23-Jun-21 10:01 visiongraph/result/ResultAnnotator.py
+-rw-r--r--  2.0 unx      483 b- defN 23-Jun-21 10:01 visiongraph/result/ResultDict.py
+-rw-r--r--  2.0 unx      466 b- defN 23-Jun-21 10:01 visiongraph/result/ResultList.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/result/__init__.py
+-rw-r--r--  2.0 unx      779 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/CrowdHumanResult.py
+-rw-r--r--  2.0 unx     1354 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/InstanceSegmentationResult.py
+-rw-r--r--  2.0 unx     4199 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/LandmarkDetectionResult.py
+-rw-r--r--  2.0 unx     3475 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/ObjectDetectionResult.py
+-rw-r--r--  2.0 unx      878 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/SpatialCascadeResult.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/__init__.py
+-rw-r--r--  2.0 unx      924 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/face/BlazeFace.py
+-rw-r--r--  2.0 unx     2064 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/face/BlazeFaceMesh.py
+-rw-r--r--  2.0 unx      702 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/face/EmotionClassificationResult.py
+-rw-r--r--  2.0 unx      409 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/face/FaceDetectionResult.py
+-rw-r--r--  2.0 unx      881 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/face/FaceLandmarkResult.py
+-rw-r--r--  2.0 unx     1390 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/face/IrisDistanceResult.py
+-rw-r--r--  2.0 unx      868 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/face/RegressionFace.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/face/__init__.py
+-rw-r--r--  2.0 unx     2648 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/hand/BlazeHand.py
+-rw-r--r--  2.0 unx      409 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/hand/HandDetectionResult.py
+-rw-r--r--  2.0 unx     2590 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/hand/HandLandmarkResult.py
+-rw-r--r--  2.0 unx       88 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/hand/Handedness.py
+-rw-r--r--  2.0 unx      106 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/hand/OpenPoseHand.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/hand/__init__.py
+-rw-r--r--  2.0 unx     3435 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/pose/BlazePose.py
+-rw-r--r--  2.0 unx     1266 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/pose/BlazePoseSegmentation.py
+-rw-r--r--  2.0 unx     2826 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/pose/COCOOpenPose.py
+-rw-r--r--  2.0 unx     2680 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/pose/COCOPose.py
+-rw-r--r--  2.0 unx     2337 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/pose/EfficientPose.py
+-rw-r--r--  2.0 unx     2738 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/pose/MobileHumanPose.py
+-rw-r--r--  2.0 unx     2823 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/pose/PoseLandmarkResult.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/result/spatial/pose/__init__.py
+-rw-r--r--  2.0 unx      492 b- defN 23-Jun-21 10:01 visiongraph/tracker/BaseObjectDetectionTracker.py
+-rw-r--r--  2.0 unx     1908 b- defN 23-Jun-21 10:01 visiongraph/tracker/CentroidTracker.py
+-rw-r--r--  2.0 unx     4906 b- defN 23-Jun-21 10:01 visiongraph/tracker/FlateTracker.py
+-rw-r--r--  2.0 unx     2705 b- defN 23-Jun-21 10:01 visiongraph/tracker/MotpyTracker.py
+-rw-r--r--  2.0 unx     3304 b- defN 23-Jun-21 10:01 visiongraph/tracker/ObjectAssignmentSolver.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/tracker/__init__.py
+-rw-r--r--  2.0 unx     3105 b- defN 23-Jun-21 10:01 visiongraph/util/ArgUtils.py
+-rw-r--r--  2.0 unx     1009 b- defN 23-Jun-21 10:01 visiongraph/util/CodeUtils.py
+-rw-r--r--  2.0 unx      222 b- defN 23-Jun-21 10:01 visiongraph/util/CollectionUtils.py
+-rw-r--r--  2.0 unx      314 b- defN 23-Jun-21 10:01 visiongraph/util/CommonArgs.py
+-rw-r--r--  2.0 unx     3653 b- defN 23-Jun-21 10:01 visiongraph/util/DrawingUtils.py
+-rw-r--r--  2.0 unx     3588 b- defN 23-Jun-21 10:01 visiongraph/util/ImageUtils.py
+-rw-r--r--  2.0 unx     2608 b- defN 23-Jun-21 10:01 visiongraph/util/LinalgUtils.py
+-rw-r--r--  2.0 unx      539 b- defN 23-Jun-21 10:01 visiongraph/util/LoggingUtils.py
+-rw-r--r--  2.0 unx     1752 b- defN 23-Jun-21 10:01 visiongraph/util/MathUtils.py
+-rw-r--r--  2.0 unx     2084 b- defN 23-Jun-21 10:01 visiongraph/util/NetworkUtils.py
+-rw-r--r--  2.0 unx      195 b- defN 23-Jun-21 10:01 visiongraph/util/OSUtils.py
+-rw-r--r--  2.0 unx      704 b- defN 23-Jun-21 10:01 visiongraph/util/OpenVinoUtils.py
+-rw-r--r--  2.0 unx     1240 b- defN 23-Jun-21 10:01 visiongraph/util/ResultUtils.py
+-rw-r--r--  2.0 unx     2102 b- defN 23-Jun-21 10:01 visiongraph/util/TimeUtils.py
+-rw-r--r--  2.0 unx     3225 b- defN 23-Jun-21 10:01 visiongraph/util/VectorUtils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 10:01 visiongraph/util/__init__.py
+-rw-r--r--  2.0 unx    11432 b- defN 23-Jun-21 10:01 visiongraph-0.1.46.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-21 10:01 visiongraph-0.1.46.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       20 b- defN 23-Jun-21 10:01 visiongraph-0.1.46.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       12 b- defN 23-Jun-21 10:01 visiongraph-0.1.46.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    26541 b- defN 23-Jun-21 10:01 visiongraph-0.1.46.1.dist-info/RECORD
+265 files, 670548 bytes uncompressed, 201059 bytes compressed:  70.0%
```

## zipnote {}

```diff
@@ -507,14 +507,17 @@
 
 Filename: visiongraph/model/tracker/Trackable.py
 Comment: 
 
 Filename: visiongraph/model/tracker/__init__.py
 Comment: 
 
+Filename: visiongraph/model/types/InputShapeOrder.py
+Comment: 
+
 Filename: visiongraph/model/types/ModelPrecision.py
 Comment: 
 
 Filename: visiongraph/model/types/RealSenseColorScheme.py
 Comment: 
 
 Filename: visiongraph/model/types/RealSenseFilter.py
@@ -771,23 +774,23 @@
 
 Filename: visiongraph/util/VectorUtils.py
 Comment: 
 
 Filename: visiongraph/util/__init__.py
 Comment: 
 
-Filename: visiongraph-0.1.45.1.dist-info/METADATA
+Filename: visiongraph-0.1.46.1.dist-info/METADATA
 Comment: 
 
-Filename: visiongraph-0.1.45.1.dist-info/WHEEL
+Filename: visiongraph-0.1.46.1.dist-info/WHEEL
 Comment: 
 
-Filename: visiongraph-0.1.45.1.dist-info/entry_points.txt
+Filename: visiongraph-0.1.46.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: visiongraph-0.1.45.1.dist-info/top_level.txt
+Filename: visiongraph-0.1.46.1.dist-info/top_level.txt
 Comment: 
 
-Filename: visiongraph-0.1.45.1.dist-info/RECORD
+Filename: visiongraph-0.1.46.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## visiongraph/__init__.py

```diff
@@ -28,22 +28,16 @@
 from .estimator.BaseEstimator import BaseEstimator
 from .estimator.BaseVisionEngine import BaseVisionEngine
 from .estimator.ChainEstimator import ChainEstimator
 from .estimator.ScoreThresholdEstimator import ScoreThresholdEstimator
 from .estimator.VisionClassifier import VisionClassifier
 from .estimator.VisionEstimator import VisionEstimator
 from .estimator.calculator.UndistortionCalculator import UndistortionCalculator
-try:
-    from .estimator.engine.InferenceEngineFactory import InferenceEngine
-except ModuleNotFoundError as ex:
-    logging.info(f"Module InferenceEngine not found")
-try:
-    from .estimator.engine.InferenceEngineFactory import InferenceEngineFactory
-except ModuleNotFoundError as ex:
-    logging.info(f"Module InferenceEngineFactory not found")
+from .estimator.engine.InferenceEngineFactory import InferenceEngine
+from .estimator.engine.InferenceEngineFactory import InferenceEngineFactory
 from .estimator.inpaint.BaseInpainter import BaseInpainter
 try:
     from .estimator.inpaint.GMCNNInpainter import GMCNNConfig
 except ModuleNotFoundError as ex:
     logging.info(f"Module GMCNNConfig not found")
 try:
     from .estimator.inpaint.GMCNNInpainter import GMCNNInpainter
@@ -73,22 +67,16 @@
     from .estimator.spatial.CenterNetDetector import CenterNetConfig
 except ModuleNotFoundError as ex:
     logging.info(f"Module CenterNetConfig not found")
 try:
     from .estimator.spatial.CenterNetDetector import CenterNetDetector
 except ModuleNotFoundError as ex:
     logging.info(f"Module CenterNetDetector not found")
-try:
-    from .estimator.spatial.CrowdHumanDetector import CrowdHumanConfig
-except ModuleNotFoundError as ex:
-    logging.info(f"Module CrowdHumanConfig not found")
-try:
-    from .estimator.spatial.CrowdHumanDetector import CrowdHumanDetector
-except ModuleNotFoundError as ex:
-    logging.info(f"Module CrowdHumanDetector not found")
+from .estimator.spatial.CrowdHumanDetector import CrowdHumanConfig
+from .estimator.spatial.CrowdHumanDetector import CrowdHumanDetector
 try:
     from .estimator.spatial.DETRDetector import DETRConfig
 except ModuleNotFoundError as ex:
     logging.info(f"Module DETRConfig not found")
 try:
     from .estimator.spatial.DETRDetector import DETRDetector
 except ModuleNotFoundError as ex:
@@ -115,26 +103,17 @@
     from .estimator.spatial.YOLODetector import YOLOConfig
 except ModuleNotFoundError as ex:
     logging.info(f"Module YOLOConfig not found")
 try:
     from .estimator.spatial.YOLODetector import YOLODetector
 except ModuleNotFoundError as ex:
     logging.info(f"Module YOLODetector not found")
-try:
-    from .estimator.spatial.YOLOXE2EDetector import YOLOXE2EDetector
-except ModuleNotFoundError as ex:
-    logging.info(f"Module YOLOXE2EDetector not found")
-try:
-    from .estimator.spatial.YOLOv5Detector import YOLOv5Config
-except ModuleNotFoundError as ex:
-    logging.info(f"Module YOLOv5Config not found")
-try:
-    from .estimator.spatial.YOLOv5Detector import YOLOv5Detector
-except ModuleNotFoundError as ex:
-    logging.info(f"Module YOLOv5Detector not found")
+from .estimator.spatial.YOLOXE2EDetector import YOLOXE2EDetector
+from .estimator.spatial.YOLOv5Detector import YOLOv5Config
+from .estimator.spatial.YOLOv5Detector import YOLOv5Detector
 try:
     from .estimator.spatial.camera.ArUcoCameraPoseEstimator import ArUcoCameraPoseEstimator
 except ModuleNotFoundError as ex:
     logging.info(f"Module ArUcoCameraPoseEstimator not found")
 from .estimator.spatial.camera.BoardCameraCalibrator import BoardCameraCalibrator
 try:
     from .estimator.spatial.camera.ChArUcoCalibrator import ChArUcoCalibrator
@@ -158,18 +137,15 @@
     from .estimator.spatial.face.OpenVinoFaceDetector import OpenVinoFaceDetector
 except ModuleNotFoundError as ex:
     logging.info(f"Module OpenVinoFaceDetector not found")
 try:
     from .estimator.spatial.face.emotion.AffectNetEmotionClassifier import AffectNetEmotionClassifier
 except ModuleNotFoundError as ex:
     logging.info(f"Module AffectNetEmotionClassifier not found")
-try:
-    from .estimator.spatial.face.emotion.FERPlusEmotionClassifier import FERPlusEmotionClassifier
-except ModuleNotFoundError as ex:
-    logging.info(f"Module FERPlusEmotionClassifier not found")
+from .estimator.spatial.face.emotion.FERPlusEmotionClassifier import FERPlusEmotionClassifier
 from .estimator.spatial.face.emotion.FaceEmotionEstimator import FaceEmotionEstimator
 from .estimator.spatial.face.landmark.FaceLandmarkEstimator import FaceLandmarkEstimator
 try:
     from .estimator.spatial.face.landmark.IrisDistanceCalculator import IrisDistanceCalculator
 except ModuleNotFoundError as ex:
     logging.info(f"Module IrisDistanceCalculator not found")
 try:
@@ -224,22 +200,16 @@
     from .estimator.spatial.pose.EfficientPoseEstimator import EfficientPoseEstimator
 except ModuleNotFoundError as ex:
     logging.info(f"Module EfficientPoseEstimator not found")
 try:
     from .estimator.spatial.pose.EfficientPoseEstimator import EfficientPoseEstimatorConfig
 except ModuleNotFoundError as ex:
     logging.info(f"Module EfficientPoseEstimatorConfig not found")
-try:
-    from .estimator.spatial.pose.KAPAOPoseEstimator import KAPAOPoseConfig
-except ModuleNotFoundError as ex:
-    logging.info(f"Module KAPAOPoseConfig not found")
-try:
-    from .estimator.spatial.pose.KAPAOPoseEstimator import KAPAOPoseEstimator
-except ModuleNotFoundError as ex:
-    logging.info(f"Module KAPAOPoseEstimator not found")
+from .estimator.spatial.pose.KAPAOPoseEstimator import KAPAOPoseConfig
+from .estimator.spatial.pose.KAPAOPoseEstimator import KAPAOPoseEstimator
 try:
     from .estimator.spatial.pose.LiteHRNetEstimator import LiteHRNetConfig
 except ModuleNotFoundError as ex:
     logging.info(f"Module LiteHRNetConfig not found")
 try:
     from .estimator.spatial.pose.LiteHRNetEstimator import LiteHRNetPoseEstimator
 except ModuleNotFoundError as ex:
@@ -356,14 +326,15 @@
 from .model.CameraStreamType import CameraStreamType
 from .model.DepthBuffer import DepthBuffer
 from .model.VisionEngineOutput import VisionEngineOutput
 from .model.geometry.BoundingBox2D import BoundingBox2D
 from .model.geometry.Size2D import Size2D
 from .model.parameter.ArgumentConfigurable import ArgumentConfigurable
 from .model.tracker.Trackable import Trackable
+from .model.types.InputShapeOrder import InputShapeOrder
 from .model.types.ModelPrecision import ModelPrecision
 from .model.types.RealSenseColorScheme import RealSenseColorScheme
 from .node.ApplyNode import ApplyNode
 from .node.BreakpointNode import BreakpointNode
 from .node.CustomNode import CustomNode
 from .node.ExtractNode import ExtractNode
 from .node.PassThroughNode import PassThroughNode
```

## visiongraph/estimator/BaseVisionEngine.py

```diff
@@ -4,44 +4,47 @@
 import cv2
 import numpy as np
 import vector
 
 from visiongraph.model.VisionEngineOutput import VisionEngineOutput
 from visiongraph.model.geometry.BoundingBox2D import BoundingBox2D
 from visiongraph.model.geometry.Size2D import Size2D
+from visiongraph.model.types.InputShapeOrder import InputShapeOrder
 from visiongraph.util import ImageUtils
 
 
 class BaseVisionEngine(ABC):
     def __init__(self, flip_channels: bool = True,
                  scale: Optional[Union[float, Sequence[float]]] = None,
                  mean: Optional[Union[float, Sequence[float]]] = None,
                  padding: bool = False,
-                 transpose: bool = True):
+                 transpose: bool = True,
+                 order: InputShapeOrder = InputShapeOrder.NCHW):
 
         self.flip_channels = flip_channels
         self.scale = scale
         self.mean = mean
         self.padding = padding
         self.padding_color: Optional[Sequence[int]] = None
         self.transpose = transpose
+        self.order = order
 
         self.input_names: List[str] = []
         self.output_names: List[str] = []
 
         self.dynamic_input_shapes: Dict[str, List[int]] = dict()
 
     @abstractmethod
     def setup(self):
         pass
 
     def process(self, image: np.ndarray, inputs: Optional[Dict[str, Any]] = None) -> VisionEngineOutput:
         in_frame, padding_box, image_size = self.pre_process_image(image, self.first_input_name,
                                                                    self.flip_channels, self.scale, self.mean,
-                                                                   self.padding, self.transpose)
+                                                                   self.padding, self.transpose, self.order)
 
         if inputs is None:
             inputs = {}
 
         inputs.update({self.first_input_name: in_frame})
         outputs = self._inference(image, inputs)
 
@@ -55,17 +58,22 @@
     def _inference(self, image: np.ndarray, inputs: Optional[Dict[str, Any]] = None) -> VisionEngineOutput:
         pass
 
     def pre_process_image(self, image: np.ndarray, input_name: str, flip_channels: bool = True,
                           scale: Optional[Union[float, Sequence[float]]] = None,
                           mean: Optional[Union[float, Sequence[float]]] = None,
                           padding: bool = False,
-                          transpose: bool = True) -> Tuple[np.ndarray, BoundingBox2D, Size2D]:
+                          transpose: bool = True,
+                          order: InputShapeOrder = InputShapeOrder.NCHW) -> Tuple[np.ndarray, BoundingBox2D, Size2D]:
         input_channels = image.shape[-1] if image.ndim == 3 else 1
-        batch_size, channels, height, width = self.get_input_shape(input_name)
+
+        if order == InputShapeOrder.NWHC:
+            batch_size, width, height, channels = self.get_input_shape(input_name)
+        else:
+            batch_size, channels, height, width = self.get_input_shape(input_name)
 
         if padding:
             pc = self.padding_color if self.padding_color is not None else (0, 0, 0)
             in_frame, pad_bbox = ImageUtils.resize_and_pad(image, (width, height), pc)
         else:
             in_frame = cv2.resize(image, (width, height))
             pad_bbox = BoundingBox2D(0, 0, width, height)
@@ -93,16 +101,19 @@
         # transform to blob
         if transpose:
             if channels == 3:
                 in_frame = in_frame.transpose((2, 0, 1))
             else:
                 in_frame = in_frame.transpose((1, 0))
 
-        # make ncwh
-        in_frame = in_frame.reshape((1, channels, height, width))
+        # make nchw
+        if order == InputShapeOrder.NWHC:
+            in_frame = in_frame.reshape((1, width, height, channels))
+        else:
+            in_frame = in_frame.reshape((1, channels, height, width))
 
         return in_frame, pad_bbox, image_size
 
     def set_dynamic_input_shape(self, name: str, batch_size: int, channels: int, height: int, width: int):
         self.dynamic_input_shapes[name] = [batch_size, channels, height, width]
 
     @property
```

## visiongraph/estimator/engine/InferenceEngineFactory.py

```diff
@@ -1,32 +1,50 @@
+import logging
 from enum import Enum
-from typing import Sequence, Dict, Optional, Union
+from functools import partial
+from typing import Sequence, Dict, Optional, Union, Any
 
 from visiongraph.data.Asset import Asset
 from visiongraph.estimator.BaseVisionEngine import BaseVisionEngine
-from visiongraph.estimator.onnx.ONNXVisionEngine import ONNXVisionEngine
-from visiongraph.estimator.openvino.VisionInferenceEngine import VisionInferenceEngine
-from visiongraph.estimator.openvino.OpenVinoEngine import OpenVinoEngine
+from visiongraph.model.types.InputShapeOrder import InputShapeOrder
+
+
+def _get_onnx_vision_engine_type():
+    from visiongraph.estimator.onnx.ONNXVisionEngine import ONNXVisionEngine
+    return ONNXVisionEngine
+
+
+def _get_vision_inference_engine_type():
+    from visiongraph.estimator.openvino.VisionInferenceEngine import VisionInferenceEngine
+    return VisionInferenceEngine
+
+
+def _get_open_vino_engine_type():
+    from visiongraph.estimator.openvino.OpenVinoEngine import OpenVinoEngine
+    return OpenVinoEngine
 
 
 class InferenceEngine(Enum):
-    ONNX = ONNXVisionEngine
-    OpenVINO = VisionInferenceEngine
-    OpenVINO2 = OpenVinoEngine
+    ONNX = partial(_get_onnx_vision_engine_type)
+    OpenVINO = partial(_get_vision_inference_engine_type)
+    OpenVINO2 = partial(_get_open_vino_engine_type)
 
 
 class InferenceEngineFactory:
     @staticmethod
     def create(engine: InferenceEngine, assets: Sequence[Asset],
                flip_channels: bool = True,
                scale: Optional[Union[float, Sequence[float]]] = None,
                mean: Optional[Union[float, Sequence[float]]] = None,
                padding: bool = False,
                transpose: bool = True,
-               **engine_options: Dict) -> BaseVisionEngine:
+               order: InputShapeOrder = InputShapeOrder.NCHW,
+               **engine_options: Any) -> BaseVisionEngine:
         if len(assets) < 0:
             raise Exception("No model or weights provided for vision engine! At least one is required!")
 
-        instance = engine.value(*assets, flip_channels=flip_channels, scale=scale, mean=mean,
-                                padding=padding, **engine_options)
+        engine_type = engine.value()
+        instance = engine_type(*assets, flip_channels=flip_channels, scale=scale, mean=mean,
+                               padding=padding, **engine_options)
         instance.transpose = transpose
+        instance.order = order
         return instance
```

## visiongraph/input/AzureKinectInput.py

```diff
@@ -343,15 +343,15 @@
 
     def get_fisheye_distortion(self, stream_type: CameraStreamType = CameraStreamType.Color) -> np.ndarray:
         calibration = self.device.calibration
         return calibration.get_distortion_coefficients(self._to_k4a_calibration_type(stream_type))
 
     @property
     def serial(self) -> str:
-        return self.device.selected_serial
+        return self.device.serial
 
     @property
     def color(self) -> np.ndarray:
         if self._playback is None:
             return self.capture.color
 
         color = self._convert_to_bgra_if_required(self._playback.configuration["color_format"], self.capture.color)
```

## visiongraph/tracker/ObjectAssignmentSolver.py

```diff
@@ -79,10 +79,9 @@
 
     @staticmethod
     def iou_cost_function(tracks: List[T], detections: List[T]) -> np.ndarray:
         cost_mat = np.zeros((len(tracks), len(detections)), dtype=float)
 
         for y, track in enumerate(tracks):
             for x, detection in enumerate(detections):
-                cost_mat[y, x] = track.bounding_box.intersection_over_union(detection.bounding_box)
-
+                cost_mat[y, x] = 1.0 - track.bounding_box.intersection_over_union(detection.bounding_box)
         return cost_mat
```

## Comparing `visiongraph-0.1.45.1.dist-info/METADATA` & `visiongraph-0.1.46.1.dist-info/METADATA`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: visiongraph
-Version: 0.1.45.1
+Version: 0.1.46.1
 Summary: Visiongraph is a high level computer vision framework.
 Home-page: https://github.com/cansik/visiongraph
 Author: Florian Bruggisser
 Author-email: github@broox.ch
 License: MIT License
 Platform: UNKNOWN
 Classifier: Development Status :: 3 - Alpha
@@ -24,57 +24,52 @@
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Description-Content-Type: text/markdown
 Requires-Dist: wheel
 Requires-Dist: opencv-python (~=4.7.0)
 Requires-Dist: numpy (<=1.22.4)
 Requires-Dist: requests
 Requires-Dist: tqdm
-Requires-Dist: vector (~=0.10.0)
+Requires-Dist: vector (~=1.0.0)
 Requires-Dist: scipy
 Requires-Dist: filterpy
 Provides-Extra: all
 Requires-Dist: openvino (~=2022.3.0) ; extra == 'all'
-Requires-Dist: protobuf (<4,>=3.11) ; extra == 'all'
-Requires-Dist: onnxruntime (~=1.12.0) ; extra == 'all'
+Requires-Dist: mediapipe (~=0.10.0) ; extra == 'all'
+Requires-Dist: onnxruntime (~=1.15.0) ; extra == 'all'
 Requires-Dist: moviepy ; extra == 'all'
 Requires-Dist: vidgear[core] ; extra == 'all'
 Requires-Dist: numba ; extra == 'all'
 Requires-Dist: pyrealsense2 ; (platform_system != "Darwin") and extra == 'all'
-Requires-Dist: onnxruntime-gpu (~=1.12.0) ; (platform_system != "Darwin") and extra == 'all'
-Requires-Dist: mediapipe (~=0.9.1) ; (platform_system != "Darwin" or platform_machine != "arm64") and extra == 'all'
+Requires-Dist: onnxruntime-gpu (~=1.15.0) ; (platform_system != "Darwin") and extra == 'all'
 Requires-Dist: pyrealsense2-macosx ; (platform_system == "Darwin") and extra == 'all'
-Requires-Dist: onnxruntime (~=1.12.0) ; (platform_system == "Darwin") and extra == 'all'
+Requires-Dist: onnxruntime (~=1.15.0) ; (platform_system == "Darwin") and extra == 'all'
 Requires-Dist: syphonpy ; (platform_system == "Darwin") and extra == 'all'
 Requires-Dist: glfw ; (platform_system == "Darwin") and extra == 'all'
-Requires-Dist: mediapipe-silicon (~=0.9.1) ; (platform_system == "Darwin" and platform_machine == "arm64") and extra == 'all'
 Requires-Dist: pyopengl ; (platform_system == "Darwin" or platform_system == "Windows") and extra == 'all'
 Requires-Dist: SpoutGL (>=0.0.4) ; (platform_system == "Windows") and extra == 'all'
 Requires-Dist: pyk4a-bundle (~=1.3.0.2) ; (platform_system == "Windows" or platform_system == "Linux") and extra == 'all'
 Provides-Extra: azure
 Requires-Dist: pyk4a-bundle (~=1.3.0.2) ; (platform_system == "Windows" or platform_system == "Linux") and extra == 'azure'
 Provides-Extra: fbs
 Requires-Dist: syphonpy ; (platform_system == "Darwin") and extra == 'fbs'
 Requires-Dist: glfw ; (platform_system == "Darwin") and extra == 'fbs'
 Requires-Dist: pyopengl ; (platform_system == "Darwin" or platform_system == "Windows") and extra == 'fbs'
 Requires-Dist: SpoutGL (>=0.0.4) ; (platform_system == "Windows") and extra == 'fbs'
 Provides-Extra: media
 Requires-Dist: moviepy ; extra == 'media'
 Requires-Dist: vidgear[core] ; extra == 'media'
 Provides-Extra: mediapipe
-Requires-Dist: protobuf (<4,>=3.11) ; extra == 'mediapipe'
-Requires-Dist: mediapipe (~=0.9.1) ; (platform_system != "Darwin" or platform_machine != "arm64") and extra == 'mediapipe'
-Requires-Dist: mediapipe-silicon (~=0.9.1) ; (platform_system == "Darwin" and platform_machine == "arm64") and extra == 'mediapipe'
+Requires-Dist: mediapipe (~=0.10.0) ; extra == 'mediapipe'
 Provides-Extra: numba
 Requires-Dist: numba ; extra == 'numba'
 Provides-Extra: onnx
-Requires-Dist: onnxruntime (~=1.12.0) ; extra == 'onnx'
+Requires-Dist: onnxruntime (~=1.15.0) ; extra == 'onnx'
 Provides-Extra: onnx-gpu
-Requires-Dist: onnxruntime-gpu (~=1.12.0) ; (platform_system != "Darwin") and extra == 'onnx-gpu'
-Requires-Dist: onnxruntime (~=1.12.0) ; (platform_system == "Darwin") and extra == 'onnx-gpu'
-Provides-Extra: opencv-contrib
+Requires-Dist: onnxruntime-gpu (~=1.15.0) ; (platform_system != "Darwin") and extra == 'onnx-gpu'
+Requires-Dist: onnxruntime (~=1.15.0) ; (platform_system == "Darwin") and extra == 'onnx-gpu'
 Provides-Extra: openvino
 Requires-Dist: openvino (~=2022.3.0) ; extra == 'openvino'
 Provides-Extra: realsense
 Requires-Dist: pyrealsense2 ; (platform_system != "Darwin") and extra == 'realsense'
 Requires-Dist: pyrealsense2-macosx ; (platform_system == "Darwin") and extra == 'realsense'
 
 # ![image](https://user-images.githubusercontent.com/5220162/192808079-2043fb41-8637-4697-8286-985bc5340f37.png) Visiongraph [![PyPI](https://img.shields.io/pypi/v/visiongraph)](https://pypi.org/project/visiongraph/)
@@ -86,14 +81,16 @@
 import visiongraph as vg
 vg.create_graph(vg.VideoCaptureInput()).then(vg.ImagePreview()).open()
 ```
 
 The main goal is to implement a platform independent and high performance framework for day-to-day computer vision tasks.
 
 ## Installation
+Visiongraph supports python `3.9` and `3.10`. Other versions might work as well but are not officially supported.
+
 To install visiongraph with all dependencies call [pip](https://pypi.org/project/pip/) like this:
 
 ```bash
 pip install "visiongraph[all]"
 ```
 
 🚨 *Please note that visiongraph is in an early alpha phase and the API will still undergo changes.*
```

## Comparing `visiongraph-0.1.45.1.dist-info/RECORD` & `visiongraph-0.1.46.1.dist-info/RECORD`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 visiongraph/AsyncGraphNode.py,sha256=sGVtD16mFM0okNXW9wdEHVJ9zzd7tD4gLFIA2lP4Wpo,1758
 visiongraph/BaseGraph.py,sha256=q_UPq53arsmW2wnZMo-jD9bGby2WFNTWwSBMvSLsxfU,2806
 visiongraph/GraphNode.py,sha256=o2uAgN4WknZV1b3gMIKF3TUFRahRRu7AdXiuXMX4hYI,678
 visiongraph/Processable.py,sha256=bhe_zj7nT2xgmD0xYM_BEWMmDlAUtjfsi3jfdLhMb60,276
 visiongraph/VisionGraph.py,sha256=d5EkjL24hmRteBXfSqZD9xfglkM4bDUIZl4GFlhADcQ,2094
 visiongraph/VisionGraphBuilder.py,sha256=i0bn8HLb3yRACeblpk4yFtMJ6hY61R46mFL1Pdkw_Vg,1898
-visiongraph/__init__.py,sha256=SHHHJYouS_lox1DrVHtKj4anOg85DJLa-bG6q7qqRo8,24206
+visiongraph/__init__.py,sha256=5abu-W0E8v0LUBU6j8AhIL5DNoAoFyTOzEsyTgfWqYg,23273
 visiongraph/cache/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 visiongraph/data/Asset.py,sha256=N43JxIuOjCmW9CropssmFaXvrtIFnQ382YvXT2nfdlM,368
 visiongraph/data/LocalAsset.py,sha256=7AIWlgdwaWHBiC0RbooqpWoRf68nQx3AT0wWdfJ4hk8,376
 visiongraph/data/RepositoryAsset.py,sha256=D9Vmjn4qKjtUdHHryRHVVKaZZg8jWExZX2frDNt2NwE,1099
 visiongraph/data/__init__.py,sha256=-6VQqFg1a72cAwplIbNMVHTDMm7pXqh_-EuWr0gwgrY,324
 visiongraph/data/labels/COCO.py,sha256=4kP0wW4j16KIfdmCPhPNlQAnacZ3Etp2XC8LeECbe5A,2568
 visiongraph/data/labels/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
@@ -17,23 +17,23 @@
 visiongraph/dsp/OneEuroFilter.py,sha256=a-VOOwP0mMZcNYgB3ltIbupv7Ft-cbijDfKgSx7roKo,1487
 visiongraph/dsp/OneEuroFilterNumba.py,sha256=Qn7h80kHKQ4keYGw8i3TG7--Vz6cRwBGT-ywY2frqjI,1651
 visiongraph/dsp/OneEuroFilterNumpy.py,sha256=RjAqFZ0xmC3PLW0e8o6gAUJR9UPrhNgEprZbs5_aIqY,2642
 visiongraph/dsp/VectorNumpySmoothFilter.py,sha256=THcMeAIxZnCtox6HtplGzZsxRO9xb1fPu0DVkpCoCcw,1037
 visiongraph/dsp/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 visiongraph/estimator/BaseClassifier.py,sha256=DUoRQf-RGLS2fbYuGgxVbwi01OZQt0cXApnzrZ1Lx0E,619
 visiongraph/estimator/BaseEstimator.py,sha256=ZAEfHAr70johC9YREIeR4TcHFXRa1MWsb_2MpEAQVHM,397
-visiongraph/estimator/BaseVisionEngine.py,sha256=HFN_lJQFlA72c1JTrFxWrw9awZm_VpJ0Vn8YXGecevk,4345
+visiongraph/estimator/BaseVisionEngine.py,sha256=FFXOXRUhgNWZOApPnSyIrPKa1jprqlibpvep90cJu0U,4863
 visiongraph/estimator/ChainEstimator.py,sha256=MmZkwqBkL1w7t6k60mBn9bKfDx7cP1UGfLicASQfeEw,1100
 visiongraph/estimator/ScoreThresholdEstimator.py,sha256=ZqOctLVH052VwKGRj2EIPY9ngGIi8411LBEDEjJnW_o,403
 visiongraph/estimator/VisionClassifier.py,sha256=rBb-yuVKPIz3YVsvCu2HCAWh76mclIJWLTCjncKkXIA,868
 visiongraph/estimator/VisionEstimator.py,sha256=dPAVLBMGGey_zy9AGCVr0kQYu3QP7KTzScZ-1UEgaPo,410
 visiongraph/estimator/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 visiongraph/estimator/calculator/UndistortionCalculator.py,sha256=IV7Vgc7UMUkXsAS7tBYespukRL5f52Q-VxOfh5wNhIc,2448
 visiongraph/estimator/calculator/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-visiongraph/estimator/engine/InferenceEngineFactory.py,sha256=PPMjIKD2vpAjnOecevvR7GhQCc4IUKvtyYM7Z5_lE9w,1335
+visiongraph/estimator/engine/InferenceEngineFactory.py,sha256=eLM5jqqfm8AI24vQNA_wfMkFQgj2pUM4dVyWizTWnek,1859
 visiongraph/estimator/engine/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 visiongraph/estimator/inpaint/BaseInpainter.py,sha256=D-YtOAvQpMIZx2dMp4sYuX_U4-GAxW8EUnQMUmW_9hg,529
 visiongraph/estimator/inpaint/GMCNNInpainter.py,sha256=vr_9uV8gmYEOWSUYfEW3iQQJVkRpQC5YGyC2QvUDpRs,2161
 visiongraph/estimator/inpaint/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 visiongraph/estimator/onnx/ONNXVisionEngine.py,sha256=HYpTOBFUbg1fDkqoeoY2i3p8s4YoN7EWRu1byX8zz3I,2532
 visiongraph/estimator/onnx/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 visiongraph/estimator/openvino/OpenVinoEngine.py,sha256=bo0I_SoiR3MS6YI7Rc9I_U7yExvRWz89riL3qWfsHuE,2337
@@ -142,15 +142,15 @@
 visiongraph/external/motpy/tracker.py,sha256=S7Gtjkm1Nb9DEmqn9WyHK5hLQMgj20O6SrjD23TY-Gg,16512
 visiongraph/external/motpy/utils.py,sha256=Yed57TN_oc8BNXDhk1WMeJMJiltGJuIMrHnvPq_qBD4,652
 visiongraph/external/motrackers/Track.py,sha256=feiTQa_G6GH8fIc_3_rC7gEr2Jch9sn_QP6fXDNlhFQ,5312
 visiongraph/external/motrackers/Tracker.py,sha256=x9c5Yt8eSVmDdyZjh76bE1oWeTBRnP3yT3jyUDMOgMg,7486
 visiongraph/external/motrackers/__init__.py,sha256=oZ27LMiAAmB0_j5sMJ8wL-z66BGOtBzSn46bc2HV-0Q,184
 visiongraph/external/motrackers/utils/__init__.py,sha256=wfsRUA77UC208Y2lKT-usnynHzGVjH4_8BYqsY0UWh0,83
 visiongraph/external/motrackers/utils/misc.py,sha256=Q4QuYxw3nb6frDHRVREghVzRm9oWZFua3jDG_uBkTt8,8978
-visiongraph/input/AzureKinectInput.py,sha256=SYkl3X6W2P55gVpS5MtwOCTdWHpMbT6UHs6fbqiApZc,16025
+visiongraph/input/AzureKinectInput.py,sha256=mjZQ980KC70m7Ag8HLs8rKonYYeIF6pJKGTz4KEJq_g,16016
 visiongraph/input/BaseDepthCamera.py,sha256=q3HngshC9ukpMF9RPG-ZHMVE1nuzjKphZ1MWvPgEc0s,4108
 visiongraph/input/BaseDepthInput.py,sha256=3nYxcLLLlPkT4oPewVQJMcLf8u3J5AABEW84qICY0mA,1309
 visiongraph/input/BaseInput.py,sha256=Uji-uvrAnHHXsTIBmT5wKDQGj9uO1NUlFLJHMvoAw0E,3760
 visiongraph/input/CamGearInput.py,sha256=FVQROPlYVpVrk2CqVeg_bT83Z0UkN9GsCLj0lUg2SZs,1721
 visiongraph/input/ImageInput.py,sha256=fX0sJcNcnd3vnu_2_23kpFPNr7goJNy7OIeERznTEjI,1493
 visiongraph/input/RealSenseInput.py,sha256=Fora-6lEjSkjpgYaXUOLBAG-I82I9mhSEhmEn4YSXhU,19563
 visiongraph/input/VideoCaptureInput.py,sha256=hupeQtiYPJyc610Hjpp8PleWQ1_Guvx0Xkvw0bOgmmE,5032
@@ -165,14 +165,15 @@
 visiongraph/model/geometry/Size2D.py,sha256=-t2jPBKm1vkEdRz7KKE16pTwqg6JUSZrDJGIoB48X_4,815
 visiongraph/model/geometry/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 visiongraph/model/parameter/ArgumentConfigurable.py,sha256=UOmxjHVaCl7In0KWPFah1hT6FLtyKg4rK13D35hxjKI,585
 visiongraph/model/parameter/NamedParameter.py,sha256=gtqJvJFVQDtjSYJ4mcYvLifcm8i_x4U15KE-hVs8iNk,186
 visiongraph/model/parameter/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 visiongraph/model/tracker/Trackable.py,sha256=ZU-UBUdmace5tw4fUQNHxp0mOmvwTOtlhdIPlvP_mW0,399
 visiongraph/model/tracker/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+visiongraph/model/types/InputShapeOrder.py,sha256=Js2qH2a3K84-2yWrZ3F5Phkf8Sb9h-EXAF1zmS9CPI0,78
 visiongraph/model/types/ModelPrecision.py,sha256=2V7UqU_zCBhYconQbucNJgrxd2pkR0rIsZoi-yUjfHw,440
 visiongraph/model/types/RealSenseColorScheme.py,sha256=NFW2G0FtMYo7L5OXIkEuui9I0_mlPB7eJTr_uXy2kVQ,199
 visiongraph/model/types/RealSenseFilter.py,sha256=LgE_b4cBfgoLFLs7vN8nDtZ0wb_Mj1zv3SW4pgdTM9s,204
 visiongraph/model/types/VideoCaptureBackend.py,sha256=ytj7-X9J3nzK5r1xRSCcGMGKV4Zub4pYawYeTQUvbUk,1180
 visiongraph/model/types/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 visiongraph/node/ApplyNode.py,sha256=Nnti2_aIxUlfwQB4hOrrk_Koe71tSJW116eHVZu7nBY,905
 visiongraph/node/BreakpointNode.py,sha256=EEZq8vU_dDyST6htesvxAv9hM5V21qQJOXnBCptEpUU,753
@@ -235,15 +236,15 @@
 visiongraph/result/spatial/pose/MobileHumanPose.py,sha256=GpOtG1VGrJxMKVzIUvp49p9MrhuyDhLjqvijDoD9ylk,2738
 visiongraph/result/spatial/pose/PoseLandmarkResult.py,sha256=OSsw0WYQlbQ9MxxKuOZdIsjBAzI9CfT9H0bDkqWwWn4,2823
 visiongraph/result/spatial/pose/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 visiongraph/tracker/BaseObjectDetectionTracker.py,sha256=4e_1Cla7hT3BFRDSUmTgS3KfphYs0YcU2-9HIbYolNQ,492
 visiongraph/tracker/CentroidTracker.py,sha256=JVxG5CAu0rjgntMl2c4XGUj3hMybxcnKIvcJmH1QsxM,1908
 visiongraph/tracker/FlateTracker.py,sha256=9T8qmL0Z4WYuw3m4tx4MDE1Owg8ui46TUvcQfjdR7L8,4906
 visiongraph/tracker/MotpyTracker.py,sha256=NJ4wUYRsJy4Ns5aKlze4_JdEwjWByXoW3lgUs1hamgM,2705
-visiongraph/tracker/ObjectAssignmentSolver.py,sha256=UnatM7p0547-hrvLtcplD5PsZabpxZWoKa_wqnEVK-I,3299
+visiongraph/tracker/ObjectAssignmentSolver.py,sha256=QsGXRFLNIS1UllYh0EnMUXc74HTmX12EMaEB0gXh0Bg,3304
 visiongraph/tracker/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 visiongraph/util/ArgUtils.py,sha256=ScmV828V-II5p0Wtpux1pDYDPENfka9cdzp8kLqSazI,3105
 visiongraph/util/CodeUtils.py,sha256=6xx82UlfereWKI7yczCApgTgOquvDXLONnfysSVYoiQ,1009
 visiongraph/util/CollectionUtils.py,sha256=IR178KrIULFRiSZzSMQkH78AaTvjhpaGFjJ57jZu0vw,222
 visiongraph/util/CommonArgs.py,sha256=sLhJv-vgMkaSCwbrfpDsZy8cAK7-kTAa5pnw_X_gqgU,314
 visiongraph/util/DrawingUtils.py,sha256=7_vksJauc7scpmFKHs8_S5xviGQoOd4n_p7sfix5G2U,3653
 visiongraph/util/ImageUtils.py,sha256=_eP8x8IrRiQv7IIOPsrBXFycGa8IgOPfKk_xsF9syi8,3588
@@ -253,12 +254,12 @@
 visiongraph/util/NetworkUtils.py,sha256=JIYgwgTfbPfHmMtLGEZmouWUgRDkafmLJ78NlMb8eIQ,2084
 visiongraph/util/OSUtils.py,sha256=B1wbK-iZMKCfVJf1j_0GGAror2VEDto1aikTBnhcEqw,195
 visiongraph/util/OpenVinoUtils.py,sha256=aQNS4nHxi16TZArVqQLZNZMEwOuJR-lUEGBwT8zr6Es,704
 visiongraph/util/ResultUtils.py,sha256=ow5p1FtfIIuXo7VJMBQz0cuaG0nfZr0NO9LnTJrWgH8,1240
 visiongraph/util/TimeUtils.py,sha256=IVCLc5PtSYhmGB8hp6-oZMceva8Y6uU0K_1BDTZXGmE,2102
 visiongraph/util/VectorUtils.py,sha256=OSjJ1LGBQiEJp-wEocJvLXM1CyS09LesNA-H86Irnjw,3225
 visiongraph/util/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-visiongraph-0.1.45.1.dist-info/METADATA,sha256=SNbW0HeE9TUsuEMYs-tG3QZVHzvosKsk0uasV1Y-dac,11847
-visiongraph-0.1.45.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-visiongraph-0.1.45.1.dist-info/entry_points.txt,sha256=eqGnTHtEVMYwfXVk1Z9MhC8O2N8wuqAbr0lisLmrkxs,20
-visiongraph-0.1.45.1.dist-info/top_level.txt,sha256=rMp8bfRr_CcL2T8juTpUUszIVf1_BFmagl0lhq3L16o,12
-visiongraph-0.1.45.1.dist-info/RECORD,,
+visiongraph-0.1.46.1.dist-info/METADATA,sha256=bZ7kTckbhOl8_Iq9DX1W2aD6zO1jSvu5mTRJMbVaJos,11432
+visiongraph-0.1.46.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+visiongraph-0.1.46.1.dist-info/entry_points.txt,sha256=eqGnTHtEVMYwfXVk1Z9MhC8O2N8wuqAbr0lisLmrkxs,20
+visiongraph-0.1.46.1.dist-info/top_level.txt,sha256=rMp8bfRr_CcL2T8juTpUUszIVf1_BFmagl0lhq3L16o,12
+visiongraph-0.1.46.1.dist-info/RECORD,,
```

