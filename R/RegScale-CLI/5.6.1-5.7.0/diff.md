# Comparing `tmp/RegScale_CLI-5.6.1-py3-none-any.whl.zip` & `tmp/RegScale_CLI-5.7.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,119 +1,118 @@
-Zip file size: 258032 bytes, number of entries: 117
--rw-r--r--  2.0 unx       22 b- defN 23-Jun-07 14:36 regscale/__init__.py
--rw-r--r--  2.0 unx    15241 b- defN 23-Jun-07 14:36 regscale/regscale.py
--rw-r--r--  2.0 unx      270 b- defN 23-Jun-07 14:36 regscale/airflow/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/airflow/tasks/__init__.py
--rw-r--r--  2.0 unx     3308 b- defN 23-Jun-07 14:36 regscale/airflow/tasks/cli.py
--rw-r--r--  2.0 unx      262 b- defN 23-Jun-07 14:36 regscale/ansible/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/core/__init__.py
--rw-r--r--  2.0 unx     1553 b- defN 23-Jun-07 14:36 regscale/core/login.py
--rw-r--r--  2.0 unx      129 b- defN 23-Jun-07 14:36 regscale/core/app/__init__.py
--rw-r--r--  2.0 unx    14666 b- defN 23-Jun-07 14:36 regscale/core/app/api.py
--rw-r--r--  2.0 unx    13607 b- defN 23-Jun-07 14:36 regscale/core/app/application.py
--rw-r--r--  2.0 unx     1206 b- defN 23-Jun-07 14:36 regscale/core/app/logz.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/core/app/internal/__init__.py
--rw-r--r--  2.0 unx    27214 b- defN 23-Jun-07 14:36 regscale/core/app/internal/admin_actions.py
--rw-r--r--  2.0 unx    31088 b- defN 23-Jun-07 14:36 regscale/core/app/internal/assessments_editor.py
--rw-r--r--  2.0 unx      979 b- defN 23-Jun-07 14:36 regscale/core/app/internal/catalog.py
--rw-r--r--  2.0 unx    16694 b- defN 23-Jun-07 14:36 regscale/core/app/internal/comparison.py
--rw-r--r--  2.0 unx    15364 b- defN 23-Jun-07 14:36 regscale/core/app/internal/control_editor.py
--rw-r--r--  2.0 unx     5948 b- defN 23-Jun-07 14:36 regscale/core/app/internal/encrypt.py
--rw-r--r--  2.0 unx    40204 b- defN 23-Jun-07 14:36 regscale/core/app/internal/evidence.py
--rw-r--r--  2.0 unx     2367 b- defN 23-Jun-07 14:36 regscale/core/app/internal/healthcheck.py
--rw-r--r--  2.0 unx     6513 b- defN 23-Jun-07 14:36 regscale/core/app/internal/login.py
--rw-r--r--  2.0 unx     9712 b- defN 23-Jun-07 14:36 regscale/core/app/internal/migrations.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/core/app/public/__init__.py
--rw-r--r--  2.0 unx    11879 b- defN 23-Jun-07 14:36 regscale/core/app/public/emass.py
--rw-r--r--  2.0 unx    62097 b- defN 23-Jun-07 14:36 regscale/core/app/public/fedramp.py
--rw-r--r--  2.0 unx     9000 b- defN 23-Jun-07 14:36 regscale/core/app/public/nist_catalog.py
--rw-r--r--  2.0 unx    87151 b- defN 23-Jun-07 14:36 regscale/core/app/public/oscal.py
--rw-r--r--  2.0 unx     6125 b- defN 23-Jun-07 14:36 regscale/core/app/public/otx.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/core/app/utils/__init__.py
--rw-r--r--  2.0 unx    23790 b- defN 23-Jun-07 14:36 regscale/core/app/utils/app_utils.py
--rw-r--r--  2.0 unx    10613 b- defN 23-Jun-07 14:36 regscale/core/app/utils/regscale_utils.py
--rw-r--r--  2.0 unx     1605 b- defN 23-Jun-07 14:36 regscale/core/app/utils/threadhandler.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/core/app/utils/catalog_utils/__init__.py
--rw-r--r--  2.0 unx     9213 b- defN 23-Jun-07 14:36 regscale/core/app/utils/catalog_utils/compare_catalog.py
--rw-r--r--  2.0 unx     4467 b- defN 23-Jun-07 14:36 regscale/core/app/utils/catalog_utils/diagnostic_catalog.py
--rw-r--r--  2.0 unx     2727 b- defN 23-Jun-07 14:36 regscale/core/app/utils/catalog_utils/export_catalog.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/core/static/__init__.py
--rw-r--r--  2.0 unx      383 b- defN 23-Jun-07 14:36 regscale/core/static/regex.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/core/utils/__init__.py
--rw-r--r--  2.0 unx     8037 b- defN 23-Jun-07 14:36 regscale/core/utils/graphql.py
--rw-r--r--  2.0 unx      583 b- defN 23-Jun-07 14:36 regscale/core/utils/urls.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/exceptions/__init__.py
--rw-r--r--  2.0 unx      195 b- defN 23-Jun-07 14:36 regscale/exceptions/license_exception.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/integrations/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/__init__.py
--rw-r--r--  2.0 unx    16252 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/ad.py
--rw-r--r--  2.0 unx    12882 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/aws.py
--rw-r--r--  2.0 unx    46871 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/defender.py
--rw-r--r--  2.0 unx     8720 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/jira.py
--rw-r--r--  2.0 unx    30770 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/okta.py
--rw-r--r--  2.0 unx    31505 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/qualys.py
--rw-r--r--  2.0 unx    12466 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/servicenow.py
--rw-r--r--  2.0 unx    63117 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/stig.py
--rw-r--r--  2.0 unx    22684 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/tenable.py
--rw-r--r--  2.0 unx    62197 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/wiz.py
--rw-r--r--  2.0 unx      206 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/azure/__init__.py
--rw-r--r--  2.0 unx     1049 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/azure/common.py
--rw-r--r--  2.0 unx    13876 b- defN 23-Jun-07 14:36 regscale/integrations/commercial/azure/intune.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/integrations/public/__init__.py
--rw-r--r--  2.0 unx    18680 b- defN 23-Jun-07 14:36 regscale/integrations/public/cisa.py
--rw-r--r--  2.0 unx      153 b- defN 23-Jun-07 14:36 regscale/models/__init__.py
--rw-r--r--  2.0 unx     4865 b- defN 23-Jun-07 14:36 regscale/models/config.py
--rw-r--r--  2.0 unx     3453 b- defN 23-Jun-07 14:36 regscale/models/platform.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/models/app_models/__init__.py
--rw-r--r--  2.0 unx     7553 b- defN 23-Jun-07 14:36 regscale/models/app_models/catalog_compare.py
--rw-r--r--  2.0 unx     4006 b- defN 23-Jun-07 14:36 regscale/models/app_models/click.py
--rw-r--r--  2.0 unx    13918 b- defN 23-Jun-07 14:36 regscale/models/app_models/control_editor.py
--rw-r--r--  2.0 unx      889 b- defN 23-Jun-07 14:36 regscale/models/app_models/pipeline.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/models/integration_models/__init__.py
--rw-r--r--  2.0 unx     7858 b- defN 23-Jun-07 14:36 regscale/models/integration_models/azure_alerts.py
--rw-r--r--  2.0 unx      872 b- defN 23-Jun-07 14:36 regscale/models/integration_models/recommendations.py
--rw-r--r--  2.0 unx     8319 b- defN 23-Jun-07 14:36 regscale/models/integration_models/tenable.py
--rw-r--r--  2.0 unx     1833 b- defN 23-Jun-07 14:36 regscale/models/integration_models/wiz.py
--rw-r--r--  2.0 unx      257 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/__init__.py
--rw-r--r--  2.0 unx     6688 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/assessment.py
--rw-r--r--  2.0 unx     5447 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/asset.py
--rw-r--r--  2.0 unx     7157 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/checklist.py
--rw-r--r--  2.0 unx     1906 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/components.py
--rw-r--r--  2.0 unx    10977 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/control_implementation.py
--rw-r--r--  2.0 unx     1465 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/control_objective.py
--rw-r--r--  2.0 unx     6359 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/implementation_objective.py
--rw-r--r--  2.0 unx     3032 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/implementation_option.py
--rw-r--r--  2.0 unx     4172 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/incident.py
--rw-r--r--  2.0 unx     2850 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/interconnects.py
--rw-r--r--  2.0 unx    11337 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/issue.py
--rw-r--r--  2.0 unx     4892 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/modules.py
--rw-r--r--  2.0 unx      232 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/objective.py
--rw-r--r--  2.0 unx     2353 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/ports_protocols.py
--rw-r--r--  2.0 unx     2415 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/requirements.py
--rw-r--r--  2.0 unx     5524 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/security_control.py
--rw-r--r--  2.0 unx     5886 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/securityplans.py
--rw-r--r--  2.0 unx    26126 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/stig.py
--rw-r--r--  2.0 unx     1425 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/threat.py
--rw-r--r--  2.0 unx     2242 b- defN 23-Jun-07 14:36 regscale/models/regscale_models/user.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/utils/__init__.py
--rw-r--r--  2.0 unx     3893 b- defN 23-Jun-07 14:36 regscale/utils/shell.py
--rw-r--r--  2.0 unx       48 b- defN 23-Jun-07 14:36 regscale/utils/string.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 regscale/validation/__init__.py
--rw-r--r--  2.0 unx      422 b- defN 23-Jun-07 14:36 regscale/validation/address.py
--rw-r--r--  2.0 unx     1405 b- defN 23-Jun-07 14:36 regscale/validation/record.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 tests/mocks/__init__.py
--rw-r--r--  2.0 unx       99 b- defN 23-Jun-07 14:36 tests/mocks/objects.py
--rw-r--r--  2.0 unx     1039 b- defN 23-Jun-07 14:36 tests/mocks/response.py
--rw-r--r--  2.0 unx      260 b- defN 23-Jun-07 14:36 tests/mocks/xml.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 tests/regscale/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 tests/regscale/core/__init__.py
--rw-r--r--  2.0 unx     1172 b- defN 23-Jun-07 14:36 tests/regscale/core/test_login.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-07 14:36 tests/regscale/models/__init__.py
--rw-r--r--  2.0 unx      810 b- defN 23-Jun-07 14:36 tests/regscale/models/test_config.py
--rw-r--r--  2.0 unx      856 b- defN 23-Jun-07 14:36 tests/regscale/models/test_platform.py
--rw-r--r--  2.0 unx     1076 b- defN 23-Jun-07 14:36 RegScale_CLI-5.6.1.dist-info/LICENSE
--rw-r--r--  2.0 unx     6658 b- defN 23-Jun-07 14:36 RegScale_CLI-5.6.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-07 14:36 RegScale_CLI-5.6.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       52 b- defN 23-Jun-07 14:36 RegScale_CLI-5.6.1.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       26 b- defN 23-Jun-07 14:36 RegScale_CLI-5.6.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    10982 b- defN 23-Jun-07 14:36 RegScale_CLI-5.6.1.dist-info/RECORD
-117 files, 980838 bytes uncompressed, 240262 bytes compressed:  75.5%
+Zip file size: 256604 bytes, number of entries: 116
+-rw-r--r--  2.0 unx       22 b- defN 23-Jun-21 15:24 regscale/__init__.py
+-rw-r--r--  2.0 unx    15470 b- defN 23-Jun-21 15:24 regscale/regscale.py
+-rw-r--r--  2.0 unx      270 b- defN 23-Jun-21 15:24 regscale/airflow/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/airflow/tasks/__init__.py
+-rw-r--r--  2.0 unx     3308 b- defN 23-Jun-21 15:24 regscale/airflow/tasks/cli.py
+-rw-r--r--  2.0 unx      262 b- defN 23-Jun-21 15:24 regscale/ansible/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/core/__init__.py
+-rw-r--r--  2.0 unx     1553 b- defN 23-Jun-21 15:24 regscale/core/login.py
+-rw-r--r--  2.0 unx      129 b- defN 23-Jun-21 15:24 regscale/core/app/__init__.py
+-rw-r--r--  2.0 unx    14666 b- defN 23-Jun-21 15:24 regscale/core/app/api.py
+-rw-r--r--  2.0 unx    13607 b- defN 23-Jun-21 15:24 regscale/core/app/application.py
+-rw-r--r--  2.0 unx     1206 b- defN 23-Jun-21 15:24 regscale/core/app/logz.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/core/app/internal/__init__.py
+-rw-r--r--  2.0 unx    27214 b- defN 23-Jun-21 15:24 regscale/core/app/internal/admin_actions.py
+-rw-r--r--  2.0 unx    35836 b- defN 23-Jun-21 15:24 regscale/core/app/internal/assessments_editor.py
+-rw-r--r--  2.0 unx      979 b- defN 23-Jun-21 15:24 regscale/core/app/internal/catalog.py
+-rw-r--r--  2.0 unx    16694 b- defN 23-Jun-21 15:24 regscale/core/app/internal/comparison.py
+-rw-r--r--  2.0 unx    15694 b- defN 23-Jun-21 15:24 regscale/core/app/internal/control_editor.py
+-rw-r--r--  2.0 unx     5948 b- defN 23-Jun-21 15:24 regscale/core/app/internal/encrypt.py
+-rw-r--r--  2.0 unx    40204 b- defN 23-Jun-21 15:24 regscale/core/app/internal/evidence.py
+-rw-r--r--  2.0 unx     2367 b- defN 23-Jun-21 15:24 regscale/core/app/internal/healthcheck.py
+-rw-r--r--  2.0 unx     6680 b- defN 23-Jun-21 15:24 regscale/core/app/internal/login.py
+-rw-r--r--  2.0 unx     9712 b- defN 23-Jun-21 15:24 regscale/core/app/internal/migrations.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/core/app/public/__init__.py
+-rw-r--r--  2.0 unx    11879 b- defN 23-Jun-21 15:24 regscale/core/app/public/emass.py
+-rw-r--r--  2.0 unx    62097 b- defN 23-Jun-21 15:24 regscale/core/app/public/fedramp.py
+-rw-r--r--  2.0 unx     9000 b- defN 23-Jun-21 15:24 regscale/core/app/public/nist_catalog.py
+-rw-r--r--  2.0 unx    87240 b- defN 23-Jun-21 15:24 regscale/core/app/public/oscal.py
+-rw-r--r--  2.0 unx     6125 b- defN 23-Jun-21 15:24 regscale/core/app/public/otx.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/core/app/utils/__init__.py
+-rw-r--r--  2.0 unx    24794 b- defN 23-Jun-21 15:24 regscale/core/app/utils/app_utils.py
+-rw-r--r--  2.0 unx    10938 b- defN 23-Jun-21 15:24 regscale/core/app/utils/regscale_utils.py
+-rw-r--r--  2.0 unx     1605 b- defN 23-Jun-21 15:24 regscale/core/app/utils/threadhandler.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/core/app/utils/catalog_utils/__init__.py
+-rw-r--r--  2.0 unx     9213 b- defN 23-Jun-21 15:24 regscale/core/app/utils/catalog_utils/compare_catalog.py
+-rw-r--r--  2.0 unx     4467 b- defN 23-Jun-21 15:24 regscale/core/app/utils/catalog_utils/diagnostic_catalog.py
+-rw-r--r--  2.0 unx     2727 b- defN 23-Jun-21 15:24 regscale/core/app/utils/catalog_utils/export_catalog.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/core/static/__init__.py
+-rw-r--r--  2.0 unx      383 b- defN 23-Jun-21 15:24 regscale/core/static/regex.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/core/utils/__init__.py
+-rw-r--r--  2.0 unx     8037 b- defN 23-Jun-21 15:24 regscale/core/utils/graphql.py
+-rw-r--r--  2.0 unx      583 b- defN 23-Jun-21 15:24 regscale/core/utils/urls.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/exceptions/__init__.py
+-rw-r--r--  2.0 unx      195 b- defN 23-Jun-21 15:24 regscale/exceptions/license_exception.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/integrations/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/__init__.py
+-rw-r--r--  2.0 unx    16252 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/ad.py
+-rw-r--r--  2.0 unx    12882 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/aws.py
+-rw-r--r--  2.0 unx    46871 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/defender.py
+-rw-r--r--  2.0 unx     8720 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/jira.py
+-rw-r--r--  2.0 unx    30770 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/okta.py
+-rw-r--r--  2.0 unx    31505 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/qualys.py
+-rw-r--r--  2.0 unx    12466 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/servicenow.py
+-rw-r--r--  2.0 unx    63117 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/stig.py
+-rw-r--r--  2.0 unx    22684 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/tenable.py
+-rw-r--r--  2.0 unx    62697 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/wiz.py
+-rw-r--r--  2.0 unx      206 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/azure/__init__.py
+-rw-r--r--  2.0 unx     1049 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/azure/common.py
+-rw-r--r--  2.0 unx    13876 b- defN 23-Jun-21 15:24 regscale/integrations/commercial/azure/intune.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/integrations/public/__init__.py
+-rw-r--r--  2.0 unx    18680 b- defN 23-Jun-21 15:24 regscale/integrations/public/cisa.py
+-rw-r--r--  2.0 unx      153 b- defN 23-Jun-21 15:24 regscale/models/__init__.py
+-rw-r--r--  2.0 unx     4865 b- defN 23-Jun-21 15:24 regscale/models/config.py
+-rw-r--r--  2.0 unx     3453 b- defN 23-Jun-21 15:24 regscale/models/platform.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/models/app_models/__init__.py
+-rw-r--r--  2.0 unx     7553 b- defN 23-Jun-21 15:24 regscale/models/app_models/catalog_compare.py
+-rw-r--r--  2.0 unx     4006 b- defN 23-Jun-21 15:24 regscale/models/app_models/click.py
+-rw-r--r--  2.0 unx      889 b- defN 23-Jun-21 15:24 regscale/models/app_models/pipeline.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/models/integration_models/__init__.py
+-rw-r--r--  2.0 unx     7858 b- defN 23-Jun-21 15:24 regscale/models/integration_models/azure_alerts.py
+-rw-r--r--  2.0 unx      872 b- defN 23-Jun-21 15:24 regscale/models/integration_models/recommendations.py
+-rw-r--r--  2.0 unx     8319 b- defN 23-Jun-21 15:24 regscale/models/integration_models/tenable.py
+-rw-r--r--  2.0 unx     1833 b- defN 23-Jun-21 15:24 regscale/models/integration_models/wiz.py
+-rw-r--r--  2.0 unx      257 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/__init__.py
+-rw-r--r--  2.0 unx     6688 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/assessment.py
+-rw-r--r--  2.0 unx     5447 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/asset.py
+-rw-r--r--  2.0 unx     7157 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/checklist.py
+-rw-r--r--  2.0 unx     1906 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/components.py
+-rw-r--r--  2.0 unx    10977 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/control_implementation.py
+-rw-r--r--  2.0 unx     1465 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/control_objective.py
+-rw-r--r--  2.0 unx     6359 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/implementation_objective.py
+-rw-r--r--  2.0 unx     3032 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/implementation_option.py
+-rw-r--r--  2.0 unx     4172 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/incident.py
+-rw-r--r--  2.0 unx     2850 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/interconnects.py
+-rw-r--r--  2.0 unx    11337 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/issue.py
+-rw-r--r--  2.0 unx     4892 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/modules.py
+-rw-r--r--  2.0 unx      232 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/objective.py
+-rw-r--r--  2.0 unx     2353 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/ports_protocols.py
+-rw-r--r--  2.0 unx     2415 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/requirements.py
+-rw-r--r--  2.0 unx     5524 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/security_control.py
+-rw-r--r--  2.0 unx     5886 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/securityplans.py
+-rw-r--r--  2.0 unx    26126 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/stig.py
+-rw-r--r--  2.0 unx     1425 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/threat.py
+-rw-r--r--  2.0 unx     2242 b- defN 23-Jun-21 15:24 regscale/models/regscale_models/user.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/utils/__init__.py
+-rw-r--r--  2.0 unx     3893 b- defN 23-Jun-21 15:24 regscale/utils/shell.py
+-rw-r--r--  2.0 unx       48 b- defN 23-Jun-21 15:24 regscale/utils/string.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 regscale/validation/__init__.py
+-rw-r--r--  2.0 unx      422 b- defN 23-Jun-21 15:24 regscale/validation/address.py
+-rw-r--r--  2.0 unx     1405 b- defN 23-Jun-21 15:24 regscale/validation/record.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 tests/mocks/__init__.py
+-rw-r--r--  2.0 unx       99 b- defN 23-Jun-21 15:24 tests/mocks/objects.py
+-rw-r--r--  2.0 unx     1039 b- defN 23-Jun-21 15:24 tests/mocks/response.py
+-rw-r--r--  2.0 unx      260 b- defN 23-Jun-21 15:24 tests/mocks/xml.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 tests/regscale/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 tests/regscale/core/__init__.py
+-rw-r--r--  2.0 unx     1172 b- defN 23-Jun-21 15:24 tests/regscale/core/test_login.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-21 15:24 tests/regscale/models/__init__.py
+-rw-r--r--  2.0 unx      810 b- defN 23-Jun-21 15:24 tests/regscale/models/test_config.py
+-rw-r--r--  2.0 unx      856 b- defN 23-Jun-21 15:24 tests/regscale/models/test_platform.py
+-rw-r--r--  2.0 unx     1076 b- defN 23-Jun-21 15:24 RegScale_CLI-5.7.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     6658 b- defN 23-Jun-21 15:24 RegScale_CLI-5.7.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-21 15:24 RegScale_CLI-5.7.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       52 b- defN 23-Jun-21 15:24 RegScale_CLI-5.7.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       26 b- defN 23-Jun-21 15:24 RegScale_CLI-5.7.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    10880 b- defN 23-Jun-21 15:24 RegScale_CLI-5.7.0.dist-info/RECORD
+116 files, 974210 bytes uncompressed, 238998 bytes compressed:  75.5%
```

## zipnote {}

```diff
@@ -195,17 +195,14 @@
 
 Filename: regscale/models/app_models/catalog_compare.py
 Comment: 
 
 Filename: regscale/models/app_models/click.py
 Comment: 
 
-Filename: regscale/models/app_models/control_editor.py
-Comment: 
-
 Filename: regscale/models/app_models/pipeline.py
 Comment: 
 
 Filename: regscale/models/integration_models/__init__.py
 Comment: 
 
 Filename: regscale/models/integration_models/azure_alerts.py
@@ -327,26 +324,26 @@
 
 Filename: tests/regscale/models/test_config.py
 Comment: 
 
 Filename: tests/regscale/models/test_platform.py
 Comment: 
 
-Filename: RegScale_CLI-5.6.1.dist-info/LICENSE
+Filename: RegScale_CLI-5.7.0.dist-info/LICENSE
 Comment: 
 
-Filename: RegScale_CLI-5.6.1.dist-info/METADATA
+Filename: RegScale_CLI-5.7.0.dist-info/METADATA
 Comment: 
 
-Filename: RegScale_CLI-5.6.1.dist-info/WHEEL
+Filename: RegScale_CLI-5.7.0.dist-info/WHEEL
 Comment: 
 
-Filename: RegScale_CLI-5.6.1.dist-info/entry_points.txt
+Filename: RegScale_CLI-5.7.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: RegScale_CLI-5.6.1.dist-info/top_level.txt
+Filename: RegScale_CLI-5.7.0.dist-info/top_level.txt
 Comment: 
 
-Filename: RegScale_CLI-5.6.1.dist-info/RECORD
+Filename: RegScale_CLI-5.7.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## regscale/__init__.py

```diff
@@ -1 +1 @@
-__version__ = "5.6.1"
+__version__ = "5.7.0"
```

## regscale/regscale.py

```diff
@@ -262,16 +262,27 @@
     "--password",
     hide_input=True,
     help="RegScale password.",
     prompt=True,
     required=True,
     type=click.STRING,
 )
-def login(username, password):
+@click.option(
+    "--token",
+    hide_input=True,
+    help="RegScale JWT Token.",
+    prompt=False,
+    required=False,
+    type=click.STRING,
+)
+def login(username, password, token: str = None):
     """Logs the user into their RegScale instance."""
+    if token:
+        lg.login(token=token)
+        sys.exit(0)
     if password:
         lg.login(username, password, app=app)
         sys.exit(0)
 
 
 @cli.command(name="validate_token")
 def validate_token():
```

## regscale/core/app/internal/assessments_editor.py

```diff
@@ -1,384 +1,413 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """ Module to allow user to make changes to Assessments in an excel spreadsheet for user friendly experience """
 
 # standard python imports
-import json
+import math
 import os
 import shutil
-import sys
 from pathlib import Path
 
 import click
 import pandas as pd
+import numpy as np
 import requests
 from openpyxl import Workbook, load_workbook
 from openpyxl.styles import Protection, Font, NamedStyle
 from openpyxl.worksheet.datavalidation import DataValidation
 
 from regscale.core.app.api import Api
 from regscale.core.app.application import Application
 from regscale.core.app.logz import create_logger
 from regscale.core.app.utils.app_utils import (
     check_file_path,
     error_and_exit,
     reformat_str_date,
+    get_user_names,
+    get_current_datetime,
+    check_empty_nan,
 )
 from regscale.models.app_models.click import regscale_id, regscale_module
 from regscale.models.regscale_models.assessment import Assessment
 from regscale.models.regscale_models.modules import Modules
 
-logger = create_logger()
-app = Application()
-config = app.config
-api = Api(app)
-
 
 @click.group(name="assessments")
 def assessments():
     """
-    [BETA] Performs actions on Assessments Feature
+    Performs actions on Assessments CLI Feature to create new or update assessments to RegScale.
     """
 
 
 # Make Empty Spreadsheet for creating new assessments.
 @assessments.command(name="generate_new_file")
 @click.option(
     "--path",
     type=click.Path(exists=False, dir_okay=True, path_type=Path),
-    help="Provide the desired path.",
+    help="Provide the desired path for excel files to be generated into.",
     default=os.path.join(os.getcwd(), "artifacts"),
     required=True,
 )
-def new_assessment(path: Path):
+def generate_new_file(path: Path):
     """This function will build an excel spreadsheet for users to be able to create new assessments."""
-    check_file_path(path)
-
-    # create excel file and setting formatting
-    try:
-        workbook = Workbook()
-        worksheet = workbook.active
-        worksheet.title = "New_Assessments"
-
-        column_headers = [
-            "Title",
-            "LeadAssessor",
-            "Facility",
-            "Organization",
-            "AssessmentType",
-            "PlannedStart",
-            "PlannedFinish",
-            "Status",
-            "ActualFinish",
-            "AssessmentResult",
-            "ParentId",
-            "ParentModule",
-        ]
-        for col, val in enumerate(column_headers, start=1):
-            worksheet.cell(row=1, column=col).value = val
-
-        for col in ["A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L"]:
-            for cell in worksheet[col]:
-                if cell.row == 1:
-                    cell.font = Font(bold=True)
-
-        # create and format reference worksheets for dropdowns
-        workbook.create_sheet(title="Facilities")
-        workbook.create_sheet(title="Organizations")
-        workbook.create_sheet(title="Accounts")
-        workbook.create_sheet(title="Modules")
-
-        workbook.save(filename=os.path.join(path, "new_assessments.xlsx"))
-
-        # pull in Facility, Organization, Module, and Account Usernames into Excel Spreadsheet to create drop downs
-        list_of_modules = Modules().module_names()
-        module_names = pd.DataFrame(list_of_modules, columns=["name"])
-        with pd.ExcelWriter(
-            os.path.join(path, "new_assessments.xlsx"),
-            mode="a",
-            engine="openpyxl",
-            if_sheet_exists="overlay",
-        ) as writer:
-            get_field_names(field_name="facilities").to_excel(
-                writer,
-                sheet_name="Facilities",
-                index=False,
-            )
-            get_field_names(field_name="organizations").to_excel(
-                writer,
-                sheet_name="Organizations",
-                index=False,
-            )
-            get_user_names().to_excel(
-                writer,
-                sheet_name="Accounts",
-                index=False,
-            )
-            module_names.to_excel(
-                writer,
-                sheet_name="Modules",
-                index=False,
-            )
+    new_assessment(path)
 
-        # Creating data Validation for fields
-        workbook = load_workbook(os.path.join(path, "new_assessments.xlsx"))
-        worksheet = workbook.active
-        facilities_worksheet = workbook["Facilities"]
-        accounts_worksheet = workbook["Accounts"]
-        organizations_worksheet = workbook["Organizations"]
-        modules_worksheet = workbook["Modules"]
 
-        # lock worksheets containing data for dropdowns
-        facilities_worksheet.protection.sheet = True
-        accounts_worksheet.protection.sheet = True
-        organizations_worksheet.protection.sheet = True
-        modules_worksheet.protection.sheet = True
-        dv1 = DataValidation(
-            type="list",
-            formula1="=Accounts!$A$2:$A$"
-            + str(get_maximum_rows(sheet_object=workbook["Accounts"])),
-            allow_blank=False,
-            showDropDown=False,
-            error="Your entry is not one of the available options",
-            errorTitle="Invalid Entry",
-            prompt="Please select from the list",
-        )
-        dv2 = DataValidation(
-            type="list",
-            formula1="=Facilities!$A$2:$A$"
-            + str(get_maximum_rows(sheet_object=workbook["Facilities"])),
-            allow_blank=True,
-            showDropDown=False,
-            error="Your entry is not one of the available options",
-            errorTitle="Invalid Entry",
-            prompt="Please select from the list",
-        )
-        dv3 = DataValidation(
-            type="list",
-            formula1="=Organizations!$A$2:$A$"
-            + str(get_maximum_rows(sheet_object=workbook["Organizations"])),
-            allow_blank=True,
-            showDropDown=False,
-            error="Your entry is not one of the available options",
-            errorTitle="Invalid Entry",
-            prompt="Please select from the list",
-        )
-        types = '"Control Testing, External Review, Inspection, Internal Audit, Lightning Assessment, Linda\'s metadata for Assessments, Management Assessment, Script/DevOps Check, Walkthrough"'
-        dv4 = DataValidation(
-            type="list",
-            formula1=types,
-            allow_blank=False,
-            showDropDown=False,
-            error="Your entry is not one of the available options",
-            errorTitle="Invalid Entry",
-            prompt="Please select from the list",
-        )
-        dv5 = DataValidation(
-            type="list",
-            formula1='"Scheduled, In Progress, Complete, Cancelled"',
-            allow_blank=True,
-            showDropDown=False,
-            error="Your entry is not one of the available options",
-            errorTitle="Invalid Entry",
-            prompt="Please select from the list",
-        )
-        dv6 = DataValidation(
-            type="list",
-            formula1='"Pass, Fail, N/A, Partial Pass"',
-            allow_blank=True,
-            showDropDown=False,
-            error="Your entry is not one of the available options",
-            errorTitle="Invalid Entry",
-            prompt="Please select from the list",
-        )
-        dv7 = DataValidation(
-            type="date",
-            allow_blank=False,
-            showDropDown=False,
-            error="Your entry is not a valid option",
-            errorTitle="Invalid Entry",
-            prompt="Please enter valid date mm/dd/yyyy",
-        )
-        dv8 = DataValidation(
-            type="list",
-            formula1="=Modules!$A$2:$A$"
-            + str(get_maximum_rows(sheet_object=workbook["Modules"])),
-            allow_blank=True,
-            showDropDown=False,
-            error="Your entry is not a valid option",
-            errorTitle="Invalid Entry",
-            prompt="Please select from the list",
-        )
-        dv9 = DataValidation(
-            type="date",
-            allow_blank=True,
-            showDropDown=False,
-            error="Your entry is not a valid option",
-            errorTitle="Invalid Entry",
-            prompt="Please enter valid date mm/dd/yyyy",
-        )
-        worksheet.add_data_validation(dv1)
-        worksheet.add_data_validation(dv2)
-        worksheet.add_data_validation(dv3)
-        worksheet.add_data_validation(dv4)
-        worksheet.add_data_validation(dv5)
-        worksheet.add_data_validation(dv6)
-        worksheet.add_data_validation(dv7)
-        worksheet.add_data_validation(dv8)
-        worksheet.add_data_validation(dv9)
-        dv1.add("B2:B1048576")
-        dv2.add("C2:C1048576")
-        dv3.add("D2:D1048576")
-        dv4.add("E2:E1048576")
-        dv5.add("H2:H1048576")
-        dv6.add("J2:J1048576")
-        dv7.add("F2:F1048576")
-        dv7.add("G2:G1048576")
-        dv9.add("I2:I1048576")
-        dv8.add("L2:L1048576")
-
-        workbook.save(filename=os.path.join(path, "new_assessments.xlsx"))
-
-        # Freezing top row and adding data style to date columns to assure validation
+def new_assessment(path: Path):
+    """Function to build excel spreadsheet for creation of new assessments.
 
-        workbook = load_workbook(os.path.join(path, "new_assessments.xlsx"))
-        worksheet = workbook.active
-        freeze_range = worksheet.cell(2, 14)
-        worksheet.freeze_panes = freeze_range
-        date_style = NamedStyle(name="date_style", number_format="mm/dd/yyyy")
-        workbook.add_named_style(date_style)
+    :param path: directory of file location
+    :return: None
+    """
+    logger = create_logger()
 
-        for col in ["F", "G", "I"]:  # Columns to edit
-            for cell in worksheet[col]:
-                if cell.row > 1:
-                    cell.style = date_style
+    check_file_path(path)
 
-        # Adjusting width of columns
+    # create excel file and setting formatting
 
-        for col in worksheet.columns:
-            max_length = 0
-            column = col[0].column_letter  # Get the column name
-            for cell in col:
-                try:  # Necessary to avoid error on empty cells
-                    if len(str(cell.value)) > max_length:
-                        max_length = len(str(cell.value))
-                except OSError:
-                    logger.error("Cell adjustment failed due to empty cells.")
-            adjusted_width = (max_length + 2) * 1.2
-            worksheet.column_dimensions[column].width = adjusted_width
+    workbook = Workbook()
+    worksheet = workbook.active
+    worksheet.title = "New_Assessments"
+
+    column_headers = [
+        "Title",
+        "LeadAssessor",
+        "Facility",
+        "Organization",
+        "AssessmentType",
+        "PlannedStart",
+        "PlannedFinish",
+        "Status",
+        "ActualFinish",
+        "AssessmentResult",
+        "ParentId",
+        "ParentModule",
+    ]
+    for col, val in enumerate(column_headers, start=1):
+        worksheet.cell(row=1, column=col).value = val
+
+    for col in ["A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L"]:
+        for cell in worksheet[col]:
+            if cell.row == 1:
+                cell.font = Font(bold=True)
+
+    # create and format reference worksheets for dropdowns
+    workbook.create_sheet(title="Facilities")
+    workbook.create_sheet(title="Organizations")
+    workbook.create_sheet(title="Accounts")
+    workbook.create_sheet(title="Modules")
+    workbook.create_sheet(title="AssessmentTypes")
+    workbook.create_sheet(title="Assessment_Ids")
+
+    workbook.save(filename=os.path.join(path, "new_assessments.xlsx"))
+
+    # pull in Facility, Organization, Module, and Account Usernames into Excel Spreadsheet to create drop downs
+    list_of_modules = Modules().api_names()
+    module_names = pd.DataFrame(list_of_modules, columns=["name"])
+    with pd.ExcelWriter(
+        os.path.join(path, "new_assessments.xlsx"),
+        mode="a",
+        engine="openpyxl",
+        if_sheet_exists="overlay",
+    ) as writer:
+        get_field_names(field_name="facilities").to_excel(
+            writer,
+            sheet_name="Facilities",
+            index=False,
+        )
+        get_field_names(field_name="organizations").to_excel(
+            writer,
+            sheet_name="Organizations",
+            index=False,
+        )
+        get_user_names().to_excel(
+            writer,
+            sheet_name="Accounts",
+            index=False,
+        )
+        module_names.to_excel(
+            writer,
+            sheet_name="Modules",
+            index=False,
+        )
+        get_assessment_types().to_excel(
+            writer,
+            sheet_name="AssessmentTypes",
+            index=False,
+        )
+
+    # Creating data Validation for fields
+    workbook = load_workbook(os.path.join(path, "new_assessments.xlsx"))
+    worksheet = workbook.active
+    facilities_worksheet = workbook["Facilities"]
+    accounts_worksheet = workbook["Accounts"]
+    organizations_worksheet = workbook["Organizations"]
+    assessment_worksheet = workbook["AssessmentTypes"]
+    modules_worksheet = workbook["Modules"]
+
+    # lock worksheets containing data for dropdowns
+    facilities_worksheet.protection.sheet = True
+    accounts_worksheet.protection.sheet = True
+    organizations_worksheet.protection.sheet = True
+    assessment_worksheet.protection.sheet = True
+    modules_worksheet.protection.sheet = True
+    dv1 = DataValidation(
+        type="list",
+        formula1="=Accounts!$A$2:$A$"
+        + str(get_maximum_rows(sheet_object=workbook["Accounts"])),
+        allow_blank=False,
+        showDropDown=False,
+        error="Your entry is not one of the available options",
+        errorTitle="Invalid Entry",
+        prompt="Please select from the list",
+    )
+    dv2 = DataValidation(
+        type="list",
+        formula1="=Facilities!$A$2:$A$"
+        + str(get_maximum_rows(sheet_object=workbook["Facilities"])),
+        allow_blank=True,
+        showDropDown=False,
+        error="Your entry is not one of the available options",
+        errorTitle="Invalid Entry",
+        prompt="Please select from the list",
+    )
+    dv3 = DataValidation(
+        type="list",
+        formula1="=Organizations!$A$2:$A$"
+        + str(get_maximum_rows(sheet_object=workbook["Organizations"])),
+        allow_blank=True,
+        showDropDown=False,
+        error="Your entry is not one of the available options",
+        errorTitle="Invalid Entry",
+        prompt="Please select from the list",
+    )
+    dv4 = DataValidation(
+        type="list",
+        formula1="=AssessmentTypes!$A$2:$A$"
+        + str(get_maximum_rows(sheet_object=workbook["AssessmentTypes"])),
+        allow_blank=False,
+        showDropDown=False,
+        error="Your entry is not one of the available options",
+        errorTitle="Invalid Entry",
+        prompt="Please select from the list",
+    )
+    dv5 = DataValidation(
+        type="list",
+        formula1='"Scheduled, In Progress, Complete, Cancelled"',
+        allow_blank=True,
+        showDropDown=False,
+        error="Your entry is not one of the available options",
+        errorTitle="Invalid Entry",
+        prompt="Please select from the list",
+    )
+    dv6 = DataValidation(
+        type="list",
+        formula1='"Pass, Fail, N/A, Partial Pass"',
+        allow_blank=True,
+        showDropDown=False,
+        error="Your entry is not one of the available options",
+        errorTitle="Invalid Entry",
+        prompt="Please select from the list",
+    )
+    dv7 = DataValidation(
+        type="date",
+        allow_blank=False,
+        showDropDown=False,
+        showErrorMessage=True,
+        showInputMessage=True,
+        error="Your entry is not a valid option",
+        errorTitle="Invalid Entry",
+        prompt="Please enter valid date mm/dd/yyyy",
+    )
+    dv8 = DataValidation(
+        type="list",
+        formula1="=Modules!$A$2:$A$"
+        + str(get_maximum_rows(sheet_object=workbook["Modules"])),
+        allow_blank=True,
+        showDropDown=False,
+        error="Your entry is not a valid option",
+        errorTitle="Invalid Entry",
+        prompt="Please select from the list",
+    )
+    dv9 = DataValidation(
+        type="date",
+        allow_blank=True,
+        showDropDown=False,
+        showErrorMessage=True,
+        showInputMessage=True,
+        error="Your entry is not a valid option",
+        errorTitle="Invalid Entry",
+        prompt="Please enter valid date mm/dd/yyyy",
+    )
+    worksheet.add_data_validation(dv1)
+    worksheet.add_data_validation(dv2)
+    worksheet.add_data_validation(dv3)
+    worksheet.add_data_validation(dv4)
+    worksheet.add_data_validation(dv5)
+    worksheet.add_data_validation(dv6)
+    worksheet.add_data_validation(dv7)
+    worksheet.add_data_validation(dv8)
+    worksheet.add_data_validation(dv9)
+    dv1.add("B2:B1048576")
+    dv2.add("C2:C1048576")
+    dv3.add("D2:D1048576")
+    dv4.add("E2:E1048576")
+    dv5.add("H2:H1048576")
+    dv6.add("J2:J1048576")
+    dv7.add("F2:F1048576")
+    dv7.add("G2:G1048576")
+    dv9.add("I2:I1048576")
+    dv8.add("L2:L1048576")
+
+    workbook.save(filename=os.path.join(path, "new_assessments.xlsx"))
+
+    # Freezing top row and adding data style to date columns to assure validation
+
+    workbook = load_workbook(os.path.join(path, "new_assessments.xlsx"))
+    worksheet = workbook.active
+    freeze_range = worksheet.cell(2, 14)
+    worksheet.freeze_panes = freeze_range
+    date_style = NamedStyle(name="date_style", number_format="mm/dd/yyyy")
+    workbook.add_named_style(date_style)
+
+    for col in ["F", "G", "I"]:  # Columns to edit
+        for cell in worksheet[col]:
+            if cell.row > 1:
+                cell.style = date_style
+
+    # Adjusting width of columns
+
+    for col in worksheet.columns:
+        max_length = 0
+        column = col[0].column_letter  # Get the column name
+        for cell in col:
+            if len(str(cell.value)) > max_length:
+                max_length = len(str(cell.value))
 
-        workbook.save(filename=os.path.join(path, "new_assessments.xlsx"))
+        adjusted_width = (max_length + 2) * 1.2
+        worksheet.column_dimensions[column].width = adjusted_width
 
-    except OSError:
-        logger.error(f"Creation of the directory {path} failed.")
+    workbook.save(filename=os.path.join(path, "new_assessments.xlsx"))
 
-    return logger.info(
+    logger.info(
         "Your excel workbook has been created. Please open the new_assessments workbook and add new assessments."
     )
+    return None
 
 
 @assessments.command(name="generate")
 @regscale_id()
 @regscale_module()
 @click.option(
     "--path",
     type=click.Path(exists=False, dir_okay=True, path_type=Path),
-    help="Provide the desired path.",
+    help="Provide the desired path for excel files to be generated into.",
     default=os.path.join(os.getcwd(), "artifacts"),
     required=True,
 )
-def all_assessments(regscale_id: str, regscale_module: str, path: Path):
+def generate(regscale_id: str, regscale_module: str, path: Path):
     """This function will build and populate a spreadsheet of all assessments
     with the selected RegScale Parent Id and RegScale Module for users to any necessary edits.
     """
-    try:
-        body = """
-                query {
-                      assessments (skip: 0, take: 50, where: {parentId: {eq: parent_id} parentModule: {eq: "parent_module"}}) {
-                        items {
-                          id
-                          title
-                          leadAssessor {
-                            firstName
-                            lastName
-                            userName
-                          }
-                          facility {
-                            name
-                          }
-                          org {
-                            name
-                          }
-                          assessmentType
-                          plannedStart
-                          plannedFinish
-                          status
-                          actualFinish
-                          assessmentResult
-                          parentId
-                          parentModule
-                        }
-                        totalCount
-                        pageInfo {
-                          hasNextPage
-                        }
+    all_assessments(regscale_id=regscale_id, regscale_module=regscale_module, path=path)
+
+
+def all_assessments(regscale_id: str, regscale_module: str, path: Path):
+    """Function takes organizer record and module and build excel worksheet of assessments.
+
+    :param regscale_id: RegScale Parent Id
+    :param regscale_module: RegScale Parent Module
+    :param path: directory of file location
+    """
+    logger = create_logger()
+    app = Application()
+    api = Api(app)
+
+    body = """
+            query {
+                  assessments (skip: 0, take: 50, where: {parentId: {eq: parent_id} parentModule: {eq: "parent_module"}}) {
+                    items {
+                      id
+                      title
+                      leadAssessor {
+                        firstName
+                        lastName
+                        userName
+                      }
+                      facility {
+                        name
+                      }
+                      org {
+                        name
+                      }
+                      assessmentType
+                      plannedStart
+                      plannedFinish
+                      status
+                      actualFinish
+                      assessmentResult
+                      parentId
+                      parentModule
+                    }
+                    totalCount
+                    pageInfo {
+                      hasNextPage
                     }
                 }
-                    """.replace(
-            "parent_module", regscale_module
-        ).replace(
-            "parent_id", str(regscale_id)
-        )
-        existing_assessment_data = api.graph(query=body)
-
-    except requests.RequestException as ex:
-        error_and_exit("Unable to retrieve assessment list from RegScale.\n %s", ex)
+            }
+                """.replace(
+        "parent_module", regscale_module
+    ).replace(
+        "parent_id", str(regscale_id)
+    )
+    existing_assessment_data = api.graph(query=body)
 
     if (
         existing_assessment_data["assessments"]["totalCount"] > 0
     ):  # Checking to see if assessment exists for selected RegScale Id and RegScale Module.
         check_file_path(path)
 
         # Loading data from db into two workbooks.
         workbook = Workbook()
         worksheet = workbook.active
         worksheet.title = f"Assessments({regscale_id}_{regscale_module})"
         workbook.create_sheet(title="Facilities")
         workbook.create_sheet(title="Organizations")
         workbook.create_sheet(title="Accounts")
+        workbook.create_sheet(title="AssessmentTypes")
         workbook.save(filename=os.path.join(path, "all_assessments.xlsx"))
         shutil.copy(
             os.path.join(path, "all_assessments.xlsx"),
             os.path.join(path, "old_assessments.xlsx"),
         )
 
         raw_data = existing_assessment_data["assessments"]["items"]
         assessments_data = []
         for a in raw_data:
             Id = a["id"]
             Title = a["title"]
             LeadAssessor = (
-                str(a["leadAssessor"]["lastName"])
+                str(a["leadAssessor"]["lastName"]).strip()
                 + ", "
-                + str(a["leadAssessor"]["firstName"])
+                + str(a["leadAssessor"]["firstName"]).strip()
                 + " ("
-                + str(a["leadAssessor"]["userName"])
+                + str(a["leadAssessor"]["userName"]).strip()
                 + ")"
             )
-            Facility = a["facility"]["name"] if a["facility"] else "None"
-            Organization = a["org"]["name"] if a["org"] else "None"
+            Facility = a["facility"]["name"] if a["facility"] else None
+            Organization = a["org"]["name"] if a["org"] else None
             AssessmentType = a["assessmentType"]
             PlannedStart = reformat_str_date(a["plannedStart"])
             PlannedFinish = reformat_str_date(a["plannedFinish"])
             Status = a["status"]
             ActualFinish = (
-                reformat_str_date(a["actualFinish"]) if a["actualFinish"] else "None"
+                reformat_str_date(a["actualFinish"]) if a["actualFinish"] else None
             )
-            AssessmentResult = a["assessmentResult"] or "None"
+            AssessmentResult = a["assessmentResult"] or None
             ParentId = a["parentId"]
             ParentModule = a["parentModule"]
 
             assessments_data.append(
                 [
                     Id,
                     Title,
@@ -430,15 +459,15 @@
             os.path.join(path, "old_assessments.xlsx"),
             mode="a",
             engine="openpyxl",
             if_sheet_exists="overlay",
         ) as writer:
             all_ass_df.to_excel(
                 writer,
-                sheet_name=f"Assessments{regscale_id}_{regscale_module})",
+                sheet_name=f"Assessments({regscale_id}_{regscale_module})",
                 index=False,
             )
 
         # Pulling in Facility Names into Excel Spreadsheet to create dropdown.
         with pd.ExcelWriter(
             os.path.join(path, "all_assessments.xlsx"),
             mode="a",
@@ -456,39 +485,41 @@
                 index=False,
             )
             get_user_names().to_excel(
                 writer,
                 sheet_name="Accounts",
                 index=False,
             )
+            get_assessment_types().to_excel(
+                writer,
+                sheet_name="AssessmentTypes",
+                index=False,
+            )
 
         # Adding protection to "old_assessments.xlsx" file that will be used as reference.
         workbook2 = load_workbook(os.path.join(path, "old_assessments.xlsx"))
         worksheet2 = workbook2.active
         worksheet2.protection.sheet = True
         workbook2.save(filename=os.path.join(path, "old_assessments.xlsx"))
 
         # Adding Data Validation to "all_assessments.xlsx" file to be adjusted internally.
         workbook = load_workbook(os.path.join(path, "all_assessments.xlsx"))
         worksheet = workbook.active
         facilities_worksheet = workbook["Facilities"]
         accounts_worksheet = workbook["Accounts"]
         organizations_worksheet = workbook["Organizations"]
+        assessments_worksheet = workbook["AssessmentTypes"]
 
         # lock worksheets containing data for dropdowns
         facilities_worksheet.protection.sheet = True
         accounts_worksheet.protection.sheet = True
         organizations_worksheet.protection.sheet = True
+        assessments_worksheet.protection.sheet = True
         worksheet.protection.sheet = True
 
-        # Unlocking cells that can be edited in each Assessment.
-        for col in ["C", "D", "E", "F", "G", "H", "I", "J", "K"]:  # Columns to edit
-            for cell in worksheet[col]:
-                cell.protection = Protection(locked=False)
-
         dv1 = DataValidation(
             type="list",
             formula1="=Accounts!$A$2:$A$"
             + str(get_maximum_rows(sheet_object=workbook["Accounts"])),
             allow_blank=False,
             showDropDown=False,
             error="Your entry is not one of the available options",
@@ -511,18 +542,18 @@
             + str(get_maximum_rows(sheet_object=workbook["Organizations"])),
             allow_blank=True,
             showDropDown=False,
             error="Your entry is not one of the available options",
             errorTitle="Invalid Entry",
             prompt="Please select from the list",
         )
-        types = '"Control Testing, External Review, Inspection, Internal Audit, Lightning Assessment, Linda\'s metadata for Assessments, Management Assessment, Script/DevOps Check, Walkthrough"'
         dv4 = DataValidation(
             type="list",
-            formula1=types,
+            formula1="=AssessmentTypes!$A$2:$A$"
+            + str(get_maximum_rows(sheet_object=workbook["AssessmentTypes"])),
             allow_blank=False,
             showDropDown=False,
             error="Your entry is not one of the available options",
             errorTitle="Invalid Entry",
             prompt="Please select from the list",
         )
         dv5 = DataValidation(
@@ -544,22 +575,26 @@
             prompt="Please select from the list",
         )
         dv7 = DataValidation(
             type="date",
             allow_blank=False,
             showDropDown=False,
             error="Your entry is not a valid option",
+            showErrorMessage=True,
+            showInputMessage=True,
             errorTitle="Invalid Entry",
             prompt="Please enter valid date mm/dd/yyyy",
         )
         dv8 = DataValidation(
             type="date",
             allow_blank=True,
             showDropDown=False,
             error="Your entry is not a valid option",
+            showErrorMessage=True,
+            showInputMessage=True,
             errorTitle="Invalid Entry",
             prompt="Please enter valid date mm/dd/yyyy",
         )
         worksheet.add_data_validation(dv1)
         worksheet.add_data_validation(dv2)
         worksheet.add_data_validation(dv3)
         worksheet.add_data_validation(dv4)
@@ -573,214 +608,331 @@
         dv4.add("F2:F1048576")
         dv5.add("I2:I1048576")
         dv6.add("K2:K1048576")
         dv7.add("G2:G1048576")
         dv7.add("H2:H1048576")
         dv8.add("J2:J1048576")
 
+        # Worksheet freeze top row
+        freeze_range = worksheet.cell(2, 17)
+        worksheet.freeze_panes = freeze_range
+        date_style = NamedStyle(name="date_style", number_format="mm/dd/yyyy")
+        workbook.add_named_style(date_style)
+
+        # Adding Date Style to Worksheet, formatting cells, and unlocking cells that can be edited in each assessment
+
         for col in worksheet.columns:
             max_length = 0
             column = col[0].column_letter  # Get the column name
             for cell in col:
-                try:  # Necessary to avoid error on empty cells
-                    if len(str(cell.value)) > max_length:
-                        max_length = len(str(cell.value))
-                except OSError:
-                    logger.error("Cell adjustment failed due to empty cells.")
+                if len(str(cell.value)) > max_length:
+                    max_length = len(str(cell.value))
+
             adjusted_width = (max_length + 2) * 1.2
             worksheet.column_dimensions[column].width = adjusted_width
 
-        # Worksheet freeze top row
-        freeze_range = worksheet.cell(2, 16)
-        worksheet.freeze_panes = freeze_range
-        date_style = NamedStyle(name="date_style", number_format="mm/dd/yyyy")
-        workbook.add_named_style(date_style)
-
-        # Adding Date Style to Worksheet
-        for col in ["G", "H", "J"]:  # Columns to edit
-            for cell in worksheet[col]:
-                if cell.row > 1:
-                    cell.style = date_style
+            if col == ["C", "D", "E", "F", "G", "H", "I", "J", "K"]:  # Columns to edit
+                for cell in worksheet[col]:
+                    cell.protection = Protection(locked=False)
+                if col == ["G", "H", "J"]:
+                    for cell in worksheet[col]:
+                        if cell.row > 1:
+                            cell.style = date_style
 
         workbook.save(filename=os.path.join(path, "all_assessments.xlsx"))
 
     else:
         logger.info(
             "Please check your selections for RegScale Id and RegScale Module and try again."
         )
         error_and_exit(
-            "There was an error creating your workbook for the given RegScale Id and RegScale Module."
+            "There was an error creating your workbook. No assessments exist for the given RegScale Id and RegScale Module."
         )
 
     return logger.info(
         "Your data has been loaded into your excel workbook. Please open the all_assessments workbook and make your desired changes."
     )
 
 
 @assessments.command(name="load")
 @click.option(
     "--path",
     type=click.Path(exists=False, dir_okay=True, path_type=Path),
-    help="Provide the desired path.",
+    help="Provide the desired path of excel workbook locations.",
     default=os.path.join(os.getcwd(), "artifacts"),
     required=True,
 )
-def upload_data(path: Path) -> None:
+def load(path: Path) -> None:
     """
-    This function uploads updated assessments and new assessments to the RegScale database from the Excel files that users have edited.
+    This function uploads updated assessments and new assessments to the RegScale from the Excel files that users have edited.
     """
+    upload_data(path=path)
+
+
+def upload_data(path: Path) -> None:
+    """Function will upload assessments to RegScale if user as made edits to any of the assessment excel workbooks.
+
+    :param path: directory of file location
+    :return: None
+    """
+    logger = create_logger()
+    app = Application()
+    config = app.config
+    api = Api(app)
+
     # Checking if new assessments have been created and updating RegScale database.
     if os.path.isfile(os.path.join(path, "new_assessments.xlsx")):
         new_files = os.path.join(path, "new_assessments.xlsx")
         new = pd.read_excel(new_files)
         new["Facility"] = new["Facility"].fillna("None")
         new["Organization"] = new["Organization"].fillna("None")
-        new["ParentId"] = new["ParentId"].fillna("None")
-        new["ParentModule"] = new["ParentModule"].fillna("None")
-        new["AssessmentResult"] = new["AssessmentResult"].fillna("N/A")
         facilities = pd.read_excel(new_files, sheet_name="Facilities")
         facilities = facilities.rename(columns={"name": "Facility", "id": "FacilityId"})
         organizations = pd.read_excel(new_files, sheet_name="Organizations")
         organizations = organizations.rename(
             columns={"name": "Organization", "id": "OrganizationId"}
         )
         accounts = pd.read_excel(new_files, sheet_name="Accounts")
+        accounts = accounts.rename(
+            columns={"User": "LeadAssessor", "UserId": "LeadAssessorId"}
+        )
         new = new.merge(accounts, how="left", on="LeadAssessor")
         new = new.merge(facilities, how="left", on="Facility")
         new = new.merge(organizations, how="left", on="Organization")
         new = new.T.to_dict()
         new_assessments = [
             Assessment(
                 leadAssessorId=value["LeadAssessorId"],
                 title=value["Title"],
                 assessmentType=value["AssessmentType"],
                 plannedStart=value["PlannedStart"],
                 plannedFinish=value["PlannedFinish"],
                 status=value["Status"],
-                facilityId=value["FacilityId"],
-                orgId=value["OrganizationId"],
-                assessmentResult=value["AssessmentResult"],
-                actualFinish=value["ActualFinish"],
-                parentId=value["ParentId"],
-                parentModule=value["ParentModule"],
-            )
+                parentModule=check_empty_nan(value["ParentModule"]),
+                facilityId=check_empty_nan(value["FacilityId"]),
+                orgId=check_empty_nan(value["OrganizationId"]),
+                assessmentResult=check_assessment_result(value["AssessmentResult"]),
+                actualFinish=check_empty_nan(value["ActualFinish"]),
+                parentId=check_empty_nan(value["ParentId"]),
+                lastUpdatedById=app.config["userId"],
+                dateLastUpdated=get_current_datetime(),
+            ).dict()
             for value in new.values()
         ]
-        new_load = json.dumps(new_assessments)
+
         try:
-            api.post(
-                url=config["domain"] + "/api/assessments/batchCreate",
-                json=new_load,
-            )
-            logger.info(
-                "%s total assessments were added to RegScale database.",
-                str(len(new_load)),
-            )
+            for i in new_assessments:
+                response = api.post(
+                    url=config["domain"] + "/api/assessments",
+                    json=i,
+                )
+                if response.ok:
+                    ids = []
+                    for i in response:
+                        assessment_ids = response.json()["id"]
+                    ids.append(assessment_ids)
+                    new_assessments_df = pd.DataFrame(ids, columns=["id_number"])
+
+                    with pd.ExcelWriter(
+                        os.path.join(path, "new_assessments.xlsx"),
+                        mode="a",
+                        engine="openpyxl",
+                        if_sheet_exists="overlay",
+                    ) as writer:
+                        new_assessments_df.to_excel(
+                            writer,
+                            sheet_name="Assessment_Ids",
+                            index=False,
+                        )
+
+                    logger.info(
+                        "%s total assessments were added to RegScale.",
+                        str(len(new_assessments)),
+                    )
+                else:
+                    logger.warning("Unable to post new assessments to RegScale")
         except requests.exceptions.RequestException as ex:
             logger.error(
-                f"Unable to add {len(new_load)} assessment(s) to RegScale.",
+                "Unable to add %i assessment(s) to RegScale.\n%s",
+                len(new_assessments),
                 ex,
             )
-    elif os.path.isfile(os.path.join(path, "all_assessments")):
+    else:
+        logger.info("No new assessments detected. Checking for edited assessments")
+
+    if os.path.isfile(os.path.join(path, "all_assessments.xlsx")):
         # Checking all_assessments file for differences before updating database
 
-        df1 = load_workbook(os.path.join(path, "old_assessments.xlsx"))
-        ws1 = df1.active
-        data1 = ws1.values
-        columns1 = next(data1)[:]
-        df1 = pd.DataFrame(data1, columns=columns1)
-
-        df2 = load_workbook(os.path.join(path, "all_assessments.xlsx"))
-        ws2 = df2.active
-        data2 = ws2.values
-        columns2 = next(data2)[:]
-        df2 = pd.DataFrame(data2, columns=columns2)
+        df1 = pd.read_excel(
+            os.path.join(path, "old_assessments.xlsx"), sheet_name=0, index_col="Id"
+        )
+
+        df2 = pd.read_excel(
+            os.path.join(path, "all_assessments.xlsx"), sheet_name=0, index_col="Id"
+        )
 
         if df1.equals(df2):
-            logger.info("No differences detected.")
-            sys.exit(1)
+            error_and_exit("No differences detected.")
+
         else:
             logger.warning("Differences found!")
 
+        diff_mask = (df1 != df2) & ~(df1.isnull() & df2.isnull())
+        ne_stacked = diff_mask.stack()
+        changed = ne_stacked[ne_stacked]
+        changed.index.names = ["Id", "Column"]
+        difference_locations = np.where(diff_mask)
+        changed_from = df1.values[difference_locations]
+        changed_to = df2.values[difference_locations]
+        changes = pd.DataFrame(
+            {"From": changed_from, "To": changed_to}, index=changed.index
+        )
+        changes.to_csv(
+            os.path.join(path, "differences.txt"),
+            header=True,
+            index=True,
+            sep=" ",
+            mode="w+",
+        )
+        logger.info(
+            "Please check differences.txt file located in %s to see changes made.",
+            path,
+        )
+        # Loading in differences.txt file and using Id to parse xlsx file for rows to update
+
+        diff = pd.read_csv(
+            os.path.join(path, "differences.txt"), header=0, sep=" ", index_col=None
+        )
+        ids = []
+
+        for i, row in diff.iterrows():
+            ids.append(row["Id"])
+
+        id_df = pd.DataFrame(ids, index=None, columns=["Id"])
+        id_df2 = id_df.drop_duplicates()
         updated_files = os.path.join(path, "all_assessments.xlsx")
-        updated = pd.read_excel(updated_files)
+        df3 = pd.read_excel(updated_files, sheet_name=0, index_col=None)
+        updated = df3[df3["Id"].isin(id_df2["Id"])]
         updated["Facility"] = updated["Facility"].fillna("None")
         updated["Organization"] = updated["Organization"].fillna("None")
-        updated["AssessmentResult"] = updated["AssessmentResult"].fillna("N/A")
         facilities = pd.read_excel(updated_files, sheet_name="Facilities")
         facilities = facilities.rename(columns={"name": "Facility", "id": "FacilityId"})
         organizations = pd.read_excel(updated_files, sheet_name="Organizations")
         organizations = organizations.rename(
             columns={"name": "Organization", "id": "OrganizationId"}
         )
         accounts = pd.read_excel(updated_files, sheet_name="Accounts")
+        accounts = accounts.rename(
+            columns={"User": "LeadAssessor", "UserId": "LeadAssessorId"}
+        )
         updated = updated.merge(accounts, how="left", on="LeadAssessor")
         updated = updated.merge(facilities, how="left", on="Facility")
         updated = updated.merge(organizations, how="left", on="Organization")
         updated = updated.T.to_dict()
-        updated_assessments = []
-        for value in updated.values():
-            updated_assessments.append(
-                Assessment(
-                    leadAssessorId=value["LeadAssessorId"],
-                    id=value["Id"],
-                    title=value["Title"],
-                    assessmentType=value["AssessmentType"],
-                    plannedStart=value["PlannedStart"],
-                    plannedFinish=value["PlannedFinish"],
-                    status=value["Status"],
-                    facilityId=value["FacilityId"],
-                    orgId=value["OrganizationId"],
-                    assessmentResult=value["AssessmentResult"],
-                    actualFinish=value["ActualFinish"],
-                    parentId=value["ParentId"],
-                    parentModule=value["ParentModule"],
-                )
-            )
+        updated_assessments = [
+            Assessment(
+                leadAssessorId=value["LeadAssessorId"],
+                id=value["Id"],
+                title=value["Title"],
+                assessmentType=value["AssessmentType"],
+                plannedStart=value["PlannedStart"],
+                plannedFinish=value["PlannedFinish"],
+                status=value["Status"],
+                parentModule=value["ParentModule"],
+                facilityId=check_empty_nan(value["FacilityId"]),
+                orgId=check_empty_nan(value["OrganizationId"]),
+                assessmentResult=check_assessment_result(value["AssessmentResult"]),
+                actualFinish=check_empty_nan(value["ActualFinish"]),
+                parentId=value["ParentId"],
+                lastUpdatedById=app.config["userId"],
+                dateLastUpdated=get_current_datetime(),
+            ).dict()
+            for value in updated.values()
+        ]
 
-            updated_load = json.dumps(updated_assessments)
-            try:
-                response = api.post(
-                    url=config["domain"] + f"/api/assessments/{id}",
-                    json=updated_load,
-                )
-                if response.ok:
-                    logger.info(f"Successfully updated assessment #{id} in RegScale.")
-                else:
-                    logger.warning(f"Unable to update assessment #{id} in RegScale.")
-            except requests.exceptions.RequestException as ex:
-                logger.error(
-                    "Unable to update assessments in RegScale database. \n %s", ex
-                )
-    os.remove(os.path.join(path, "all_assessments.xlsx"))
-    os.remove(os.path.join(path, "old_assessments.xlsx"))
-    os.remove(os.path.join(path, "new_assessments.xlsx"))
+        api.update_server(
+            url=config["domain"] + "/api/assessments",
+            json_list=updated_assessments,
+            message="Working on uploading updated assessments to RegScale.",
+            config=config,
+            method="put",
+        )
+
+    else:
+        logger.info("No Assessments exist to load to RegScale.")
     return logger.info(
-        "Assessment files have been deleted. Changes made to existing files can be seen in differences.txt file. Thank you!"
+        "Assessment files have been uploaded. Changes made to existing files can be seen in differences.txt file. Thank you!"
     )
 
 
+@assessments.command(name="delete_files")
+@click.option(
+    "--path",
+    type=click.Path(exists=False, dir_okay=True, path_type=Path),
+    help="Provide the desired path of file location.",
+    default=Path("./artifacts"),
+    required=True,
+)
+def generate_delete_file(path: Path):
+    """This command will delete files used during the Assessment editing process."""
+    delete_file(path)
+
+
+def delete_file(path: Path):
+    """
+    Deletes files used during the process.
+
+    :param path: directory of file location
+    :return: None
+    """
+    logger = create_logger()
+
+    if os.path.isfile(os.path.join(path, "new_assessments.xlsx")):
+        os.remove(os.path.join(path, "new_assessments.xlsx"))
+    else:
+        logger.warning(
+            "No new_assessment.xlsx file found. Checking for other files before exiting."
+        )
+    if os.path.isfile(os.path.join(path, "all_assessments.xlsx")):
+        os.remove(os.path.join(path, "all_assessments.xlsx"))
+        os.remove(os.path.join(path, "old_assessments.xlsx"))
+    else:
+        logger.warning("No assessment files exist to delete.")
+
+    if os.path.isfile(os.path.join(path, "differences.txt")):
+        os.remove(os.path.join(path, "differences.txt"))
+    else:
+        pass
+    os.rmdir(path)
+    logger.info("All files have been deleted.")
+
+    return None
+
+
 def get_maximum_rows(*, sheet_object):
     """This function finds the last row containing data in a spreadsheet
     :param sheet_object: excel worksheet to be referenced
     :return: integer representing last row with data in spreadsheet
     :rtype: int
     """
     return sum(
         any(col.value is not None for col in row)
         for max_row, row in enumerate(sheet_object, 1)
     )
 
 
-def get_field_names(field_name):
+def get_field_names(field_name) -> pd.DataFrame:
     """
     This function uses GraphQL to retrieve all names of a given parent table in database
     :return: pandas dataframe with facility names
     :rtype: pd.dataframe
     """
+    app = Application()
+    api = Api(app)
+
     body = """
     query {
         field_name(skip: 0, take: 50, order: {name: ASC}, ) {
             items {
                 name
                 id
             }
@@ -794,25 +946,55 @@
         "field_name", field_name
     )
 
     field_items = api.graph(query=body)
     names = field_items[str(field_name)]["items"]
     field_names = [[i["name"], i["id"]] for i in names]
     all_names = pd.DataFrame(field_names, index=None, columns=["name", "id"])
-    all_names.loc[len(all_names.index)] = ["None", "None"]
 
     return all_names
 
 
-def get_user_names():
-    """This function uses API Endpoint to retrieve all user names in database
-    :return: pandas dataframe with usernames
-    :rtype: pd.dataframe
-    """
-    accounts = api.get(url=config["domain"] + "/api/accounts").json()
+def get_assessment_types() -> pd.DataFrame:
+    """This function uses GraphQL to retrieve all assessment types in database
+    :return: pandas dataframe with assessment types
+    :rtype: pd.dataframe"""
+    app = Application()
+    api = Api(app)
 
-    user_names = [[item["name"], item["id"]] for item in accounts]
-    return pd.DataFrame(
-        user_names,
-        index=None,
-        columns=["LeadAssessor", "LeadAssessorId"],
+    body = """
+        query{
+          assessments (skip: 0, take: 50, order: {assessmentType: ASC}, ) {
+            items {
+              assessmentType
+            }
+            totalCount
+            pageInfo {
+              hasNextPage
+            }
+          }
+        } """
+
+    assessments_raw = api.graph(query=body)
+    assessmentTypes = assessments_raw["assessments"]["items"]
+    field_names = [i["assessmentType"] for i in assessmentTypes]
+    all_assessmentTypes = pd.DataFrame(
+        field_names, index=None, columns=["assessmentType"]
     )
+    all_assessmentTypes = all_assessmentTypes.drop_duplicates()
+
+    return all_assessmentTypes
+
+
+def check_assessment_result(
+    value,
+):  # this function has to be checked separate to account for API only accpeting empty string unlike other class paramas
+    """This function takes a given value for an assessment and checks if value is empty or NaN based on value type.
+    :param value: A string or float object
+    :return: A string value, float value. or ""
+    :rtype: str, float, or ""
+    """
+    if isinstance(value, str) and value.strip() == "":
+        return ""
+    if isinstance(value, float) and math.isnan(value):
+        return ""
+    return value
```

## regscale/core/app/internal/control_editor.py

```diff
@@ -1,427 +1,479 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """
 Module to allow user to make changes to Control Implementations in an Excel spreadsheet for a user-friendly experience
 """
 
 # standard python imports
-import json
+import math
 import os
 import shutil
-import sys
 from pathlib import Path
 
 import click
 import numpy as np
 import pandas as pd
-import requests
 from openpyxl import Workbook, load_workbook
 from openpyxl.styles import Protection
 from openpyxl.worksheet.datavalidation import DataValidation
 
 from regscale.core.app.api import Api
 from regscale.core.app.application import Application
 from regscale.core.app.logz import create_logger
-from regscale.core.app.utils.app_utils import error_and_exit
+from regscale.core.app.utils.app_utils import (
+    error_and_exit,
+    get_current_datetime,
+    check_file_path,
+    check_empty_nan,
+)
 from regscale.models.app_models.click import regscale_id, regscale_module
 from regscale.models.regscale_models.control_implementation import (
     ControlImplementation,
     Control,
 )
 
-logger = create_logger()
-app = Application()
-config = app.config
-api = Api(app)
-
 
 @click.group(name="control_editor")
 def control_editor():
     """
-    Performs actions on Control Editor Feature!
+    Performs actions on Control Editor Feature to edit controls to RegScale.
     """
 
 
 # Get data and pull into Excel worksheets.
 
 
-@control_editor.command(name="data_download")
+@control_editor.command(name="generate")
 @regscale_id()
 @regscale_module()
 @click.option(
     "--path",
     type=click.Path(exists=False, dir_okay=True, path_type=Path),
-    help="Provide the desired path.",
-    default=os.path.join(os.getcwd(), "artifacts"),
+    help="Provide the desired path for created excel files to be saved to.",
+    default=Path("./artifacts"),
     required=True,
 )
-def data_load(regscale_id: str, regscale_module: str, path: Path):
+def generate_data_download(regscale_id: str, regscale_module: str, path: Path):
     """
     This function will build and populate a spreadsheet of all control implementations
     with the selected RegScale Parent Id and RegScale Module.
     """
+    data_load(regscale_id=regscale_id, regscale_module=regscale_module, path=path)
+
+
+def data_load(regscale_id: str, regscale_module: str, path: Path):
+    """Function takes organizer record and module and build excel worksheet of control implementations.
+
+    :param regscale_id: RegScale Parent Id
+    :param regscale_module: RegScale Parent Module
+    :param path: directory of file location
+    """
+    logger = create_logger()
+    app = Application()
+    api = Api(app)
 
     # Making directory for files
 
-    if os.path.isdir(path) is False:
-        try:
-            os.mkdir(path)
-            workbook = Workbook()
-            ws = workbook.active
-            ws.title = f"Impls_PId({regscale_id}_{regscale_module})"
-            workbook.save(filename=os.path.join(path, "all_implementations.xlsx"))
-            shutil.copy(
-                os.path.join(path, "all_implementations.xlsx"),
-                os.path.join(path, "old_implementations.xlsx"),
-            )
+    check_file_path(path)
 
-            # Loading data from RegScale database into two workbooks.
+    workbook = Workbook()
+    ws = workbook.active
+    ws.title = f"Impls_PId({regscale_id}_{regscale_module})"
+    workbook.save(filename=os.path.join(path, "all_implementations.xlsx"))
+    shutil.copy(
+        os.path.join(path, "all_implementations.xlsx"),
+        os.path.join(path, "old_implementations.xlsx"),
+    )
 
-            try:
-                body = """
-                        query{
-                            controlImplementations (skip: 0, take: 50, where: {parentId: {eq: parent_id} parentModule: {eq: "parent_module"}}) {
-                                items {
-                                id
-                                controlID
-                                controlOwnerId
-                                control {
-                                    title
-                                    description
-                                }
-                                status
-                                policy
-                                implementation
-                                responsibility
-                                inheritable
-                                parentId
-                                parentModule
-                                }
-                                totalCount
-                                pageInfo {
-                                    hasNextPage
-                                }
-                            }
-                            }""".replace(
-                    "parent_module", regscale_module
-                ).replace(
-                    "parent_id", regscale_id
-                )
-
-                existing_implementation_data = api.graph(query=body)
-
-            except requests.RequestException as ex:
-                error_and_exit(
-                    "Unable to retrieve assessment list from RegScale.\n %s", ex
-                )
-
-            if existing_implementation_data["controlImplementations"]["totalCount"] > 0:
-                raw_data = existing_implementation_data["controlImplementations"][
-                    "items"
-                ]
+    # Loading data from RegScale database into two workbooks.
 
-                all_imps = []
-                for item in raw_data:
-                    Id = item["id"]
-                    ControlId = item["controlID"]
-                    ControlOwnerId = item["controlOwnerId"]
-                    ControlName = item["control"]["title"]
-                    Description = item["control"]["description"]
-                    Status = item["status"]
-                    Policy = item["policy"]
-                    Implementation = item["implementation"]
-                    Responsibility = item["responsibility"]
-                    Inheritable = item["inheritable"]
-
-                    all_imps.append(
-                        [
-                            Id,
-                            ControlId,
-                            ControlOwnerId,
-                            ControlName,
-                            Description,
-                            Status,
-                            Policy,
-                            Implementation,
-                            Responsibility,
-                            Inheritable,
-                        ]
-                    )
-
-                all_imps_df = pd.DataFrame(
-                    all_imps,
-                    columns=[
-                        "Id",
-                        "ControlId",
-                        "ControlOwnerId",
-                        "ControlName",
-                        "Description",
-                        "Status",
-                        "Policy",
-                        "Implementation",
-                        "Responsibility",
-                        "Inheritable",
-                    ],
-                )
-
-                with pd.ExcelWriter(
-                    os.path.join(path, "all_implementations.xlsx"),
-                    mode="w",
-                    engine="openpyxl",
-                ) as writer:
-                    all_imps_df.to_excel(
-                        writer,
-                        sheet_name=f"Impls_PId({regscale_id}_{regscale_module})",
-                        index=False,
-                    )
-
-                with pd.ExcelWriter(
-                    os.path.join(path, "old_implementations.xlsx"),
-                    mode="w",
-                    engine="openpyxl",
-                ) as writer:
-                    all_imps_df.to_excel(
-                        writer,
-                        sheet_name=f"Impls_PId({regscale_id}_{regscale_module})",
-                        index=False,
-                    )
-            else:
-                logger.info(
-                    "Please check your selections for RegScale Id and RegScale Module and try again."
-                )
-                error_and_exit(
-                    "There was an error creating your workbook for the given RegScale Id and RegScale Module."
-                )
-
-            # Adding Data validation to "old_implementations.xlsx" file that will be used as reference.
-
-            workbook2 = load_workbook(os.path.join(path, "old_implementations.xlsx"))
-            worksheet2 = workbook2.active
-            worksheet2.protection.sheet = True
-            workbook2.save(filename=os.path.join(path, "old_implementations.xlsx"))
-
-            # Adding Data Validation to "all_implementations.xlsx" file to be adjusted internally by clients.
-
-            workbook = load_workbook(os.path.join(path, "all_implementations.xlsx"))
-            worksheet = workbook.active
-            worksheet.protection.sheet = True
-
-            dv1 = DataValidation(
-                type="list",
-                formula1='"Not Implemented, Fully Implemented, In Remediation, Not Applicable, Inherited, Planned"',
-                allow_blank=True,
-                showDropDown=False,
-                error="Your entry is not one of the available options",
-                errorTitle="Invalid Entry",
-                prompt="Please select from the list",
-            )
-            dv2 = DataValidation(
-                type="list",
-                formula1='"Provider, Customer, Shared, Not Applicable"',
-                allow_blank=True,
-                showDropDown=False,
-                error="Your entry is not one of the available options",
-                errorTitle="Invalid Entry",
-                prompt="Please select from the list",
+    body = """
+            query{
+                controlImplementations (skip: 0, take: 50, where: {parentId: {eq: parent_id} parentModule: {eq: "parent_module"}}) {
+                    items {
+                        id
+                        controlID
+                        controlOwnerId
+                        controlOwner {
+                            firstName
+                            lastName
+                            userName
+                        }
+                        control {
+                            title
+                            description
+                            controlId
+                        }
+                        status
+                        policy
+                        implementation
+                        responsibility
+                        inheritable
+                        parentId
+                        parentModule
+                    }
+                    totalCount
+                    pageInfo {
+                        hasNextPage
+                    }
+                }
+            }""".replace(
+        "parent_module", regscale_module
+    ).replace(
+        "parent_id", str(regscale_id)
+    )
+
+    existing_implementation_data = api.graph(query=body)
+
+    if existing_implementation_data["controlImplementations"]["totalCount"] > 0:
+        raw_data = existing_implementation_data["controlImplementations"]["items"]
+
+        all_imps = []
+        for item in raw_data:
+            Id = item["id"]
+            ControlId = item["controlID"]
+            ControlOwnerId = item["controlOwnerId"]
+            ControlOwner = (
+                str(item["controlOwner"]["lastName"]).strip()
+                + ", "
+                + str(item["controlOwner"]["firstName"]).strip()
+                + " ("
+                + str(item["controlOwner"]["userName"]).strip()
+                + ")"
             )
-            dv3 = DataValidation(
-                type="list", formula1='"TRUE, FALSE"', allow_blank=True
+            ControlName = item["control"]["controlId"]
+            ControlTitle = item["control"]["title"]
+            Description = item["control"]["description"]
+            Status = item["status"]
+            Policy = item["policy"]
+            Implementation = item["implementation"]
+            Responsibility = item["responsibility"]
+            Inheritable = item["inheritable"]
+
+            all_imps.append(
+                [
+                    Id,
+                    ControlId,
+                    ControlOwnerId,
+                    ControlOwner,
+                    ControlName,
+                    ControlTitle,
+                    Description,
+                    Status,
+                    Policy,
+                    Implementation,
+                    Responsibility,
+                    Inheritable,
+                ]
             )
 
-            worksheet.add_data_validation(dv1)
-            worksheet.add_data_validation(dv2)
-            worksheet.add_data_validation(dv3)
-            dv1.add("F2:F1048576")
-            dv2.add("I2:I1048576")
-            dv3.add("J2:J1048576")
-
-            for col in worksheet.columns:
-                max_length = 0
-                column = col[0].column_letter  # Get the column name
-                for cell in col:
-                    try:  # Necessary to avoid error on empty cells
-                        if len(str(cell.value)) > max_length:
-                            max_length = len(str(cell.value))
-                    except OSError:
-                        logger.error("Cell adjustment failed due to empty cells.")
-                adjusted_width = (max_length + 2) * 1.2
-                worksheet.column_dimensions[column].width = adjusted_width
-
-            for col in ["F", "G", "H", "I", "J"]:
-                for cell in worksheet[col]:
-                    cell.protection = Protection(locked=False)
+        all_imps_df = pd.DataFrame(
+            all_imps,
+            columns=[
+                "Id",
+                "ControlId",
+                "ControlOwnerId",
+                "ControlOwner",
+                "ControlName",
+                "ControlTitle",
+                "Description",
+                "Status",
+                "Policy",
+                "Implementation",
+                "Responsibility",
+                "Inheritable",
+            ],
+        )
 
-            workbook.save(filename=os.path.join(path, "all_implementations.xlsx"))
+        with pd.ExcelWriter(
+            os.path.join(path, "all_implementations.xlsx"),
+            mode="a",
+            engine="openpyxl",
+            if_sheet_exists="overlay",
+        ) as writer:
+            all_imps_df.to_excel(
+                writer,
+                sheet_name=f"Impls_PId({regscale_id}_{regscale_module})",
+                index=False,
+            )
 
-        except OSError:
-            logger.error(f"Creation of the directory {path} failed.")
+        with pd.ExcelWriter(
+            os.path.join(path, "old_implementations.xlsx"),
+            mode="a",
+            engine="openpyxl",
+            if_sheet_exists="overlay",
+        ) as writer:
+            all_imps_df.to_excel(
+                writer,
+                sheet_name=f"Impls_PId({regscale_id}_{regscale_module})",
+                index=False,
+            )
     else:
-        logger.info(f"Successfully created the directory {path}.")
-        logger.info("All files are located within directory.")
-        sys.exit()
+        error_and_exit(
+            "No records exist for the given RegScale Id and RegScale Module."
+        )
+
+    # Adding Data validation to "old_implementations.xlsx" file that will be used as reference.
 
-    return logger.info(
+    workbook2 = load_workbook(os.path.join(path, "old_implementations.xlsx"))
+    worksheet2 = workbook2.active
+    worksheet2.protection.sheet = True
+    workbook2.save(filename=os.path.join(path, "old_implementations.xlsx"))
+
+    # Adding Data Validation to "all_implementations.xlsx" file to be adjusted internally by clients.
+
+    workbook = load_workbook(os.path.join(path, "all_implementations.xlsx"))
+    worksheet = workbook.active
+    worksheet.protection.sheet = True
+
+    dv1 = DataValidation(
+        type="list",
+        formula1='"Not Implemented, Fully Implemented, In Remediation, Not Applicable, Inherited, Planned"',
+        allow_blank=True,
+        showDropDown=False,
+        error="Your entry is not one of the available options",
+        errorTitle="Invalid Entry",
+        prompt="Please select from the list",
+    )
+    dv2 = DataValidation(
+        type="list",
+        formula1='"Provider, Customer, Shared, Not Applicable"',
+        allow_blank=True,
+        showDropDown=False,
+        error="Your entry is not one of the available options",
+        errorTitle="Invalid Entry",
+        prompt="Please select from the list",
+    )
+    dv3 = DataValidation(type="list", formula1='"TRUE, FALSE"', allow_blank=True)
+
+    worksheet.add_data_validation(dv1)
+    worksheet.add_data_validation(dv2)
+    worksheet.add_data_validation(dv3)
+    dv1.add("H2:H1048576")
+    dv2.add("K2:K1048576")
+    dv3.add("L2:L1048576")
+
+    for col in worksheet.columns:
+        max_length = 0
+        column = col[0].column_letter  # Get the column name
+        for cell in col:
+            if len(str(cell.value)) > max_length:
+                max_length = len(str(cell.value))
+
+        adjusted_width = (max_length + 2) * 1.2
+        worksheet.column_dimensions[column].width = adjusted_width
+
+        if col == ["H", "I", "J", "K", "L"]:  # columns to edit
+            for cell in worksheet[col]:
+                cell.protection = Protection(locked=False)
+
+    workbook.save(filename=os.path.join(path, "all_implementations.xlsx"))
+
+    logger.info("Successfully created the directory %s.", path)
+    logger.info("All files are located within directory.")
+
+    logger.info(
         "Your data has been loaded into your excel workbook. Please open the all_implementations workbook and make your desired changes."
     )
+    return None
 
 
 # Save Spreadsheet if file changed, append Update API changes that were manually entered in an Excel worksheet
 
 
-@control_editor.command(name="data_upload")
+@control_editor.command(name="load")
 @click.option(
     "--path",
     type=click.Path(exists=False, dir_okay=True, path_type=Path),
-    help="Provide the desired path.",
-    default=os.path.join(os.getcwd(), "artifacts"),
+    help="Provide the desired path where excel workbooks are located.",
+    default=Path("./artifacts"),
     required=True,
 )
 @click.option(
     "--skip_prompt",
     type=click.BOOL,
     help="To Skip (Y/N) Prompt, input True.",
     default=False,
     required=False,
 )
-def db_update(path: Path, skip_prompt: bool):
+def generate_db_update(path: Path, skip_prompt: bool):
     """
-    This function will check changes made to spreadsheet and upload any changes made to RegScale database.
+    This function will check changes made to spreadsheet and upload any changes made to RegScale.
 
     """
+    db_update(path, skip_prompt)
+
+
+def db_update(path: Path, skip_prompt=True):
+    """Function will check changes made by user and upload any changes to RegScale.
+
+    :param path: directory of file location
+    :param skip_prompt: boolean to skip prompt save message, defaults to True
+    :return: None
+    """
+    logger = create_logger()
+
     logger.info(
         "Proceed only after you have made the necessary changes and have saved file."
     )
 
     x = "y" if skip_prompt else input("Ready to Proceed (Y/N): ").lower()
 
     if x[0] == "y":
-        df1 = load_workbook(os.path.join(path, "all_implementations.xlsx"))
-        ws1 = df1.active
+        df = load_workbook(os.path.join(path, "all_implementations.xlsx"))
 
-        sheet_name = df1.sheetnames[0]
+        sheet_name = df.sheetnames[0]
         sheet_name = sheet_name[sheet_name.find("(") + 1 : sheet_name.find(")")].split(
             "_"
         )
         regscale_parent_id, regscale_module = set(sheet_name)
 
-        data1 = ws1.values
-        columns1 = next(data1)[0:]
-        df1 = pd.DataFrame(data1, columns=columns1)
-
-        df2 = load_workbook(os.path.join(path, "old_implementations.xlsx"))
-        ws2 = df2.active
-        data2 = ws2.values
-        columns2 = next(data2)[0:]
-        df2 = pd.DataFrame(data2, columns=columns2)
-
-        data_frame_same = df1.equals(df2)  # Files being compared here.
-
-        with open(
-            os.path.join(path, "differences.txt"),
-            "w+",
-        ) as f:
-            f.truncate(0)
+        df1 = pd.read_excel(
+            os.path.join(path, "all_implementations.xlsx"), sheet_name=0, index_col="Id"
+        )
+
+        df2 = pd.read_excel(
+            os.path.join(path, "old_implementations.xlsx"), sheet_name=0, index_col="Id"
+        )
 
-        if data_frame_same:
-            logger.info("No differences detected.")
+        if df1.equals(df2):
+            error_and_exit("No differences detected.")
 
         else:
-            upload_data(regscale_parent_id, regscale_module, path)
             logger.warning("*** WARNING *** Differences Found.")
 
             # Logs changes to txt file
 
             diff_mask = (df1 != df2) & ~(df1.isnull() & df2.isnull())
             ne_stacked = diff_mask.stack()
             changed = ne_stacked[ne_stacked]
-            changed.index.names = ["row", "col"]
+            changed.index.names = ["Id", "Column"]
             difference_locations = np.where(diff_mask)
-            changed_from = df1.values[difference_locations]
-            changed_to = df2.values[difference_locations]
+            changed_to = df1.values[difference_locations]
+            changed_from = df2.values[difference_locations]
             changes = pd.DataFrame(
-                {"from": changed_from, "to": changed_to}, index=changed.index
+                {"From": changed_from, "To": changed_to}, index=changed.index
             )
             changes.to_csv(
                 os.path.join(path, "differences.txt"),
-                header=None,
-                index=None,
+                header=True,
+                index=True,
                 sep=" ",
                 mode="a",
             )
-    return logger.info(
-        "Please check differences.txt file located in artifacts folder of current working directory to see changes made."
+
+            upload_data(regscale_parent_id, regscale_module, path)
+
+    logger.info(
+        "Please check differences.txt file located in artifacts folder to see changes made."
     )
+    return None
 
 
 def upload_data(regscale_parent_id: int, regscale_module: str, path: Path) -> None:
     """
-    Batch uploads updated control implementation statements to the provided RegScale parent ID
+    Batch uploads updated control implementation statements to the provided RegScale parent ID.
     :param int regscale_parent_id: RegScale parent ID
     :param str regscale_module: RegScale parent module
     :param Path path: file path where control spreadsheet resides
     :raises: requests.exceptions.RequestException if API call encountered an error
     :return: None
     """
-    updated_implementations = []
+    app = Application()
+    config = app.config
+    api = Api(app)
+
+    diff = pd.read_csv(
+        os.path.join(path, "differences.txt"), header=0, sep=" ", index_col=None
+    )
+    ids = []
+    for i, row in diff.iterrows():
+        ids.append(row["Id"])
+
+    id_df = pd.DataFrame(ids, index=None, columns=["Id"])
+    id_df2 = id_df.drop_duplicates()
+
     reader = pd.read_excel(os.path.join(path, "all_implementations.xlsx"))
+    updates = reader[reader["Id"].isin(id_df2["Id"])]
     updates = reader.T.to_dict()
-    for i in updates.values():
-        updated_implementations.append(
-            ControlImplementation(
-                id=i["Id"],
-                controlOwnerId=i["ControlOwnerId"],
-                control=Control(
-                    title=i["ControlName"], description=i["Description"]
-                ).dict(),
-                status=i["Status"],
-                implementation=i["Implementation"],
-                policy=i["Policy"],
-                controlID=i["ControlId"],
-                responsibility=i["Responsibility"],
-                parentId=int(regscale_parent_id),
-                parentModule=regscale_module,
-                inheritable=i["Inheritable"],
-            )
-        )
-    new_implementations = json.dumps(updated_implementations)
-    try:
-        api.post(
-            url=config["domain"] + "/api/controlImplementation/batchUpdate",
-            json=new_implementations,
-        )
-        logger.info(
-            "%s total %s for Parent ID: %s in RegScale were updated.",
-            len(new_implementations),
-            regscale_module,
-            regscale_parent_id,
-        )
-    except requests.exceptions.RequestException as ex:
-        logger.error(
-            "Unable to update %s for ParentId: %s in RegScale \n %s",
-            regscale_module,
-            regscale_parent_id,
-            ex,
-        )
+    updated_implementations = [
+        ControlImplementation(
+            id=i["Id"],
+            controlOwnerId=i["ControlOwnerId"],
+            control=Control(
+                title=i["ControlTitle"],
+                description=i["Description"],
+                controlId=i["ControlName"],
+            ).dict(),
+            status=i["Status"],
+            implementation=check_empty_nan(i["Implementation"]),
+            policy=check_empty_nan(i["Policy"]),
+            controlID=i["ControlId"],
+            responsibility=check_empty_nan(i["Responsibility"]),
+            parentId=regscale_parent_id,
+            parentModule=regscale_module,
+            inheritable=check_inheritable(i["Inheritable"]),
+            lastUpdatedById=app.config["userId"],
+            dateLastUpdated=get_current_datetime(),
+        ).dict()
+        for i in updates.values()
+    ]
+
+    api.update_server(
+        url=config["domain"] + "/api/controlImplementation",
+        json_list=updated_implementations,
+        message="Working on uploading updated control implementations to RegScale.",
+        config=config,
+        method="put",
+    )
 
 
 # Delete and remove files from user's system.
 
 
 @control_editor.command(name="delete_files")
 @click.option(
     "--path",
     type=click.Path(exists=False, dir_okay=True, path_type=Path),
-    help="Provide the desired path.",
-    default=os.path.join(os.getcwd(), "artifacts"),
+    help="Provide the desired path of file location.",
+    default=Path("./artifacts"),
     required=True,
 )
+def generate_delete_file(path: Path):
+    """This command will delete files used during the Control editing process."""
+    delete_file(path)
+
+
 def delete_file(path: Path):
     """
     Deletes files used during the process.
 
+    :param path: directory of file location
+    :return: None
     """
+    logger = create_logger()
+
     os.remove(os.path.join(path, "all_implementations.xlsx"))
     os.remove(os.path.join(path, "old_implementations.xlsx"))
-    os.remove(os.path.join(path, "differences.txt"))
+    if os.path.isfile(os.path.join(path, "differences.txt")):
+        os.remove(os.path.join(path, "differences.txt"))
+    else:
+        pass
     os.rmdir(path)
-    return logger.info("Files have been deleted. Thank you.")
+    logger.info("Files have been deleted. Thank you.")
+    return None
+
+
+def check_inheritable(
+    value,
+):  # this function has to be checked separate to account for API only accpeting False Boolean unlike other class paramas
+    """This function takes a given value for an inheritable and checks if value is empty or NaN based on value type.
+    :param value: A string or float object
+    :return: A string value, float value. or False
+    :rtype: str, float, or False
+    """
+    if isinstance(value, str) and value.strip() == "":
+        return False
+    if isinstance(value, float) and math.isnan(value):
+        return False
+    return value
```

## regscale/core/app/internal/login.py

```diff
@@ -18,30 +18,38 @@
 from regscale.core.app.application import Application
 from regscale.core.app.logz import create_logger
 
 logger = create_logger()
 
 
 def login(
-    str_user: str, str_password: str, host: str = None, app: Application = None
+    str_user: str,
+    str_password: str,
+    host: str = None,
+    app: Application = None,
+    token: str = None,
 ) -> str:
     """
     Wrapper for Login to RegScale
     :param str str_user: username to log in with
     :param str str_password: password of provided user
     :param str host: host to log into, defaults to None
     :param app: Application object
+    :param token: a valid JWT token to pass
     :raises: ValueError if no domain value found in init.yaml
     :raises: TypeError if token or user id doesn't match expected data type
     :raises: SSLCertVerificationError if unable to validate SSL certificate
     :return: JWT after authentication
     :rtype: str
     """
     config = app.config
-    token = None
+    if token:
+        config["token"] = token
+        app.save_config(conf=config)
+        return token
     if config["domain"] is None:
         raise ValueError("No domain set in the initialization file.")
     if config["domain"] == "":
         raise ValueError("The domain is blank in the initialization file.")
     # set the catalog URL for your RegScale instance
     if host is None:
         url_login = normalize_url(config["domain"] + "/api/authentication/login")
```

## regscale/core/app/public/oscal.py

```diff
@@ -138,14 +138,16 @@
         if not check_component:
             response = api.post(url=f'{config["domain"]}/api/components/', json=reg)
             if not response.raise_for_status():
                 component_id = response.json()["id"]
                 logger.info("Successfully posted %s to RegScale.", reg["title"])
         else:
             for cmp in check_component:
+                # update the id for the reg object
+                reg["id"] = cmp["id"]
                 response = api.put(
                     url=f'{config["domain"]}/api/components/{cmp["id"]}', json=reg
                 )
                 if not response.raise_for_status():
                     component_id = cmp["id"]
                     # component_id = r.json()['id']
                     logger.info(
```

## regscale/core/app/utils/app_utils.py

```diff
@@ -3,14 +3,15 @@
 """ Functions used throughout the application """
 
 # standard python imports
 import csv
 import glob
 import json
 import ntpath
+import math
 import os
 import random
 import re
 import sys
 from collections import abc
 from datetime import datetime
 from pathlib import Path
@@ -27,14 +28,15 @@
     BarColumn,
     Progress,
     SpinnerColumn,
     TextColumn,
     TimeElapsedColumn,
 )
 
+from regscale.core.app.api import Api
 from regscale.core.app.application import Application
 from regscale.core.app.internal.login import is_licensed
 from regscale.core.app.logz import create_logger
 from regscale.exceptions.license_exception import LicenseException
 
 logger = create_logger()
 
@@ -707,7 +709,38 @@
         for i in node:
             yield from find_keys(i, kv)
     elif isinstance(node, dict):
         if kv in node:
             yield node[kv]
         for j in node.values():
             yield from find_keys(j, kv)
+
+
+def get_user_names() -> pd.DataFrame:
+    """This function uses API Endpoint to retrieve all user names in database
+    :return: pandas dataframe with usernames
+    :rtype: pd.dataframe
+    """
+    app = Application()
+    config = app.config
+    api = Api(app)
+    accounts = api.get(url=config["domain"] + "/api/accounts").json()
+
+    user_names = [[" ".join(item["name"].split()), item["id"]] for item in accounts]
+    return pd.DataFrame(
+        user_names,
+        index=None,
+        columns=["User", "UserId"],
+    )
+
+
+def check_empty_nan(value):
+    """This function takes a given value and checks if value is empty or NaN based on value type.
+    :param value: A string or float object
+    :return: A string value, float value. or None
+    :rtype: str, float, or None
+    """
+    if isinstance(value, str) and value.strip() == "":
+        return None
+    if isinstance(value, float) and math.isnan(value):
+        return None
+    return value
```

## regscale/core/app/utils/regscale_utils.py

```diff
@@ -230,34 +230,41 @@
     else:
         error_and_exit(
             f"Unable to get assets from RegScale. Received:{response.status_code}\n{response.text}"
         )
     return results
 
 
-def get_all_from_module(api, module: str) -> list[dict]:
+def get_all_from_module(api, module: str, timeout: int = 300) -> list[dict]:
     """
     Function to retrieve all records for the provided Module in RegScale via API
     :param api: API object
     :param str module: RegScale Module
+    :param int timeout: Timeout for the API call, defaults to 300 seconds
     :raises: JSONDecodeError if API response cannot be converted to a json object
     :return: list of objects from RegScale API of the provided module
     :rtype: list[dict]
     """
     # verify provided module
     verify_provided_module(module)
 
+    # get the original timeout and update the timeout to the provided timeout
+    original_timeout = api.timeout
+    api.timeout = timeout
+
     # set URL for API call
     regscale_url = f"{api.config['domain']}/api/{module}/getAll"
 
     logger.info("Fetching full list of %s from RegScale.", module)
     # get the full list of provided module
     try:
         regscale_response = api.get(regscale_url)
         regscale_data = regscale_response.json()
+        # reset the timeout to the original timeout
+        api.timeout = original_timeout
     except JSONDecodeError:
         error_and_exit(f"Unable to retrieve full list of {module} from RegScale.")
     logger.info("Retrieved %s %s from RegScale.", len(regscale_data), module)
     return regscale_data
 
 
 def format_control(control: str):
```

## regscale/integrations/commercial/wiz.py

```diff
@@ -421,56 +421,28 @@
         # Batch post new properties.
         api.post(
             url=app.config["domain"] + "/api/properties/batchcreate",
             json=new_props,
         )
 
 
-def create_assets(
-    app: Application,
-    wiz_report_ids: list[str],
-    parent_id: int,
-    parent_module: str,
-) -> tuple[list[dict], list[Asset]]:
+def create_wiz_assets(
+    app: Application, df: pd.DataFrame, parent_id: int, parent_module: str
+) -> list[Asset]:
+    """Create Wiz Assets
+
+    :param app: Application instance
+    :param wiz_assets: list of wiz assets
+    :param all_df: Dataframe with Wiz Assets
+    :param parent_id: RegScale parent id
+    :param parent_module: RegScale parent module
+    :return: A list of assets
+    :rtype: list[Asset]
     """
-    Create Wiz Assets and Sync to RegScale
-    :param Application app: The application instance
-    :param list wiz_report_ids: A list of Wiz report IDs
-    :param int parent_id: ID from RegScale of parent
-    :param str parent_module: Parent Module of item in RegScale
-    :raises Exception: A generic exception
-    :raises requests.RequestException: A requests exception
-    :return: properties: str, wiz_assets: list
-    :rtype: tuple[list[dict], list[Asset]]
-    """
-    frames = []
-    properties = None
-
-    def gather_urls(report_id: str) -> list[str]:
-        """Gather download URLS for wiz reports
-
-        :param wiz_report_ids: A list of report ids
-        :return: A list of urls.
-        """
-        download_url = get_report_url_and_status(app=app, report_id=report_id)
-        url_job_progress.update(gathering_urls, advance=1)
-        return download_url
-
-    def stream_inventory(args: Tuple) -> None:
-        (url, session) = args
-        # find which records should be executed by the current thread
-        logger.debug("Downloading %s", url)
-        response = session.get(url, stream=True)
-        url_data = response.content
-        stream_frame = pd.read_csv(io.StringIO(url_data.decode("utf-8")))
-        logger.debug(len(stream_frame))
-        frames.append(stream_frame)
-        job_progress.update(downloading_reports, advance=1)
-        logger.debug("Frame Update.. for %s", url)
-
+    wiz_assets = []
     mapping = {
         "ACCESS_ROLE": "Other",
         "ACCESS_ROLE_BINDING": "Other",
         "ACCESS_ROLE_PERMISSION": "Other",
         "API_GATEWAY": "Other",
         "APPLICATION": "Other",
         "AUTHENTICATION_CONFIGURATION": "Other",
@@ -545,17 +517,110 @@
         "VIRTUAL_MACHINE": "Virtual Machine (VM)",
         "VIRTUAL_MACHINE_IMAGE": "Other",
         "VIRTUAL_NETWORK": "Other",
         "VOLUME": "Other",
         "WEB_SERVICE": "Other",
         "DATA_WORKFLOW": "Other",
     }
+    for _, row in df.iterrows():
+        if isinstance(row["Provider ID"], str):
+            provider_id = (
+                find_uuid_in_str(row["Provider ID"])
+                if isinstance(row["Provider ID"], str)
+                else row["Provider ID"]
+            )
+            wiz_data = json.dumps(
+                {
+                    "tags": json.loads(row["Tags"]),
+                    "wiz_json": json.loads(row["Wiz JSON Object"]),
+                    "other": json.loads(row["Cloud Native JSON"]),
+                }
+            )
+            properties = get_properties(app=app, wiz_data=wiz_data, wiz_id=provider_id)
+            external_id = row["External ID"]
+            description = format_dict_to_html(
+                {
+                    "Tags": json.loads(row["Tags"]),
+                    "WizJSON": json.loads(row["Wiz JSON Object"]),
+                    "CloudNativeJSON": json.loads(row["Cloud Native JSON"]),
+                }
+            )
+            r_asset = Asset(
+                name=row["Name"],
+                notes=f"External ID: {external_id}",
+                otherTrackingNumber=provider_id,
+                wizId=external_id,
+                wizInfo=None,
+                parentId=parent_id,
+                parentModule=parent_module,
+                ipAddress=None,
+                macAddress=None,
+                operatingSystem=row["app.kubernetes.io/os"]
+                if "app.kubernetes.io/os" in json.loads(row["Tags"]).keys()
+                else None,
+                assetOwnerId=app.config["userId"],
+                status="Active (On Network)",  # Get Status from Tags
+                assetCategory=map_category(row["Resource Type"]),
+                assetType=mapping[row["Resource Type"]]
+                if row["Resource Type"] in mapping
+                else "Other",
+                description=description,
+            )
+            wiz_assets.append(r_asset.dict())
+    logger.info(
+        "%i Wiz Assets with valid provider id's filtered..",
+        len(wiz_assets),
+    )
+    return wiz_assets
+
+
+def create_assets(
+    app: Application,
+    wiz_report_ids: list[str],
+    parent_id: int,
+    parent_module: str,
+) -> tuple[list[dict], list[Asset]]:
+    """
+    Create Wiz Assets and Sync to RegScale
+    :param Application app: The application instance
+    :param list wiz_report_ids: A list of Wiz report IDs
+    :param int parent_id: ID from RegScale of parent
+    :param str parent_module: Parent Module of item in RegScale
+    :raises Exception: A generic exception
+    :raises requests.RequestException: A requests exception
+    :return: properties: str, wiz_assets: list
+    :rtype: tuple[list[dict], list[Asset]]
+    """
+    frames = []
+    properties = None
+
+    def gather_urls(report_id: str) -> list[str]:
+        """Gather download URLS for wiz reports
+
+        :param wiz_report_ids: A list of report ids
+        :return: A list of urls.
+        """
+        download_url = get_report_url_and_status(app=app, report_id=report_id)
+        url_job_progress.update(gathering_urls, advance=1)
+        return download_url
+
+    def stream_inventory(args: Tuple) -> None:
+        (url, session) = args
+        # find which records should be executed by the current thread
+        logger.debug("Downloading %s", url)
+        response = session.get(url, stream=True)
+        url_data = response.content
+        stream_frame = pd.read_csv(io.StringIO(url_data.decode("utf-8")))
+        logger.debug(len(stream_frame))
+        frames.append(stream_frame)
+        job_progress.update(downloading_reports, advance=1)
+        logger.debug("Frame Update.. for %s", url)
+
     api = Api(app)
     random.shuffle(wiz_report_ids)
-    wiz_assets = []
     logger.info("Streaming Automated Inventory Report(s) to RegScale Assets..")
     session = api.session
     urls = []
     with url_job_progress:
         gathering_urls = url_job_progress.add_task(
             f"[#ba1d49]Gathering {len(wiz_report_ids)} Wiz report URL(s)...",
             total=len(wiz_report_ids),
@@ -589,64 +654,16 @@
                     for url in urls
                 ]
                 # wait for all download tasks to complete
                 _, _ = wait(futures)
     if job_progress.finished and frames:
         all_df = pd.concat(frames)
         logger.info("Merging reports to a dataset with %i records", len(all_df))
-        for _, row in all_df.iterrows():
-            if isinstance(row["Provider ID"], str):
-                provider_id = (
-                    find_uuid_in_str(row["Provider ID"])
-                    if isinstance(row["Provider ID"], str)
-                    else row["Provider ID"]
-                )
-                wiz_data = json.dumps(
-                    {
-                        "tags": json.loads(row["Tags"]),
-                        "wiz_json": json.loads(row["Wiz JSON Object"]),
-                        "other": json.loads(row["Cloud Native JSON"]),
-                    }
-                )
-                properties = get_properties(
-                    app=app, wiz_data=wiz_data, wiz_id=provider_id
-                )
-                external_id = row["External ID"]
-                description = format_dict_to_html(
-                    {
-                        "Tags": json.loads(row["Tags"]),
-                        "WizJSON": json.loads(row["Wiz JSON Object"]),
-                        "CloudNativeJSON": json.loads(row["Cloud Native JSON"]),
-                    }
-                )
-                r_asset = Asset(
-                    name=row["Name"],
-                    notes=f"External ID: {external_id}",
-                    otherTrackingNumber=provider_id,
-                    wizId=external_id,
-                    wizInfo=None,
-                    parentId=parent_id,
-                    parentModule=parent_module,
-                    ipAddress=None,
-                    macAddress=None,
-                    operatingSystem=row["app.kubernetes.io/os"]
-                    if "app.kubernetes.io/os" in json.loads(row["Tags"]).keys()
-                    else None,
-                    assetOwnerId=app.config["userId"],
-                    status="Active (On Network)",  # Get Status from Tags
-                    assetCategory=map_category(row["Resource Type"]),
-                    assetType=mapping[row["Resource Type"]]
-                    if row["Resource Type"] in mapping
-                    else "Other",
-                    description=description,
-                )
-                wiz_assets.append(r_asset.dict())
-        logger.info(
-            "%i Wiz Assets with valid provider id's filtered..",
-            len(wiz_assets),
+        wiz_assets = create_wiz_assets(
+            app=app, df=all_df, parent_id=parent_id, parent_module=parent_module
         )
     if len(wiz_assets) == 0:
         logger.warning("No Wiz Assets found!")
         sys.exit(0)
     return properties, wiz_assets
 
 
@@ -693,14 +710,63 @@
         regscale_module=regscale_module,
         client_id=client_id,
         client_secret=client_secret,
         issue_severity_filter=issue_severity_filter,
     )
 
 
+def update_issue(issue: Issue, wiz_issues: list[Issue]) -> Issue:
+    """Process RegScale issue and update it with Wiz issue data.
+
+    :param issue: RegScale Issue
+    :param wiz_issues: Wiz Issues
+    :return: RegScale Issue
+    :rtype: Issue
+    """
+    set_wiz_issues = set(wiz.wizId for wiz in wiz_issues)
+    issue.status = "Open" if issue.wizId in set_wiz_issues else "Closed"
+    issue.description = (
+        issue.description if issue.wizId in set_wiz_issues else issue.description
+    )
+    # concatenate the new security check from wiz if RegScale issue is found in Wiz issue
+    # and the RegScale issue already has data in the severityCheck field
+    if issue.wizId in set_wiz_issues:
+        for wiz_issue in wiz_issues:
+            # concatenate the security checks because RegScale issue already has security checks populated
+            if (
+                issue.wizId == wiz_issue.wizId
+                and issue.securityChecks
+                and issue.securityChecks != wiz_issue.securityChecks
+            ):
+                issue.securityChecks += f"</br>{wiz_issue.securityChecks}"
+                issue.recommendedActions = wiz_issue.recommendedActions
+                break
+            # set the RegScale issue's security checks to Wiz's security checks because it is empty
+            elif (
+                issue.wizId == wiz_issue.wizId
+                and issue.securityChecks != wiz_issue.securityChecks
+            ):
+                issue.securityChecks = wiz_issue.securityChecks
+                issue.recommendedActions = wiz_issue.recommendedActions
+                break
+            # the securityChecks match for Wiz and RegScale, but not the recommended actions
+            elif (
+                issue.wizId == wiz_issue.wizId
+                and issue.securityChecks == wiz_issue.securityChecks
+                and issue.recommendedActions != wiz_issue.recommendedActions
+            ):
+                issue.recommendedActions = wiz_issue.recommendedActions
+                break
+    if issue.status == "Closed" and not issue.dateCompleted:
+        issue.dateCompleted = get_current_datetime()
+    if issue.status == "Open":
+        issue.dateCompleted = ""
+    return issue
+
+
 def process_wiz_issues(
     wiz_project_id: str,
     regscale_id: int,
     regscale_module: str,
     client_id: str,
     client_secret: str,
     issue_severity_filter: str,
@@ -862,52 +928,15 @@
         else:
             days = config["issues"]["wiz"]["low"]
         issue["dueDate"] = (
             datetime.datetime.now() + datetime.timedelta(days=days)
         ).strftime(fmt)
         new_issues.append(issue)
     for issue in existing_regscale_issues:
-        set_wiz_issues = set(wiz.wizId for wiz in wiz_issues)
-        issue.status = "Open" if issue.wizId in set_wiz_issues else "Closed"
-        issue.description = (
-            issue.description if issue.wizId in set_wiz_issues else issue.description
-        )
-        # concatenate the new security check from wiz if RegScale issue is found in Wiz issue
-        # and the RegScale issue already has data in the severityCheck field
-        if issue.wizId in set_wiz_issues:
-            for wiz_issue in wiz_issues:
-                # concatenate the security checks because RegScale issue already has security checks populated
-                if (
-                    issue.wizId == wiz_issue.wizId
-                    and issue.securityChecks
-                    and issue.securityChecks != wiz_issue.securityChecks
-                ):
-                    issue.securityChecks += f'</br>{wiz_issue["securityChecks"]}'
-                    issue.recommendedActions = wiz_issue.recommendedActions
-                    break
-                # set the RegScale issue's security checks to Wiz's security checks because it is empty
-                elif (
-                    issue.wizId == wiz_issue.wizId
-                    and issue.securityChecks != wiz_issue.securityChecks
-                ):
-                    issue.securityChecks = wiz_issue.securityChecks
-                    issue.recommendedActions = wiz_issue.recommendedActions
-                    break
-                # the securityChecks match for Wiz and RegScale, but not the recommended actions
-                elif (
-                    issue.wizId == wiz_issue.wizId
-                    and issue.securityChecks == wiz_issue.securityChecks
-                    and issue.recommendedActions != wiz_issue.recommendedActions
-                ):
-                    issue.recommendedActions = wiz_issue.recommendedActions
-                    break
-        if issue.status == "Closed" and not issue.dateCompleted:
-            issue.dateCompleted = get_current_datetime()
-        if issue.status == "Open":
-            issue.dateCompleted = ""
+        issue = update_issue(issue, wiz_issues)
         update_issues.append(issue)
 
     api.update_server(
         config=app.config,
         method="post",
         url=app.config["domain"] + "/api/issues",
         json_list=new_issues,
```

## Comparing `RegScale_CLI-5.6.1.dist-info/LICENSE` & `RegScale_CLI-5.7.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `RegScale_CLI-5.6.1.dist-info/METADATA` & `RegScale_CLI-5.7.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: RegScale-CLI
-Version: 5.6.1
+Version: 5.7.0
 Summary: Command Line Interface (CLI) for bulk processing/loading data into RegScale
 Home-page: https://github.com/RegScale/regscale-cli
 Author: Travis Howerton
 Author-email: thowerton@regscale.com
 License: MIT
 Platform: UNKNOWN
 Classifier: Operating System :: OS Independent
```

## Comparing `RegScale_CLI-5.6.1.dist-info/RECORD` & `RegScale_CLI-5.7.0.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,39 +1,39 @@
-regscale/__init__.py,sha256=-q9tSF5ofTJum4PMjvbhaE1xmTXehc_9rxMGcmfodcw,22
-regscale/regscale.py,sha256=Nhbt4M3kA4pw4tV1Y_16Dl1rHOub3rDQvCiySq5HdkM,15241
+regscale/__init__.py,sha256=QmHMXVnw5DVPfWzvN7FS1tOhDAesdxpM_aVOh9CMuSk,22
+regscale/regscale.py,sha256=POf6J5Fv4n7WHELeoz-jOIlI1u1yBTGiV0BMopkMcL0,15470
 regscale/airflow/__init__.py,sha256=yMwN0Bz4JbM0nl5qY_hPegxo_O2ilhTOL9PY5Njhn-s,270
 regscale/airflow/tasks/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/airflow/tasks/cli.py,sha256=bsrFOtiHMqK661LG4IwJ0Yxq1T0tk2I14Y9UQpLO76w,3308
 regscale/ansible/__init__.py,sha256=DZmNktNFs5ilDX8vbYdxdjFADjyWZhawWuLk8O27CNM,262
 regscale/core/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/core/login.py,sha256=vpiEvWz31PgSLvOrNM9QQ3MfqWlJsGdx9jFdYcN9Dj4,1553
 regscale/core/app/__init__.py,sha256=8gm8M1aKTdDNsiBLrWXNKURK3DUThg52FEkZcCEELgM,129
 regscale/core/app/api.py,sha256=i0QyB2418p5zoagOmLAumMFFlzatmzDGlMkhUA3yIWw,14666
 regscale/core/app/application.py,sha256=Zkl-8BPnrMT8xTD2x-MP7rintgKXB4TybrnP-6juoWQ,13607
 regscale/core/app/logz.py,sha256=j8E0ZqkCUBxV7ncBU9MIjOD_yn9AOOZYnxQ9_MMpR4k,1206
 regscale/core/app/internal/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/core/app/internal/admin_actions.py,sha256=CSALLdTlqF_Gy9W2f-cTTZmd42uKX0ljofr7h10HC1I,27214
-regscale/core/app/internal/assessments_editor.py,sha256=rjFOLtgacdWawEOrRw69bnIY1Cc3NTROf3qpSc-WWpk,31088
+regscale/core/app/internal/assessments_editor.py,sha256=sUl2spf4L500UHEjn3-j8kJI9ywNHPG9THRjV03hXKw,35836
 regscale/core/app/internal/catalog.py,sha256=S_bKw6X3G9EG2--gz8WDBAN0iILCBHWlq7_sONx2nLA,979
 regscale/core/app/internal/comparison.py,sha256=hYHgLY5f4bc9aOZ7uE2tDAnCvRRRSQaW6lgZpMFa-8I,16694
-regscale/core/app/internal/control_editor.py,sha256=7Q9ptoxrrZcTsU0ETtBL54-1Q1vggfc_eyH9k0N3qPk,15364
+regscale/core/app/internal/control_editor.py,sha256=EMOTl33z-OGZGkBfTik52L_ChSROt67p0hZlmAZ8zoE,15694
 regscale/core/app/internal/encrypt.py,sha256=CRfWU0hTiirBdz8Ff7khaIasOmCR8CQ3Dmff7o1gjUo,5948
 regscale/core/app/internal/evidence.py,sha256=uHfoGmJ7ao4iuGEtVBNVpnot588TU9v1-3cimMeC-sI,40204
 regscale/core/app/internal/healthcheck.py,sha256=0Il1Wa70BKhKBA2VVANFQBD-2PMDEpFzRtYdB0Kj7D0,2367
-regscale/core/app/internal/login.py,sha256=W4jzkQW1yF8hseyIoPNdTDKPcARoZ05dlX3iG4fB0wU,6513
+regscale/core/app/internal/login.py,sha256=jIExAn3MqJ7-2ySRUtJYHYsrDR4DYGz5eIr2IFeKAwI,6680
 regscale/core/app/internal/migrations.py,sha256=cBpn5lKN_c8u6O0iLKXtjee70QJGiuc06mw_XwH6Mdo,9712
 regscale/core/app/public/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/core/app/public/emass.py,sha256=g2UHEVKHkPjhsqYsltXgThhBcC3jZcxL5B1i_VDIaTQ,11879
 regscale/core/app/public/fedramp.py,sha256=-EpBY238tiMoZFRLuC5Tg-I5UBodbQVak-k5DlJHol4,62097
 regscale/core/app/public/nist_catalog.py,sha256=B5UjKEuEE3BiXMfrAbYVsHwVpoMj4a5q5OLhFcoSRHQ,9000
-regscale/core/app/public/oscal.py,sha256=lSnoEoC4aKDneNs2Ck57tgYFlzilM_fAZuvRVgoOCv0,87151
+regscale/core/app/public/oscal.py,sha256=9wj-0DKJhqfDqkaoJebnDtrBp24cnx532gEGfFK3wGI,87240
 regscale/core/app/public/otx.py,sha256=fI9WPeeai2f4Hix5R3gk6uGnD3o1pIrt8Is9zySZk_8,6125
 regscale/core/app/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-regscale/core/app/utils/app_utils.py,sha256=73Jo-d4DOZUI6kpHrhvwwzE_VHtP5QoJyoLdoJt-JTQ,23790
-regscale/core/app/utils/regscale_utils.py,sha256=f8DPbnxpgqA4MGl5h4l-gtkSqCR4pMVgS4lu_Qzq_eo,10613
+regscale/core/app/utils/app_utils.py,sha256=QXtmE17CKTEjKwmtxuPjnjptAXkkgGb2UF6CTDD0u2Y,24794
+regscale/core/app/utils/regscale_utils.py,sha256=7lH1IYJzwIgrRP3QsGN7eho-0WK28a6IlUf9AVcoJvA,10938
 regscale/core/app/utils/threadhandler.py,sha256=1CTYikH-HeeGMhfxhqhVcmCUaBrJiAXQInNUI5iEHDc,1605
 regscale/core/app/utils/catalog_utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/core/app/utils/catalog_utils/compare_catalog.py,sha256=gvDI1tO8AxcyVx4umI9ABQ61nvlmmYBkHaMxCBJZdQM,9213
 regscale/core/app/utils/catalog_utils/diagnostic_catalog.py,sha256=_dwKLGICKNcz6aOsku9wetRN7KK6k8-N0UwzlIgnvEI,4467
 regscale/core/app/utils/catalog_utils/export_catalog.py,sha256=QO3x8L5qFs0S5HNxCgbSawQY6-k30VrZwNeN3Dgl0Sc,2727
 regscale/core/static/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/core/static/regex.py,sha256=Nf0aiAvBxzFWC96Bk2dZYby-y7KrFAVjI3f6I599UIU,383
@@ -49,27 +49,26 @@
 regscale/integrations/commercial/defender.py,sha256=P2nqaRTRu78Hha2q-SGjd9dBfH_2mUEr2PrBiDG1moE,46871
 regscale/integrations/commercial/jira.py,sha256=YEzu7tg17fDhFYMiIxup6dhQGod1yHDcns8P0GKaaPo,8720
 regscale/integrations/commercial/okta.py,sha256=f1vf05y9qhnblDBc9S1-pVPttUDPNKFzQUJVfAj-RjM,30770
 regscale/integrations/commercial/qualys.py,sha256=YUfxx_cSggrbqcPVlovP9UVq6t1fxAaTPoelrz4YIZ4,31505
 regscale/integrations/commercial/servicenow.py,sha256=Hvn285cputK1YKsGMzmV16BsF5s96mezUe0Mq3V_39Y,12466
 regscale/integrations/commercial/stig.py,sha256=kukN7-5D-Ocn4ELZkXs83R0Vj1o_OYR5j8q8bZ9hqlM,63117
 regscale/integrations/commercial/tenable.py,sha256=bMsbmb7M7D7R56_vwTKLHuCZGOc12uyEGXrlxgjCRUU,22684
-regscale/integrations/commercial/wiz.py,sha256=rK1NxBvgQTomxoWsyC-t1aGkInVN0z7VqKHHb-2z4Fw,62197
+regscale/integrations/commercial/wiz.py,sha256=1xo-wXilfPal7t7BuT9LzjlL-UHEyM49yk5Be-FlyxE,62697
 regscale/integrations/commercial/azure/__init__.py,sha256=FbBC6JCWmQAleAqmvsvMC2pjj0iFZPmJQgPZFcV7r8s,206
 regscale/integrations/commercial/azure/common.py,sha256=5AsfMuah-ipOrIeGJemah4iMNRvgGEuPDELB_3pFc-c,1049
 regscale/integrations/commercial/azure/intune.py,sha256=paIRrC9PMva7LX-7x4yUWN20kRfYSZ2pytr2Jev2--k,13876
 regscale/integrations/public/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/integrations/public/cisa.py,sha256=EkiCrxrPIQmyayDwPxS3RMGkJxWyUOcgOwiE2gYGXks,18680
 regscale/models/__init__.py,sha256=I8g3yVQOgPLH_d3UWwHPpwrnfDoHG-VW2S0k4lmkz3o,153
 regscale/models/config.py,sha256=fnF6tTd5DX88VcsKQpMWd3WVDqkLfkOCATnqziJZYjA,4865
 regscale/models/platform.py,sha256=0HCSqXc9JwKdzlO37vJs252ucGzfZEyKI50rnXEGxT4,3453
 regscale/models/app_models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/models/app_models/catalog_compare.py,sha256=l9zI6f0oV2igEoOQU9RpMLriYi7XZng6UR7UcsMyx7k,7553
 regscale/models/app_models/click.py,sha256=JgWwakrKTs2x9cUUMExMma1ag1HBXJbkCMvpZ1mDM40,4006
-regscale/models/app_models/control_editor.py,sha256=g8iHaawU-XstzuZQO0wGp4I4Jx5U199r4OAD6xEpqfE,13918
 regscale/models/app_models/pipeline.py,sha256=13BuBreZESL7SP7ajCFXy8bgaEchTnyGlaRtUMBl0bM,889
 regscale/models/integration_models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/models/integration_models/azure_alerts.py,sha256=I_jcjaLMsQpgabkdtVbalGZ23GeAH8aQCmH9iXlKFhw,7858
 regscale/models/integration_models/recommendations.py,sha256=T_zyM1G4xFsZgApVvz8CGUMYuZLzfXLgoAcXsz1xUKE,872
 regscale/models/integration_models/tenable.py,sha256=ssbs0p5VNqWBvQSwDqNchVHQOxhzblnd1F_Zjf9NAJ8,8319
 regscale/models/integration_models/wiz.py,sha256=BqHeFvHtft7Ona8Gz1p9_JctxHjdJi0KlrDJ83Ub5g4,1833
 regscale/models/regscale_models/__init__.py,sha256=oVsqx-SyDOCfELxGuDy4tIXccZcvWHG86zVDjVhPwrY,257
@@ -105,13 +104,13 @@
 tests/mocks/xml.py,sha256=ANUjXOyT8KidrqpidmfoOuy9jwi6zjsoy-BUY2Pxep8,260
 tests/regscale/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/regscale/core/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/regscale/core/test_login.py,sha256=VRSV22SXqORduZy-zKMhlXF_3rbO_MOuQpEjRcUghpQ,1172
 tests/regscale/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/regscale/models/test_config.py,sha256=IheTP4zxZqGaBJ7n0_fU5tgtbdX-VXyEe4jTUHoXZAo,810
 tests/regscale/models/test_platform.py,sha256=FPU74dye7gxl-VjFkiXpz3lcBxUQeCEgiU-xghSdXAE,856
-RegScale_CLI-5.6.1.dist-info/LICENSE,sha256=ytNhYQ9Rmhj_m-EX2pPq9Ld6tH5wrqqDYg-fCf46WDU,1076
-RegScale_CLI-5.6.1.dist-info/METADATA,sha256=tMJH9iV-Kv4Z7SL1h0YqmT_cmfi7ntsAM4hr0JlSARc,6658
-RegScale_CLI-5.6.1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-RegScale_CLI-5.6.1.dist-info/entry_points.txt,sha256=zrr7q-ywNBiOJZfZyKIzCdLzeF94lsnbweTQWj8VG-Y,52
-RegScale_CLI-5.6.1.dist-info/top_level.txt,sha256=cYezFj4wbGuaRuyLPNikMoIZf0jEgEIfTfLRVvC9bEs,26
-RegScale_CLI-5.6.1.dist-info/RECORD,,
+RegScale_CLI-5.7.0.dist-info/LICENSE,sha256=ytNhYQ9Rmhj_m-EX2pPq9Ld6tH5wrqqDYg-fCf46WDU,1076
+RegScale_CLI-5.7.0.dist-info/METADATA,sha256=0qI6B9uv6AacAraBfnqOGV8z1x9TrjA45nwKr6atMn8,6658
+RegScale_CLI-5.7.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+RegScale_CLI-5.7.0.dist-info/entry_points.txt,sha256=zrr7q-ywNBiOJZfZyKIzCdLzeF94lsnbweTQWj8VG-Y,52
+RegScale_CLI-5.7.0.dist-info/top_level.txt,sha256=cYezFj4wbGuaRuyLPNikMoIZf0jEgEIfTfLRVvC9bEs,26
+RegScale_CLI-5.7.0.dist-info/RECORD,,
```

